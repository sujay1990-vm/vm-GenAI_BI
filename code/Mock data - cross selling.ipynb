{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.7)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikeras 0.4.1 requires packaging<22.0,>=0.21, but you have packaging 23.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (2.2.3)\n",
      "Collecting scikit-learn>=1.3.1 (from mlxtend)\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (3.9.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.28.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Collecting joblib>=0.13.2 (from mlxtend)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 1.4/1.4 MB 23.2 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 11.1/11.1 MB 18.8 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib, scikit-learn, mlxtend\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "  Attempting uninstall: mlxtend\n",
      "    Found existing installation: mlxtend 0.1.7\n",
      "    Uninstalling mlxtend-0.1.7:\n",
      "      Successfully uninstalled mlxtend-0.1.7\n",
      "Successfully installed joblib-1.4.2 mlxtend-0.23.4 scikit-learn-1.6.1\n"
     ]
    }
   ],
   "source": [
    "! py -m pip install mlxtend --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock Customers data generated and saved as 'Customers.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "n = 10000\n",
    "\n",
    "# CustomerID: 1, 2, 3, ..., 10000\n",
    "customer_id = np.arange(1, n + 1)\n",
    "\n",
    "# Age: random integer values between 18 and 74\n",
    "age = np.random.randint(18, 75, n)\n",
    "\n",
    "# Income: Correlated with age.\n",
    "# Base income scales linearly from $50,000 (age 18) to $500,000 (age 74).\n",
    "income_base = 50000 + ((age - 18) / (74 - 18)) * (500000 - 50000)\n",
    "# Add some noise to vary the income (mean 0, standard deviation $30,000)\n",
    "noise_income = np.random.normal(0, 30000, n)\n",
    "income = income_base + noise_income\n",
    "# Ensure income stays within [$50,000, $500,000]\n",
    "income = np.clip(income, 50000, 500000)\n",
    "# Round income to the nearest 1000 so it always ends with '000'\n",
    "income = np.round(income / 1000) * 1000\n",
    "\n",
    "# Credit Score: Simulate a score between 300 and 850.\n",
    "# We make it increase with age: baseline score is 300 at age 18 and 850 at age 74.\n",
    "credit_score_base = 300 + (age - 18) * ((850 - 300) / (74 - 18))\n",
    "noise_credit = np.random.normal(0, 30, n)\n",
    "credit_score = credit_score_base + noise_credit\n",
    "credit_score = np.clip(credit_score, 300, 850)\n",
    "credit_score = np.round(credit_score).astype(int)\n",
    "\n",
    "# Tenure: Number of years with the company, random integer between 1 and 20.\n",
    "tenure = np.random.randint(1, 21, n)\n",
    "\n",
    "# Segment: Determine customer segment.\n",
    "# Default is \"Mass Market\". High income customers (income > $300,000) become \"Affluent\".\n",
    "# Customers aged 60 or above have a 70% chance to be \"Retiree\", otherwise assign based on income.\n",
    "segment = []\n",
    "for a, inc in zip(age, income):\n",
    "    if a >= 60:\n",
    "        # 70% chance for older customers to be \"Retiree\"\n",
    "        if np.random.rand() < 0.7:\n",
    "            segment.append(\"Retiree\")\n",
    "        else:\n",
    "            segment.append(\"Affluent\" if inc > 300000 else \"Mass Market\")\n",
    "    else:\n",
    "        segment.append(\"Affluent\" if inc > 300000 else \"Mass Market\")\n",
    "\n",
    "# Create the DataFrame\n",
    "df_customers = pd.DataFrame({\n",
    "    'CustomerID': customer_id,\n",
    "    'Age': age,\n",
    "    'Income': income.astype(int),\n",
    "    'Credit Score': credit_score,\n",
    "    'Tenure': tenure,\n",
    "    'Segment': segment\n",
    "})\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df_customers.to_csv(\"../data/Customers.csv\", index=False)\n",
    "\n",
    "print(\"Mock Customers data generated and saved as 'Customers.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock Transactions data generated and saved as 'Transactions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "total_customers = 10000\n",
    "\n",
    "# Ensure each customer has at least one transaction.\n",
    "base_customer_ids = np.arange(1, total_customers + 1)\n",
    "\n",
    "# Decide on extra transactions (e.g., 5000 additional transactions)\n",
    "extra_transactions = 10000\n",
    "extra_customer_ids = np.random.randint(1, total_customers + 1, extra_transactions)\n",
    "\n",
    "# Combine to get a list where every customer appears at least once.\n",
    "customer_ids = np.concatenate([base_customer_ids, extra_customer_ids])\n",
    "num_transactions = len(customer_ids)\n",
    "\n",
    "# TransactionID: Sequential IDs starting from 5001\n",
    "transaction_ids = np.arange(5001, 5001 + num_transactions)\n",
    "\n",
    "# Extensive list of products and their variations that large banks typically offer\n",
    "products = {\n",
    "    'Mortgage': ['Fixed Rate', 'Adjustable Rate', 'Interest Only', 'Reverse Mortgage'],\n",
    "    'Credit Card': ['Rewards', 'Cashback', 'Travel', 'Business', 'Secured'],\n",
    "    'Checking Account': ['Premium', 'Basic', 'Senior', 'Interest Bearing'],\n",
    "    'Savings Account': ['High Yield', 'Regular', 'Money Market', \"Children's Savings\"],\n",
    "    'Certificate of Deposit': ['1-Year', '2-Year', '5-Year', '10-Year'],\n",
    "    'Personal Loan': ['Secured', 'Unsecured', 'Debt Consolidation', 'Home Improvement'],\n",
    "    'Auto Loan': ['New Car', 'Used Car', 'Refinance', 'Lease'],\n",
    "    'Home Equity Loan': ['Fixed Rate', 'Variable Rate', 'HELOC'],\n",
    "    'Investment Account': ['Managed', 'Self-Directed', 'Robo Advisor', 'Brokerage'],\n",
    "    'Business Loan': ['Term Loan', 'Line of Credit', 'SBA Loan', 'Equipment Financing'],\n",
    "    'Retirement Account': ['IRA', '401K', 'Roth IRA', 'Simple IRA'],\n",
    "    'Student Loan': ['Federal', 'Private', 'Refinance', 'Consolidation']\n",
    "}\n",
    "\n",
    "# List of product names for random selection\n",
    "product_list = list(products.keys())\n",
    "chosen_products = np.random.choice(product_list, num_transactions)\n",
    "variations = [np.random.choice(products[prod]) for prod in chosen_products]\n",
    "\n",
    "# Generate random dates between 2020-01-01 and 2025-03-31\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2025, 3, 31)\n",
    "days_range = (end_date - start_date).days\n",
    "random_days = np.random.randint(0, days_range + 1, num_transactions)\n",
    "dates = [start_date + timedelta(days=int(day)) for day in random_days]\n",
    "# Format dates as MM/DD/YYYY (e.g., \"08/04/2020\")\n",
    "formatted_dates = [d.strftime(\"%m/%d/%Y\") for d in dates]\n",
    "\n",
    "# Create the DataFrame\n",
    "df_transactions = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'CustomerID': customer_ids,\n",
    "    'Product': chosen_products,\n",
    "    'Variation': variations,\n",
    "    'Date': formatted_dates\n",
    "})\n",
    "\n",
    "# Ensure Date column is explicitly string\n",
    "df_transactions['Date'] = df_transactions['Date'].astype(str)\n",
    "\n",
    "# Save to CSV with all fields quoted so that formatting is preserved\n",
    "df_transactions.to_csv(\"../data/Transactions.csv\", index=False, quoting=csv.QUOTE_ALL)\n",
    "print(\"Mock Transactions data generated and saved as 'Transactions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified mock Transactions data generated and saved as 'Transactions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "total_customers = 10000\n",
    "\n",
    "# Ensure each customer has at least one transaction.\n",
    "base_customer_ids = np.arange(1, total_customers + 1)\n",
    "extra_transactions = 10000  # Increase extra transactions if needed\n",
    "extra_customer_ids = np.random.randint(1, total_customers + 1, extra_transactions)\n",
    "customer_ids = np.concatenate([base_customer_ids, extra_customer_ids])\n",
    "num_transactions = len(customer_ids)\n",
    "\n",
    "# TransactionID: Sequential IDs starting from 5001\n",
    "transaction_ids = np.arange(5001, 5001 + num_transactions)\n",
    "\n",
    "# Original products dictionary with variations\n",
    "products = {\n",
    "    'Mortgage': ['Fixed Rate', 'Adjustable Rate', 'Hybrid Rate', 'Interest Only', 'Balloon Payment', 'Reverse Mortgage'],\n",
    "    'Credit Card': ['Rewards', 'Cashback', 'Travel', 'Business', 'Student', 'Secured', 'Balance Transfer'],\n",
    "    'Checking Account': ['Premium', 'Basic', 'Student', 'Senior', 'Interest Bearing'],\n",
    "    'Savings Account': ['High Yield', 'Regular', 'Money Market', \"Children's Savings\"],\n",
    "    'Certificate of Deposit': ['3-Month', '6-Month', '1-Year', '2-Year', '5-Year', '10-Year'],\n",
    "    'Personal Loan': ['Secured', 'Unsecured', 'Debt Consolidation', 'Home Improvement'],\n",
    "    'Auto Loan': ['New Car', 'Used Car', 'Refinance', 'Lease'],\n",
    "    'Home Equity Loan': ['Fixed Rate', 'Variable Rate', 'HELOC'],\n",
    "    'Investment Account': ['Managed', 'Self-Directed', 'Robo Advisor', 'Brokerage'],\n",
    "    'Business Loan': ['Term Loan', 'Line of Credit', 'SBA Loan', 'Equipment Financing'],\n",
    "    'Retirement Account': ['IRA', '401K', 'Roth IRA', 'SEP IRA', 'Simple IRA'],\n",
    "    'Student Loan': ['Federal', 'Private', 'Refinance', 'Consolidation']\n",
    "}\n",
    "\n",
    "# Define three product groups (fewer combinations per customer)\n",
    "group1 = ['Mortgage', 'Credit Card', 'Business Loan']\n",
    "group2 = ['Checking Account', 'Savings Account', 'Certificate of Deposit', 'Personal Loan']\n",
    "group3 = ['Auto Loan', 'Home Equity Loan', 'Investment Account', 'Retirement Account', 'Student Loan']\n",
    "\n",
    "groups = {1: group1, 2: group2, 3: group3}\n",
    "all_products = group1 + group2 + group3  # complete list of products\n",
    "\n",
    "# Assign each customer to one group at random\n",
    "customer_group = {}\n",
    "for cid in range(1, total_customers + 1):\n",
    "    customer_group[cid] = np.random.choice([1, 2, 3])\n",
    "\n",
    "# Generate chosen_products for each transaction:\n",
    "# With 80% probability, choose from the customer's group.\n",
    "chosen_products = []\n",
    "expanded_customer_ids = []\n",
    "\n",
    "for cid in customer_ids:\n",
    "    if np.random.rand() < 0.9:\n",
    "        n_products = np.random.choice([2, 3], p=[0.7, 0.3])\n",
    "        prods = np.random.choice(groups[customer_group[cid]], size=n_products, replace=False)\n",
    "        chosen_products.extend(prods)\n",
    "        expanded_customer_ids.extend([cid] * n_products)\n",
    "    else:\n",
    "        prod = np.random.choice(all_products)\n",
    "        chosen_products.append(prod)\n",
    "        expanded_customer_ids.append(cid)\n",
    "\n",
    "# Now they match\n",
    "assert len(expanded_customer_ids) == len(chosen_products)\n",
    "\n",
    "# TransactionID\n",
    "transaction_ids = np.arange(5001, 5001 + len(expanded_customer_ids))\n",
    "\n",
    "# Variations\n",
    "chosen_variations = [np.random.choice(products[prod]) for prod in chosen_products]\n",
    "\n",
    "# Dates\n",
    "random_days = np.random.randint(0, days_range + 1, len(expanded_customer_ids))\n",
    "dates = [start_date + timedelta(days=int(day)) for day in random_days]\n",
    "formatted_dates = [d.strftime(\"%m/%d/%Y\") for d in dates]\n",
    "\n",
    "# Final DataFrame\n",
    "df_transactions = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'CustomerID': expanded_customer_ids,\n",
    "    'Product': chosen_products,\n",
    "    'Variation': chosen_variations,\n",
    "    'Date': formatted_dates\n",
    "})\n",
    "\n",
    "# Save\n",
    "df_transactions['Date'] = df_transactions['Date'].astype(str)\n",
    "df_transactions.to_csv(\"../data/Transactions.csv\", index=False, quoting=csv.QUOTE_ALL)\n",
    "print(\"Modified mock Transactions data generated and saved as 'Transactions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductVariationRatings.csv generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Transactions data\n",
    "df_transactions = pd.read_csv(\"../data/Transactions.csv\")\n",
    "\n",
    "# Generate a rating between 1.0 to 5.0 with slight skew toward higher values\n",
    "# We'll use a clipped normal distribution\n",
    "ratings = np.random.normal(loc=4.0, scale=0.7, size=len(df_transactions))\n",
    "ratings = np.clip(ratings, 1.0, 5.0)\n",
    "ratings = np.round(ratings, 1)\n",
    "\n",
    "# Create the new DataFrame\n",
    "df_ratings = df_transactions.copy()\n",
    "df_ratings = df_ratings.drop(columns=[\"Date\"])  # Remove Date\n",
    "df_ratings[\"Rating\"] = ratings  # Add Rating column\n",
    "\n",
    "# Save to CSV\n",
    "df_ratings.to_csv(\"../data/ProductVariationRatings.csv\", index=False, quoting=1)  # quoting=1 = csv.QUOTE_ALL\n",
    "print(\"ProductVariationRatings.csv generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions Data Sample:\n",
      "   TransactionID  CustomerID             Product         Variation        Date\n",
      "0           5001           1         Credit Card  Balance Transfer  04/30/2020\n",
      "1           5002           1            Mortgage  Reverse Mortgage  11/15/2021\n",
      "2           5003           2  Retirement Account           SEP IRA  04/12/2023\n",
      "3           5004           2  Investment Account     Self-Directed  09/09/2023\n",
      "4           5005           3         Credit Card           Rewards  03/28/2025\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Transactions data\n",
    "df_transactions = pd.read_csv(\"../data/Transactions.csv\")\n",
    "\n",
    "# Take a quick look at the data\n",
    "print(\"Transactions Data Sample:\")\n",
    "print(df_transactions.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basket Sample:\n",
      "<bound method NDFrame.head of       CustomerID                                            Product\n",
      "0              1                            [Mortgage, Credit Card]\n",
      "1              2  [Investment Account, Auto Loan, Home Equity Lo...\n",
      "2              3             [Business Loan, Mortgage, Credit Card]\n",
      "3              4             [Business Loan, Mortgage, Credit Card]\n",
      "4              5             [Business Loan, Mortgage, Credit Card]\n",
      "...          ...                                                ...\n",
      "9995        9996             [Investment Account, Home Equity Loan]\n",
      "9996        9997  [Mortgage, Savings Account, Home Equity Loan, ...\n",
      "9997        9998                          [Business Loan, Mortgage]\n",
      "9998        9999  [Business Loan, Mortgage, Credit Card, Home Eq...\n",
      "9999       10000             [Business Loan, Mortgage, Credit Card]\n",
      "\n",
      "[10000 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Group transactions by CustomerID and aggregate unique products into a list (basket)\n",
    "basket = df_transactions.groupby('CustomerID')['Product'] \\\n",
    "                          .apply(lambda x: list(set(x))) \\\n",
    "                          .reset_index()\n",
    "\n",
    "print(\"\\nBasket Sample:\")\n",
    "print(basket.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-Hot Encoded Basket Sample:\n",
      "   CustomerID  Auto Loan  Business Loan  Certificate of Deposit  \\\n",
      "0           1      False          False                   False   \n",
      "1           2       True          False                   False   \n",
      "2           3      False           True                   False   \n",
      "3           4      False           True                   False   \n",
      "4           5      False           True                   False   \n",
      "\n",
      "   Checking Account  Credit Card  Home Equity Loan  Investment Account  \\\n",
      "0             False         True             False               False   \n",
      "1             False        False              True                True   \n",
      "2             False         True             False               False   \n",
      "3             False         True             False               False   \n",
      "4             False         True             False               False   \n",
      "\n",
      "   Mortgage  Personal Loan  Retirement Account  Savings Account  Student Loan  \n",
      "0      True          False               False            False         False  \n",
      "1     False          False                True            False         False  \n",
      "2      True          False               False            False         False  \n",
      "3      True          False               False            False         False  \n",
      "4      True          False               False            False         False  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Transform the basket list into one-hot encoded format\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(basket['Product']).transform(basket['Product'])\n",
    "df_basket = pd.DataFrame(te_array, columns=te.columns_, index=basket['CustomerID'])\n",
    "df_basket.reset_index(inplace=True)  # Optionally keep CustomerID as a column\n",
    "\n",
    "print(\"\\nOne-Hot Encoded Basket Sample:\")\n",
    "print(df_basket.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets Sample:\n",
      "    support                                           itemsets\n",
      "0    0.2214                                        (Auto Loan)\n",
      "1    0.2901                                    (Business Loan)\n",
      "2    0.2590                           (Certificate of Deposit)\n",
      "3    0.2481                                 (Checking Account)\n",
      "4    0.2869                                      (Credit Card)\n",
      "..      ...                                                ...\n",
      "92   0.0591  (Auto Loan, Student Loan, Retirement Account, ...\n",
      "93   0.0578  (Investment Account, Auto Loan, Student Loan, ...\n",
      "94   0.0964  (Certificate of Deposit, Checking Account, Per...\n",
      "95   0.0574  (Investment Account, Home Equity Loan, Student...\n",
      "96   0.0406  (Investment Account, Student Loan, Retirement ...\n",
      "\n",
      "[97 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Drop CustomerID from the one-hot encoded DataFrame since it's not needed for Apriori\n",
    "df_onehot = df_basket.drop(columns=['CustomerID'])\n",
    "\n",
    "# Run the Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df_onehot, min_support=0.005, use_colnames=True)\n",
    "\n",
    "print(\"\\nFrequent Itemsets Sample:\")\n",
    "print(frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules from the frequent itemsets\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "# print(\"\\nAssociation Rules Sample:\")\n",
    "# print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "rules = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sets to lists so they can be JSON-serialized\n",
    "rules_clean = rules.copy()\n",
    "rules_clean['antecedents'] = rules_clean['antecedents'].apply(list)\n",
    "rules_clean['consequents'] = rules_clean['consequents'].apply(list)\n",
    "\n",
    "# Save as JSON Lines\n",
    "rules_clean.to_json(\"../data/rules.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Similar Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load JSON lines\n",
    "rules = pd.read_json(\"../data/rules.json\", lines=True)\n",
    "\n",
    "# Convert antecedents/consequents back to sets\n",
    "rules['antecedents'] = rules['antecedents'].apply(set)\n",
    "rules['consequents'] = rules['consequents'].apply(set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_next_products(customer_products, rules_df, min_conf, min_lift):\n",
    "    recommendations = set()\n",
    "    for _, row in rules_df.iterrows():\n",
    "        antecedent = list(row['antecedents'])\n",
    "        consequent = list(row['consequents'])\n",
    "        if set(antecedent).issubset(set(customer_products)) and row['confidence'] >= min_conf and row['lift'] >= min_lift:\n",
    "            recommendations.update(consequent)\n",
    "    return list(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_customer_similarity(customers_df):\n",
    "    # Select numeric and categorical features\n",
    "    numeric_cols = ['Age', 'Income', 'Credit Score', 'Tenure']\n",
    "    categorical_col = ['Segment']\n",
    "    \n",
    "    # Normalize numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    numeric_scaled = scaler.fit_transform(customers_df[numeric_cols])\n",
    "    \n",
    "    # One-hot encode Segment\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    segment_encoded = encoder.fit_transform(customers_df[categorical_col])\n",
    "    \n",
    "    # Combine features into single vector\n",
    "    combined_features = np.hstack((numeric_scaled, segment_encoded))\n",
    "    \n",
    "    # Compute cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(combined_features)\n",
    "    \n",
    "    # Return as DataFrame with CustomerID as index/columns\n",
    "    sim_df = pd.DataFrame(similarity_matrix, \n",
    "                          index=customers_df['CustomerID'], \n",
    "                          columns=customers_df['CustomerID'])\n",
    "    return sim_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Customer 200 has Mortgage. We recommend Credit Card. Now find best Credit Card variation\n",
    "\n",
    "# Load the Customers.csv first\n",
    "customers_df = pd.read_csv(\"../data/Customers.csv\")\n",
    "\n",
    "# Compute cosine similarity between all customers using their attributes\n",
    "sim_df = compute_customer_similarity(customers_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test set with 100 customers and their main product saved as 'customer_test.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the real data from the data folder\n",
    "df_customers = pd.read_csv(\"../data/Customers.csv\")\n",
    "df_transactions = pd.read_csv(\"../data/Transactions.csv\")\n",
    "\n",
    "# Get each customer's first product (sorted by transaction ID or date)\n",
    "df_first_product = df_transactions.sort_values(by=\"TransactionID\").groupby(\"CustomerID\").first().reset_index()\n",
    "df_first_product = df_first_product[['CustomerID', 'Product']]\n",
    "df_first_product.rename(columns={'Product': 'MainProduct'}, inplace=True)\n",
    "\n",
    "# Merge with customers\n",
    "df_customer_test = pd.merge(df_customers, df_first_product, on=\"CustomerID\", how=\"inner\")\n",
    "\n",
    "# Take any 100 customers for the test set\n",
    "df_customer_test = df_customer_test.sample(n=100, random_state=42)\n",
    "\n",
    "# Save to CSV\n",
    "df_customer_test.to_csv(\"../data/customer_test.csv\", index=False)\n",
    "\n",
    "print(\"✅ Test set with 100 customers and their main product saved as 'customer_test.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend Product variation based on Similar Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_variation_with_customer_similarity(customer_id, product, df_ratings, sim_df, top_n_similar_users=10):\n",
    "    if customer_id not in sim_df.index:\n",
    "        return None\n",
    "\n",
    "    # Get most similar customers\n",
    "    similar_customers = sim_df.loc[customer_id].sort_values(ascending=False)\n",
    "    similar_customers = similar_customers.drop(index=customer_id).head(top_n_similar_users).index.tolist()\n",
    "\n",
    "    # Filter ratings by these similar customers for the product\n",
    "    similar_ratings = df_ratings[(df_ratings['CustomerID'].isin(similar_customers)) &\n",
    "                                 (df_ratings['Product'] == product)]\n",
    "\n",
    "    if similar_ratings.empty:\n",
    "        return None\n",
    "\n",
    "    # Get highest-rated variation\n",
    "    top_variation = (similar_ratings.groupby('Variation')['Rating']\n",
    "                     .mean()\n",
    "                     .sort_values(ascending=False)\n",
    "                     .idxmax())\n",
    "    return top_variation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reverse Mortgage'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_variation_with_customer_similarity(\n",
    "    customer_id=1, \n",
    "    product=\"Mortgage\", \n",
    "    df_ratings=df_ratings, \n",
    "    sim_df=sim_df,top_n_similar_users=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_recommendation(customer_id, df_transactions, rules_df, df_ratings, sim_df, min_conf, min_lift):\n",
    "    # Step 1: Find what the customer already has\n",
    "    customer_products = df_transactions[df_transactions['CustomerID'] == customer_id]['Product'].unique().tolist()\n",
    "    \n",
    "    # Step 2: Get recommended products using Apriori rules\n",
    "    recommended_products = recommend_next_products(customer_products, rules_df, min_conf, min_lift)\n",
    "\n",
    "    # Step 3: Recommend best variation using customer-based similarity\n",
    "    recommendations = []\n",
    "    for prod in recommended_products:\n",
    "        best_variation = recommend_variation_with_customer_similarity(\n",
    "            customer_id, prod, df_ratings, sim_df, 10\n",
    "        )\n",
    "        recommendations.append({\n",
    "            'Product': prod,\n",
    "            'Variation': best_variation or \"Default\"\n",
    "        })\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investment Account</td>\n",
       "      <td>Robo Advisor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student Loan</td>\n",
       "      <td>Consolidation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retirement Account</td>\n",
       "      <td>Simple IRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home Equity Loan</td>\n",
       "      <td>Fixed Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto Loan</td>\n",
       "      <td>Refinance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Product      Variation\n",
       "0  Investment Account   Robo Advisor\n",
       "1        Student Loan  Consolidation\n",
       "2  Retirement Account     Simple IRA\n",
       "3    Home Equity Loan     Fixed Rate\n",
       "4           Auto Loan      Refinance"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions = pd.read_csv(\"../data/Transactions.csv\")\n",
    "# rules = pd.read_csv(\"../data/rules.csv\")  # assuming you've saved your Apriori rules\n",
    "\n",
    "recos = full_recommendation(\n",
    "    customer_id=6,\n",
    "    df_transactions=df_transactions,\n",
    "    rules_df=rules,\n",
    "    df_ratings=df_ratings,\n",
    "    sim_df=sim_df, min_conf=0.6, min_lift=2\n",
    ")\n",
    "\n",
    "pd.DataFrame(recos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
