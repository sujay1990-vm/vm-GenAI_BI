{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.7)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikeras 0.4.1 requires packaging<22.0,>=0.21, but you have packaging 23.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (2.2.3)\n",
      "Collecting scikit-learn>=1.3.1 (from mlxtend)\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (3.9.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.28.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Collecting joblib>=0.13.2 (from mlxtend)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 1.4/1.4 MB 23.2 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 11.1/11.1 MB 18.8 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib, scikit-learn, mlxtend\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "  Attempting uninstall: mlxtend\n",
      "    Found existing installation: mlxtend 0.1.7\n",
      "    Uninstalling mlxtend-0.1.7:\n",
      "      Successfully uninstalled mlxtend-0.1.7\n",
      "Successfully installed joblib-1.4.2 mlxtend-0.23.4 scikit-learn-1.6.1\n"
     ]
    }
   ],
   "source": [
    "! py -m pip install mlxtend --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Random.randint() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m dob \u001b[38;5;241m=\u001b[39m fake\u001b[38;5;241m.\u001b[39mdate_of_birth(minimum_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m, maximum_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m75\u001b[39m)\n\u001b[0;32m     24\u001b[0m age \u001b[38;5;241m=\u001b[39m (datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mdate() \u001b[38;5;241m-\u001b[39m dob)\u001b[38;5;241m.\u001b[39mdays \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m365\u001b[39m\n\u001b[1;32m---> 25\u001b[0m income \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m credit_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mclip(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m \u001b[38;5;241m+\u001b[39m (income \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m), scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m), \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m850\u001b[39m))\n\u001b[0;32m     28\u001b[0m customer_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUST\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst_Name\u001b[39m\u001b[38;5;124m\"\u001b[39m: first_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCredit_Score\u001b[39m\u001b[38;5;124m\"\u001b[39m: credit_score\n\u001b[0;32m     44\u001b[0m })\n",
      "\u001b[1;31mTypeError\u001b[0m: Random.randint() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Setup\n",
    "fake = Faker()\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# -----------------------\n",
    "# 1. Generate Customers\n",
    "# -----------------------\n",
    "num_customers = 100\n",
    "customer_data = []\n",
    "\n",
    "for i in range(1, num_customers + 1):\n",
    "    is_male = random.choice([True, False])\n",
    "    first_name = fake.first_name_male() if is_male else fake.first_name_female()\n",
    "    last_name = fake.last_name()\n",
    "    gender = 'M' if is_male else 'F'\n",
    "    dob = fake.date_of_birth(minimum_age=18, maximum_age=75)\n",
    "    age = (datetime.now().date() - dob).days // 365\n",
    "    income = random.randint(20000, 150000)\n",
    "    credit_score = int(np.clip(np.random.normal(loc=600 + (income / 1000), scale=50), 300, 850))\n",
    "\n",
    "    customer_data.append({\n",
    "        \"Customer_ID\": f\"CUST{i:04d}\",\n",
    "        \"First_Name\": first_name,\n",
    "        \"Last_Name\": last_name,\n",
    "        \"Gender\": gender,\n",
    "        \"Date_of_Birth\": dob,\n",
    "        \"Age\": age,\n",
    "        \"Email\": fake.email(),\n",
    "        \"Phone\": fake.phone_number(),\n",
    "        \"Address\": fake.address().replace(\"\\n\", \", \"),\n",
    "        \"City\": fake.city(),\n",
    "        \"State\": fake.state(),\n",
    "        \"Postal_Code\": fake.postcode(),\n",
    "        \"Country\": \"USA\",\n",
    "        \"Annual_Income\": income,\n",
    "        \"Credit_Score\": credit_score\n",
    "    })\n",
    "\n",
    "df_customers = pd.DataFrame(customer_data)\n",
    "df_customers.to_csv(\"customers.csv\", index=False)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Generate Transactions\n",
    "# ----------------------------\n",
    "transaction_data = []\n",
    "categories = ['Grocery', 'Fuel', 'Dining', 'Travel', 'Medical', 'Baby', 'Education', 'Entertainment', 'Home', 'Salary']\n",
    "merchants = {\n",
    "    'Grocery': ['Walmart', 'Whole Foods', 'Kroger'],\n",
    "    'Fuel': ['Shell', 'Exxon', 'Chevron'],\n",
    "    'Dining': ['McDonald\\'s', 'Starbucks', 'Chipotle'],\n",
    "    'Travel': ['Delta', 'Airbnb', 'Uber'],\n",
    "    'Medical': ['CVS', 'Walgreens', 'Urgent Care'],\n",
    "    'Baby': ['BabyGap', 'Target', 'Pampers Store'],\n",
    "    'Education': ['Coursera', 'Udemy', 'University Bookstore'],\n",
    "    'Entertainment': ['Netflix', 'AMC Theatres', 'Spotify'],\n",
    "    'Home': ['Home Depot', 'Lowe\\'s', 'IKEA'],\n",
    "    'Salary': ['Company Payroll', 'Direct Deposit']\n",
    "}\n",
    "\n",
    "txn_id = 1\n",
    "for customer in df_customers['Customer_ID']:\n",
    "    num_txns = random.randint(5, 15)\n",
    "    for _ in range(num_txns):\n",
    "        category = random.choice(categories)\n",
    "        merchant = random.choice(merchants[category])\n",
    "        amount = round(random.uniform(10, 2000) if category != 'Salary' else random.uniform(3000, 10000), 2)\n",
    "        date = datetime.now() - timedelta(days=random.randint(0, 28))\n",
    "        \n",
    "        transaction_data.append({\n",
    "            \"Transaction_ID\": f\"TXN{txn_id:06d}\",\n",
    "            \"Customer_ID\": customer,\n",
    "            \"Timestamp\": date.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"Merchant\": merchant,\n",
    "            \"Category\": category,\n",
    "            \"Amount\": amount,\n",
    "            \"Description\": f\"{category} - {merchant}\"\n",
    "        })\n",
    "        txn_id += 1\n",
    "\n",
    "df_transactions = pd.DataFrame(transaction_data)\n",
    "df_transactions.to_csv(\"transactions.csv\", index=False)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Generate Product Table\n",
    "# -------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSVs\n",
    "df_customers = pd.read_csv(\"customers.csv\")\n",
    "df_transactions = pd.read_csv(\"transactions.csv\")\n",
    "\n",
    "# Ensure timestamp is in datetime format\n",
    "df_transactions[\"Timestamp\"] = pd.to_datetime(df_transactions[\"Timestamp\"])\n",
    "\n",
    "# Filter only last 4 weeks of transactions\n",
    "latest_date = df_transactions[\"Timestamp\"].max()\n",
    "cutoff_date = latest_date - pd.Timedelta(days=28)\n",
    "df_recent = df_transactions[df_transactions[\"Timestamp\"] >= cutoff_date]\n",
    "\n",
    "# Aggregate features per customer\n",
    "features = df_recent.groupby(\"Customer_ID\").agg(\n",
    "    Total_Spend=(\"Amount\", \"sum\"),\n",
    "    Num_Transactions=(\"Transaction_ID\", \"count\"),\n",
    "    Avg_Txn_Amount=(\"Amount\", \"mean\"),\n",
    "    Max_Txn_Amount=(\"Amount\", \"max\"),\n",
    "    Has_Salary_Credit=(\"Category\", lambda x: int(\"Salary\" in x.values))\n",
    ").reset_index()\n",
    "\n",
    "# Pivot category spend into separate columns\n",
    "category_spend = df_recent.pivot_table(\n",
    "    index=\"Customer_ID\",\n",
    "    columns=\"Category\",\n",
    "    values=\"Amount\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    ").add_prefix(\"Spend_\").reset_index()\n",
    "\n",
    "# Merge with customer demographics\n",
    "df_feature_store = (\n",
    "    features\n",
    "    .merge(category_spend, on=\"Customer_ID\", how=\"left\")\n",
    "    .merge(df_customers[[\"Customer_ID\", \"Age\", \"Annual_Income\", \"Credit_Score\"]], on=\"Customer_ID\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "df_feature_store.to_csv(\"feature_store.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ products.csv created with structured eligibility columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Full product list with detailed columns, plus structured eligibility fields\n",
    "products = [\n",
    "    # Product_ID, Name, Type, Tier,\n",
    "    # Features_Benefits, Target_Behavior, Special_Offer,\n",
    "    # min_age, min_income, min_credit_score\n",
    "    (\"P001\", \"Starter Credit Card\", \"Credit Card\", \"Low\",\n",
    "     \"1% cashback on all purchases\",\n",
    "     \"New credit users, low spenders\",\n",
    "     \"USD 25 cashback on first USD 300 spend\",\n",
    "     None,       20000, 600),\n",
    "    (\"P002\", \"Everyday Saver\", \"Savings Account\", \"Low\",\n",
    "     \"4% interest, no maintenance fees\",\n",
    "     \"Customers starting savings\",\n",
    "     \"USD 50 bonus for maintaining USD 1,000 balance for 3 months\",\n",
    "     None,       100,   None),\n",
    "    (\"P003\", \"Smart Shopper Card\", \"Credit Card\", \"Mid\",\n",
    "     \"2% cashback on groceries & fuel\",\n",
    "     \"High grocery and fuel spenders\",\n",
    "     \"USD 50 cashback on first USD 500 spend\",\n",
    "     None,       30000, 650),\n",
    "    (\"P004\", \"Smart Budget Account\", \"Savings + Budget\", \"Mid\",\n",
    "     \"5% APY on goal-based savings\",\n",
    "     \"Budget-conscious savers\",\n",
    "     \"Free premium budgeting tools for 6 months\",\n",
    "     None,       25000, None),\n",
    "    (\"P005\", \"Travel Rewards Elite\", \"Credit Card\", \"High\",\n",
    "     \"3x travel points, lounge access\",\n",
    "     \"Frequent travelers\",\n",
    "     \"USD 200 travel voucher after USD 5,000 spend\",\n",
    "     None,       70000, 700),\n",
    "    (\"P006\", \"Elite Wealth Plan\", \"Investment\", \"High\",\n",
    "     \"6–8% ROI, personal wealth advisor\",\n",
    "     \"High-income professionals\",\n",
    "     \"1% bonus returns for first year\",\n",
    "     30,         100000, None),\n",
    "    (\"P007\", \"Family Future Plan\", \"Insurance/Savings\", \"Mid-High\",\n",
    "     \"Child savings + life insurance combo\",\n",
    "     \"Families, new parents\",\n",
    "     \"USD 100 bonus on first-year premium\",\n",
    "     25,         None,   None),\n",
    "    (\"P008\", \"Student Flex Account\", \"Savings\", \"Student\",\n",
    "     \"No fees, education budgeting tools\",\n",
    "     \"Students under 25\",\n",
    "     \"USD 100 top-up on monthly deposits over USD 200\",\n",
    "     None,       None,   None),  # eligibility purely age<25\n",
    "    (\"P009\", \"Home Advantage Loan\", \"Loan\", \"Mid-High\",\n",
    "     \"Low-interest home loans\",\n",
    "     \"First-time home buyers\",\n",
    "     \"Reduced interest rate for bundled insurance\",\n",
    "     None,       None,   None),\n",
    "    (\"P010\", \"Retirement Essentials\", \"Wealth + Health\", \"Senior\",\n",
    "     \"Pension fund + health perks\",\n",
    "     \"Customers over 60\",\n",
    "     \"USD 500 wellness bonus for first year\",\n",
    "     60,         None,   None),\n",
    "    (\"P011\", \"FlexFuel Card\", \"Credit Card\", \"Low-Mid\",\n",
    "     \"3% cashback on fuel\",\n",
    "     \"Regular commuters\",\n",
    "     \"USD 50 fuel voucher after USD 500 spend\",\n",
    "     None,       None,   None),\n",
    "    (\"P012\", \"Digital Nomad Saver\", \"Savings Account\", \"Mid\",\n",
    "     \"1.5% bonus APY for international use\",\n",
    "     \"Frequent travelers, remote workers\",\n",
    "     \"No international transfer fees for 6 months\",\n",
    "     None,       None,   None),\n",
    "    (\"P013\", \"HealthSecure Plan\", \"Health + Savings\", \"Mid\",\n",
    "     \"HSA integration, telehealth access\",\n",
    "     \"Health-conscious individuals\",\n",
    "     \"USD 200 credit toward medical expenses\",\n",
    "     None,       None,   None),\n",
    "    (\"P014\", \"GreenLife Investment\", \"ESG Investment\", \"Mid-High\",\n",
    "     \"5–9% returns in sustainable funds\",\n",
    "     \"Eco-conscious investors\",\n",
    "     \"USD 100 green bonus + 0.5% bonus returns\",\n",
    "     None,       40000,  None),\n",
    "    (\"P015\", \"Weekend Explorer Card\", \"Credit Card\", \"Mid\",\n",
    "     \"2.5% cashback on dining & entertainment\",\n",
    "     \"Social and active lifestyle\",\n",
    "     \"Free concert ticket after USD 2,000 spend\",\n",
    "     None,       400,    None),\n",
    "    (\"P016\", \"CashBuilder Certificate\", \"CD / Fixed Deposit\", \"Low-Mid\",\n",
    "     \"4.75% fixed interest (6 months)\",\n",
    "     \"Idle balance savers\",\n",
    "     \"USD 25 bonus for auto-renewal\",\n",
    "     None,       5000,   None),\n",
    "    (\"P017\", \"Lifestyle Bundle Plus\", \"Bundle (3-in-1)\", \"High\",\n",
    "     \"Credit + Wealth + Travel perks\",\n",
    "     \"Affluent, multi-product users\",\n",
    "     \"USD 300 statement credit + concierge onboarding\",\n",
    "     None,       100000, None),\n",
    "    (\"P018\", \"BabyStart Trust Plan\", \"Child Investment\", \"Mid\",\n",
    "     \"Custodial account for education\",\n",
    "     \"Parents with young children\",\n",
    "     \"1st-year fees waived + USD 100 education bonus\",\n",
    "     None,       None,   None),\n",
    "    (\"P019\", \"MoveSmart Relocation Loan\", \"Loan\", \"Mid\",\n",
    "     \"0% for 6 months, flexible repayment\",\n",
    "     \"Customers with large recent spends\",\n",
    "     \"USD 150 moving voucher\",\n",
    "     None,       5000,   None),\n",
    "    (\"P020\", \"SideHustle Account\", \"Business Checking\", \"Low-Mid\",\n",
    "     \"No fees, invoice management\",\n",
    "     \"Freelancers, side businesses\",\n",
    "     \"USD 75 bonus for linking payment gateway\",\n",
    "     None,       None,   None),\n",
    "]\n",
    "\n",
    "# Create DataFrame with the new structured columns\n",
    "columns = [\n",
    "    \"Product_ID\", \"Product_Name\", \"Product_Type\", \"Tier\",\n",
    "    \"Features_Benefits\", \"Target_Behavior\", \"Special_Offer\",\n",
    "    \"min_age\", \"min_income\", \"min_credit_score\"\n",
    "]\n",
    "\n",
    "df_products = pd.DataFrame(products, columns=columns)\n",
    "\n",
    "# Save to CSV (or load into your DB directly)\n",
    "df_products.to_csv(\"products.csv\", index=False)\n",
    "print(\"✅ products.csv created with structured eligibility columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enhanced feature_store_enhanced.csv created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df_transactions = pd.read_csv(\"transactions.csv\")\n",
    "df_customers = pd.read_csv(\"customers.csv\")\n",
    "df_feature_store = pd.read_csv(\"feature_store.csv\")\n",
    "\n",
    "# Ensure Timestamp is datetime\n",
    "df_transactions[\"Timestamp\"] = pd.to_datetime(df_transactions[\"Timestamp\"])\n",
    "\n",
    "# 1️⃣ Calculate Aggregation_Days per customer\n",
    "agg_days = df_transactions.groupby(\"Customer_ID\").agg(\n",
    "    First_Txn_Date=(\"Timestamp\", \"min\"),\n",
    "    Last_Txn_Date=(\"Timestamp\", \"max\")\n",
    ")\n",
    "agg_days[\"Aggregation_Days\"] = (agg_days[\"Last_Txn_Date\"] - agg_days[\"First_Txn_Date\"]).dt.days + 1\n",
    "agg_days = agg_days[[\"Aggregation_Days\"]].reset_index()\n",
    "\n",
    "# 2️⃣ Calculate Spend Variability (std deviation of Amount)\n",
    "spend_var = df_transactions.groupby(\"Customer_ID\").agg(\n",
    "    Spend_Variability=(\"Amount\", \"std\")\n",
    ").fillna(0).reset_index()\n",
    "\n",
    "# 3️⃣ Calculate Salary_to_Spend_Ratio\n",
    "salary_spend = df_transactions.groupby([\"Customer_ID\", \"Category\"]).agg(Total_Category_Spend=(\"Amount\", \"sum\")).reset_index()\n",
    "salary = salary_spend[salary_spend[\"Category\"] == \"Salary\"][[\"Customer_ID\", \"Total_Category_Spend\"]].rename(columns={\"Total_Category_Spend\": \"Total_Salary\"})\n",
    "total_spend = df_feature_store[[\"Customer_ID\", \"Total_Spend\"]]\n",
    "\n",
    "salary_ratio = pd.merge(total_spend, salary, on=\"Customer_ID\", how=\"left\").fillna(0)\n",
    "salary_ratio[\"Salary_to_Spend_Ratio\"] = salary_ratio[\"Total_Salary\"] / salary_ratio[\"Total_Spend\"]\n",
    "salary_ratio = salary_ratio[[\"Customer_ID\", \"Salary_to_Spend_Ratio\"]]\n",
    "\n",
    "# 4️⃣ Top Spend Category\n",
    "top_category = df_transactions[df_transactions[\"Category\"] != \"Salary\"].groupby([\"Customer_ID\", \"Category\"]).agg(\n",
    "    Category_Spend=(\"Amount\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "top_spend_cat = top_category.loc[top_category.groupby(\"Customer_ID\")[\"Category_Spend\"].idxmax()]\n",
    "top_spend_cat = top_spend_cat[[\"Customer_ID\", \"Category\"]].rename(columns={\"Category\": \"Top_Spend_Category\"})\n",
    "\n",
    "# 5️⃣ Idle Balance Estimate\n",
    "income = df_customers[[\"Customer_ID\", \"Annual_Income\"]]\n",
    "idle_balance = pd.merge(total_spend, income, on=\"Customer_ID\", how=\"left\")\n",
    "idle_balance[\"Idle_Balance_Estimate\"] = idle_balance[\"Annual_Income\"] - idle_balance[\"Total_Spend\"]\n",
    "idle_balance = idle_balance[[\"Customer_ID\", \"Idle_Balance_Estimate\"]]\n",
    "\n",
    "# Merge all new features\n",
    "df_enhanced = df_feature_store.merge(agg_days, on=\"Customer_ID\", how=\"left\")\n",
    "df_enhanced = df_enhanced.merge(spend_var, on=\"Customer_ID\", how=\"left\")\n",
    "df_enhanced = df_enhanced.merge(salary_ratio, on=\"Customer_ID\", how=\"left\")\n",
    "df_enhanced = df_enhanced.merge(top_spend_cat, on=\"Customer_ID\", how=\"left\")\n",
    "df_enhanced = df_enhanced.merge(idle_balance, on=\"Customer_ID\", how=\"left\")\n",
    "\n",
    "# Fill any remaining NaNs\n",
    "df_enhanced = df_enhanced.fillna({\n",
    "    \"Spend_Variability\": 0,\n",
    "    \"Salary_to_Spend_Ratio\": 0,\n",
    "    \"Top_Spend_Category\": \"Unknown\",\n",
    "    \"Aggregation_Days\": 28  # Default if only 1 txn\n",
    "})\n",
    "\n",
    "# Save enhanced feature store\n",
    "df_enhanced.to_csv(\"feature_store_enhanced.csv\", index=False)\n",
    "\n",
    "print(\"✅ Enhanced feature_store_enhanced.csv created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ customer_products.csv created with Acquisition_Date in H1 2024.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load customer data and product catalog\n",
    "df_customers = pd.read_csv(\"customers.csv\")\n",
    "df_products = pd.read_csv(\"products.csv\")\n",
    "\n",
    "# Prepare list to store ownership records\n",
    "customer_products = []\n",
    "\n",
    "# Define logic-based exclusions\n",
    "def get_eligible_products(customer_row):\n",
    "    age = customer_row['Age']\n",
    "    eligible_products = df_products.copy()\n",
    "\n",
    "    # Exclude Student Account for non-students\n",
    "    if age > 25:\n",
    "        eligible_products = eligible_products[eligible_products['Product_ID'] != 'P008']\n",
    "    \n",
    "    # Exclude Retirement plan for young customers\n",
    "    if age < 55:\n",
    "        eligible_products = eligible_products[eligible_products['Product_ID'] != 'P010']\n",
    "    \n",
    "    return eligible_products['Product_ID'].tolist()\n",
    "\n",
    "# Helper to pick a random date in H1 2024\n",
    "start_date = datetime(2024, 1, 1)\n",
    "end_date   = datetime(2024, 6, 30)\n",
    "delta_days = (end_date - start_date).days\n",
    "\n",
    "def random_h1_2024_date():\n",
    "    return (start_date + timedelta(days=random.randint(0, delta_days))).date()\n",
    "\n",
    "# Generate ownership for each customer\n",
    "for _, customer in df_customers.iterrows():\n",
    "    cust_id = customer['Customer_ID']\n",
    "    \n",
    "    # Get eligible products\n",
    "    eligible_products = get_eligible_products(customer)\n",
    "    \n",
    "    # Randomly assign 1 to 3 products\n",
    "    owned_count = random.randint(1, 3)\n",
    "    owned_products = random.sample(eligible_products, owned_count)\n",
    "    \n",
    "    for prod_id in owned_products:\n",
    "        customer_products.append({\n",
    "            \"Customer_ID\": cust_id,\n",
    "            \"Product_ID\": prod_id,\n",
    "            \"Acquisition_Date\": random_h1_2024_date().isoformat()\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df_customer_products = pd.DataFrame(customer_products)\n",
    "\n",
    "# Save to CSV\n",
    "df_customer_products.to_csv(\"customer_products.csv\", index=False)\n",
    "\n",
    "print(\"✅ customer_products.csv created with Acquisition_Date in H1 2024.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded into cross_selling.db\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load CSVs\n",
    "df_customers = pd.read_csv(\"customers.csv\")\n",
    "df_transactions = pd.read_csv(\"transactions.csv\")\n",
    "df_products = pd.read_csv(\"products.csv\")\n",
    "df_feature_store = pd.read_csv(\"feature_store_enhanced.csv\")  # From earlier step\n",
    "df_customer_products = pd.read_csv(\"customer_products.csv\")  # From earlier step\n",
    "\n",
    "# Create SQLite DB\n",
    "conn = sqlite3.connect(\"cross_selling.db\")\n",
    "\n",
    "# Write tables\n",
    "df_customers.to_sql(\"customers\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"transactions\", conn, if_exists=\"replace\", index=False)\n",
    "df_products.to_sql(\"products\", conn, if_exists=\"replace\", index=False)\n",
    "df_feature_store.to_sql(\"feature_store\", conn, if_exists=\"replace\", index=False)\n",
    "df_customer_products.to_sql(\"customer_products\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "conn.close()\n",
    "print(\"✅ Data loaded into cross_selling.db\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from langchain.agents import tool\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from prompts import *\n",
    "import re\n",
    "\n",
    "conn = sqlite3.connect(\"cross_selling.db\")\n",
    "\n",
    "@tool\n",
    "def fetch_customer_profile(name: str) -> str:\n",
    "    \"\"\"Fetch basic customer profile by full name.\"\"\"\n",
    "    df = pd.read_sql(f\"SELECT * FROM customers WHERE First_Name || ' ' || Last_Name = '{name}'\", conn)\n",
    "    return df.to_json(orient=\"records\") if not df.empty else \"Customer not found.\"\n",
    "\n",
    "@tool\n",
    "def analyze_customer_behavior(customer_id: str) -> str:\n",
    "    \"\"\"Provides a detailed analysis of customer behavior, spending patterns, and financial signals.\"\"\"\n",
    "    df = pd.read_sql(f\"SELECT * FROM feature_store WHERE Customer_ID = '{customer_id}'\", conn)\n",
    "    if df.empty:\n",
    "        return \"No behavior data found for this customer.\"\n",
    "    \n",
    "    row = df.iloc[0]\n",
    "    insights = []\n",
    "\n",
    "    # 1️⃣ Aggregation Period\n",
    "    insights.append(f\"Analysis based on {row['Aggregation_Days']} days of transaction data.\")\n",
    "\n",
    "    # 2️⃣ Spending Overview\n",
    "    insights.append(f\"Total spending during this period is ${row['Total_Spend']:.2f} across {row['Num_Transactions']} transactions.\")\n",
    "    insights.append(f\"Average transaction amount is ${row['Avg_Txn_Amount']:.2f}, with a maximum single transaction of ${row['Max_Txn_Amount']:.2f}.\")\n",
    "    \n",
    "    # 3️⃣ Key Spending Categories\n",
    "    category_flags = []\n",
    "    if row.get(\"Spend_Grocery\", 0) > 500:\n",
    "        category_flags.append(f\"Grocery: ${row['Spend_Grocery']:.2f}\")\n",
    "    if row.get(\"Spend_Travel\", 0) > 800:\n",
    "        category_flags.append(f\"Travel: ${row['Spend_Travel']:.2f}\")\n",
    "    if row.get(\"Spend_Fuel\", 0) > 150:\n",
    "        category_flags.append(f\"Fuel: ${row['Spend_Fuel']:.2f}\")\n",
    "    if row.get(\"Spend_Medical\", 0) > 200:\n",
    "        category_flags.append(f\"Medical: ${row['Spend_Medical']:.2f}\")\n",
    "    if row.get(\"Spend_Entertainment\", 0) > 300:\n",
    "        category_flags.append(f\"Entertainment: ${row['Spend_Entertainment']:.2f}\")\n",
    "\n",
    "    if category_flags:\n",
    "        insights.append(\"Significant spending detected in categories: \" + \"; \".join(category_flags))\n",
    "    else:\n",
    "        insights.append(f\"Primary spending category is {row['Top_Spend_Category']}.\")\n",
    "\n",
    "    # 4️⃣ Income & Salary Patterns\n",
    "    if row[\"Has_Salary_Credit\"]:\n",
    "        insights.append(\"Regular salary deposits detected, indicating stable income.\")\n",
    "    if row[\"Salary_to_Spend_Ratio\"] > 0.5:\n",
    "        insights.append(f\"Healthy disposable income, with a Salary-to-Spend Ratio of {row['Salary_to_Spend_Ratio']:.2f}.\")\n",
    "\n",
    "    # 5️⃣ Financial Profile\n",
    "    if row[\"Annual_Income\"] > 100000:\n",
    "        insights.append(f\"High annual income: ${row['Annual_Income']}.\")\n",
    "    elif row[\"Annual_Income\"] > 60000:\n",
    "        insights.append(f\"Moderate annual income: ${row['Annual_Income']}.\")\n",
    "\n",
    "    if row[\"Credit_Score\"] >= 750:\n",
    "        insights.append(f\"Excellent credit score: {row['Credit_Score']}.\")\n",
    "    elif row[\"Credit_Score\"] >= 700:\n",
    "        insights.append(f\"Good credit score: {row['Credit_Score']}.\")\n",
    "    else:\n",
    "        insights.append(f\"Credit score is {row['Credit_Score']}.\")\n",
    "\n",
    "    # 6️⃣ Spend Variability\n",
    "    if row[\"Spend_Variability\"] > 500:\n",
    "        insights.append(f\"High variability in spending, suggesting inconsistent transaction amounts.\")\n",
    "    else:\n",
    "        insights.append(f\"Consistent spending behavior with low variability.\")\n",
    "\n",
    "    # 7️⃣ Idle Balance Potential\n",
    "    if row[\"Idle_Balance_Estimate\"] > 5000:\n",
    "        insights.append(f\"Estimated idle balance of ${row['Idle_Balance_Estimate']:.2f}, indicating potential for savings or investment products.\")\n",
    "\n",
    "    return \" | \".join(insights)\n",
    "\n",
    "@tool\n",
    "def fetch_product_catalog(dummy_input: str) -> str:\n",
    "    \"\"\"Returns the bank's product catalog for cross-selling.\"\"\"\n",
    "    df = pd.read_sql(\"SELECT * FROM products\", conn)\n",
    "    return df.to_json(orient=\"records\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def scientific_calculator(expression: str) -> str:\n",
    "    \"\"\"Performs safe scientific calculations. Provide expressions like '1250 / 28' or 'sqrt(256)'.\"\"\"\n",
    "    import math\n",
    "    allowed_names = {k: v for k, v in math.__dict__.items() if not k.startswith(\"__\")}\n",
    "    allowed_names['abs'] = abs\n",
    "\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}}, allowed_names)\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def fetch_owned_products(customer_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the list of products currently owned by the customer.\n",
    "    The LLM should avoid recommending these products again.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "            SELECT p.Product_ID, p.Product_Name, p.Product_Type\n",
    "            FROM customer_products cp\n",
    "            JOIN products p ON cp.Product_ID = p.Product_ID\n",
    "            WHERE cp.Customer_ID = '{customer_id}'\n",
    "        \"\"\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    \n",
    "    if df.empty:\n",
    "        return \"This customer does not own any products currently.\"\n",
    "    \n",
    "    # Return a readable list\n",
    "    owned_list = df[['Product_ID', 'Product_Name', 'Product_Type']].to_dict(orient='records')\n",
    "    return f\"Customer currently owns the following products: {owned_list}\"\n",
    "\n",
    "@tool\n",
    "def fetch_schema_info(dummy_input: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Returns the pre‐built SCHEMA_INFO string describing your database schema.\n",
    "    \"\"\"\n",
    "    return SCHEMA_INFO\n",
    "\n",
    "\n",
    "@tool\n",
    "def run_sql(sql_statements: str) -> str:\n",
    "    \"\"\"\n",
    "    Executes one or more semicolon-separated SQL statements against `conn`.\n",
    "    - SELECT queries: returns top 5 rows as a markdown table.\n",
    "    - Other queries: returns success/failure status.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for stmt in sql_statements.split(\";\"):\n",
    "        stmt = stmt.strip()\n",
    "        if not stmt:\n",
    "            continue\n",
    "        try:\n",
    "            if stmt.lower().startswith(\"select\"):\n",
    "                df = pd.read_sql(stmt, conn)\n",
    "                if df.empty:\n",
    "                    outputs.append(f\"✅ `{stmt}` returned no rows.\")\n",
    "                else:\n",
    "                    table = df.to_markdown(index=False)\n",
    "                    outputs.append(f\"✅ Results for `{stmt}`:\\n\\n{table}\")\n",
    "            else:\n",
    "                conn.execute(stmt)\n",
    "                conn.commit()\n",
    "                outputs.append(f\"✅ Executed `{stmt}` successfully.\")\n",
    "        except Exception as e:\n",
    "            outputs.append(f\"❌ Error executing `{stmt}`:\\n{str(e)}\")\n",
    "    return \"\\n\\n\".join(outputs)\n",
    "\n",
    "@tool\n",
    "def clean_sql_statement(raw_sql: str) -> str:\n",
    "    \"\"\"\n",
    "    Strips out markdown fences (```sql``` or ```), any leading/trailing backticks,\n",
    "    and excessive whitespace so you get a clean SQL string.\n",
    "    \"\"\"\n",
    "    # Remove opening fences like ```sql or ``` and closing ```\n",
    "    cleaned = re.sub(r\"```(?:sql)?\\s*\", \"\", raw_sql)\n",
    "    cleaned = cleaned.replace(\"```\", \"\")\n",
    "    # Collapse any multiple newlines/spaces\n",
    "    cleaned = re.sub(r\"\\s*\\n\\s*\", \" \", cleaned)\n",
    "    # Remove trailing semicolon if desired (we’ll handle semis in run_sql)\n",
    "    cleaned = cleaned.strip().rstrip(\";\")\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_customer_profile.description = \"Fetch the customer's demographic and financial profile by full name.\"\n",
    "\n",
    "fetch_product_catalog.description = \"Retrieve the complete product catalog including features, target behaviors, eligibility criteria, and special offers.\"\n",
    "\n",
    "fetch_owned_products.description = \"Get a list of products already owned by the customer to avoid duplicate recommendations.\"\n",
    "\n",
    "scientific_calculator.description = \"Perform numeric calculations such as averages, ratios, or thresholds to support financial reasoning.\"\n",
    "\n",
    "fetch_schema_info.description = (\n",
    "    \"Use this tool to retrieve the database schema (tables, columns, types) \"\n",
    "    \"from the predefined SCHEMA_INFO string before using run_sql rool\"\n",
    ")\n",
    "\n",
    "run_sql.description = (\n",
    "    \"Use this tool to execute raw SQL statements. \"\n",
    "    \"Accepts one or multiple semicolon-separated queries. \"\n",
    "    \"other statements return execution status.\"\n",
    "    \"use fetch_schema tool before using this tool\"\n",
    ")\n",
    "\n",
    "analyze_customer_behavior.description = (\n",
    "    \"Use this ONLY to summarize customer behavior patterns for making product recommendations. \"\n",
    "    \"Do NOT use this tool to answer specific data questions like amounts spent.\"\n",
    ")\n",
    "\n",
    "clean_sql_statement.description = (\n",
    "    \"Use this tool to take any raw SQL (even wrapped in markdown fences) \"\n",
    "    \"and return a single clean SQL string, ready for execution.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity-to-Buy Scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool for propensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eligibility criteria tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_eligibility(customer_id: str, product_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Checks structured eligibility rules and returns 'eligible' or lists unmet criteria.\n",
    "    \"\"\"\n",
    "    cust = pd.read_sql(f\"SELECT Age, Annual_Income, Credit_Score FROM customers WHERE Customer_ID='{customer_id}'\", conn).iloc[0]\n",
    "    prod = pd.read_sql(f\"SELECT min_age, min_income, min_credit_score FROM products WHERE Product_ID='{product_id}'\", conn).iloc[0]\n",
    "    fails = []\n",
    "    if cust.Age < prod.min_age: fails.append(f\"Age<{prod.min_age}\")\n",
    "    if cust.Annual_Income < prod.min_income: fails.append(f\"Income<{prod.min_income}\")\n",
    "    if cust.Credit_Score < prod.min_credit_score: fails.append(f\"CreditScore<{prod.min_credit_score}\")\n",
    "    owned = pd.read_sql(f\"SELECT 1 FROM customer_products WHERE Customer_ID='{customer_id}' AND Product_ID='{product_id}'\", conn)\n",
    "    if not owned.empty: fails.append(\"AlreadyOwned\")\n",
    "    return \"eligible\" if not fails else \"not eligible: \" + \",\".join(fails)\n",
    "\n",
    "check_eligibility.description = (\n",
    "    \"Checks structured product eligibility rules (min_age,min_income,min_credit_score,not already owned).\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifecycle Stage Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def detect_stage(customer_id: str) -> str:\n",
    "    row = pd.read_sql(f\"SELECT Age, Customer_Since FROM customers WHERE Customer_ID='{customer_id}'\", conn).iloc[0]\n",
    "    tenure_years = (pd.Timestamp.now() - pd.to_datetime(row.Customer_Since)).days/365\n",
    "    if row.Age < 25 and tenure_years<5: return \"Student\"\n",
    "    if row.Age < 35: return \"YoungProfessional\"\n",
    "    if row.Age < 50: return \"Family\"\n",
    "    if row.Age < 60: return \"PreRetiree\"\n",
    "    return \"Retiree\"\n",
    "\n",
    "detect_stage.description = \"Classifies customer life stage using age + tenure.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment Enricher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "features = pd.read_sql(\"SELECT * FROM feature_store_enhanced\", conn).set_index('Customer_ID')\n",
    "kmeans = KMeans(n_clusters=3, random_state=42).fit(features)\n",
    "pd.Series(kmeans.labels_, index=features.index).to_csv(\"segments.csv\")\n",
    "\n",
    "@tool\n",
    "def segment_customer(customer_id: str) -> str:\n",
    "    seg = pd.read_csv(\"segments.csv\", index_col=0).loc[customer_id]\n",
    "    mapping = {0:\"HighValue\",1:\"ValueShopper\",2:\"Occasional\"}\n",
    "    return mapping.get(seg, \"Unknown\")\n",
    "\n",
    "segment_customer.description = \"Assigns customer to one of three clusters trained on aggregated features.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bundle Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp\n",
    "\n",
    "@tool\n",
    "def optimize_bundle(customer_id: str, budget: float=0.0) -> str:\n",
    "    # fetch eligible & scores\n",
    "    prods = [pid for pid in pd.read_sql(\"SELECT Product_ID FROM products\", conn)['Product_ID']\n",
    "             if check_eligibility(customer_id,pid)==\"eligible\"]\n",
    "    scores = {pid: float(score_propensity(customer_id,pid)) for pid in prods}\n",
    "    # assume cost=1 per product for demo\n",
    "    prob = pulp.LpProblem(\"bundle\", pulp.LpMaximize)\n",
    "    x = pulp.LpVariable.dicts('x', prods, cat='Binary')\n",
    "    prob += pulp.lpSum([scores[p]*x[p] for p in prods])\n",
    "    prob += pulp.lpSum([x[p] for p in prods]) <= 3  # max 3\n",
    "    prob.solve()\n",
    "    chosen = [p for p in prods if x[p].value()==1]\n",
    "    return chosen\n",
    "\n",
    "optimize_bundle.description = \"Selects up to 3 eligible products maximizing propensity via 0/1 knapsack.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next-Best-Action Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "@tool\n",
    "def plan_next_actions(customer_id: str, _: str=\"\") -> str:\n",
    "    stage = detect_stage(customer_id)\n",
    "    segment = segment_customer(customer_id)\n",
    "    bundle = optimize_bundle(customer_id)\n",
    "    return json.dumps({\n",
    "        \"stage\": stage,\n",
    "        \"segment\": segment,\n",
    "        \"recommendations\": bundle\n",
    "    })\n",
    "\n",
    "plan_next_actions.description = (\n",
    "    \"Orchestrates detection, segmentation, and bundle optimization \"\n",
    "    \"to output a next-best-action JSON.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI_DEPLOYMENT_ENDPOINT = \"https://az-openai-document-question-answer-service.openai.azure.com/\" \n",
    "# OPENAI_API_KEY = \"5d24331966b648738e5003caad552df8\" \n",
    "# OPENAI_API_VERSION = \"2023-05-15\"\n",
    "\n",
    "# OPENAI_DEPLOYMENT_NAME = \"az-gpt_35_model\"\n",
    "# OPENAI_MODEL_NAME=\"gpt-3.5-turbo\"\n",
    "\n",
    "# OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = \"az-embedding_model\" \n",
    "# OPENAI_ADA_EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "\n",
    "# encoding_name = \"cl100k_base\"\n",
    "\n",
    "# llm = AzureChatOpenAI(\n",
    "#                         temperature=0.1,\n",
    "#                         deployment_name=OPENAI_DEPLOYMENT_NAME,\n",
    "#                         model_name=OPENAI_MODEL_NAME,\n",
    "#                         azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "#                         openai_api_version=OPENAI_API_VERSION,\n",
    "#                         openai_api_key=OPENAI_API_KEY            \n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_DEPLOYMENT_ENDPOINT = \"https://pkl-aa-dev-aiservices.openai.azure.com/\" \n",
    "OPENAI_API_KEY = \"AXEC3y1jC9ZNGCBB12NZwrpBSzScq1esexgvCXiqw7PaHE04vSMbJQQJ99BDACYeBjFXJ3w3AAABACOG4CMN\" \n",
    "OPENAI_API_VERSION = \"2024-12-01-preview\"\n",
    "\n",
    "OPENAI_DEPLOYMENT_NAME = \"gpt-4o\"\n",
    "OPENAI_MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "                        temperature=0.1,\n",
    "                        deployment_name=OPENAI_DEPLOYMENT_NAME,\n",
    "                        model_name=OPENAI_MODEL_NAME,\n",
    "                        azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "                        openai_api_version=OPENAI_API_VERSION,\n",
    "                        openai_api_key=OPENAI_API_KEY            \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To determine how much Kevin Fleming spent in total and over how many days, I need to query the database. First, I need to fetch the schema information to understand the structure of the database.\n",
      "\n",
      "Action: fetch_schema_info\n",
      "Action Input: ''\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "You have access to the following database schema:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **customers**\n",
      "Stores customer demographic and financial profile information.\n",
      "\n",
      "| Column Name   | Type    | Description                                | Example         |\n",
      "|---------------|---------|--------------------------------------------|-----------------|\n",
      "| Customer_ID   | TEXT PK | Unique customer identifier                 | 'CUST0012'      |\n",
      "| First_Name    | TEXT    | Customer's first name                      | 'David'         |\n",
      "| Last_Name     | TEXT    | Customer's last name                       | 'Brown'         |\n",
      "| Gender        | TEXT    | Customer's gender ('M' or 'F')             | 'M'             |\n",
      "| Date_of_Birth | DATE    | Customer's date of birth                   | '1988-05-20'    |\n",
      "| Age           | INTEGER | Customer's age                             | 35              |\n",
      "| Email         | TEXT    | Customer's email address                   | 'david.b@example.com' |\n",
      "| Phone         | TEXT    | Customer's phone number                    | '+1-202-555-0147' |\n",
      "| Address       | TEXT    | Street address                             | '123 Main St'   |\n",
      "| City          | TEXT    | City                                       | 'New York'      |\n",
      "| State         | TEXT    | State                                      | 'NY'            |\n",
      "| Postal_Code   | TEXT    | Postal/ZIP code                            | '10001'         |\n",
      "| Country       | TEXT    | Country                                    | 'USA'           |\n",
      "| Annual_Income | INTEGER | Declared annual income in USD              | 75000           |\n",
      "| Credit_Score  | INTEGER | Customer's credit score                    | 720             |\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **transactions**\n",
      "Records all customer transaction activities.\n",
      "\n",
      "| Column Name   | Type     | Description                                | Example               |\n",
      "|---------------|----------|--------------------------------------------|-----------------------|\n",
      "| Transaction_ID| TEXT PK  | Unique transaction identifier              | 'TXN10001'            |\n",
      "| Customer_ID   | TEXT FK  | References customers.Customer_ID           | 'CUST0012'            |\n",
      "| Timestamp     | DATETIME | Date and time of transaction               | '2024-03-15 14:22'    |\n",
      "| Merchant      | TEXT     | Merchant name                              | 'Amazon'              |\n",
      "| Category      | TEXT     | Transaction category                       | 'Grocery'             |\n",
      "| Amount        | FLOAT    | Transaction amount in USD                  | 125.50                |\n",
      "| Description   | TEXT     | Transaction description                    | 'Whole Foods Market'  |\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **products**\n",
      "Details of all financial products available for customers.\n",
      "\n",
      "| Column Name        | Type    | Description                                 | Example               |\n",
      "|--------------------|---------|---------------------------------------------|-----------------------|\n",
      "| Product_ID         | TEXT PK | Unique product identifier                   | 'P003'                |\n",
      "| Product_Name       | TEXT    | Name of the product                         | 'Smart Shopper Card'  |\n",
      "| Product_Type       | TEXT    | Type of product (Credit Card, Savings, etc.)| 'Credit Card'         |\n",
      "| Tier               | TEXT    | Customer segment target                     | 'Mid'                 |\n",
      "| Features_Benefits  | TEXT    | Key features and benefits                   | '2% cashback on groceries & fuel' |\n",
      "| Target_Behavior    | TEXT    | Ideal customer behavior                     | 'High grocery spend'  |\n",
      "| Eligibility_Criteria| TEXT   | Requirements to qualify                     | 'Income > 30,000...'  |\n",
      "| Special_Offer      | TEXT    | Promotional offer                           | 'USD 50 cashback...'  |\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **customer_products**\n",
      "Links customers to products they currently own.\n",
      "\n",
      "| Column Name   | Type    | Description                         | Example     |\n",
      "|---------------|---------|-------------------------------------|-------------|\n",
      "| Customer_ID   | TEXT FK | References customers.Customer_ID    | 'CUST0012'  |\n",
      "| Product_ID    | TEXT FK | References products.Product_ID      | 'P003'      |\n",
      "\n",
      "---\n",
      "\n",
      "### 5. **feature_store**\n",
      "Aggregated customer behavior data for analytics and recommendations.\n",
      "\n",
      "| Column Name             | Type     | Description                                | Example     |\n",
      "|-------------------------|----------|--------------------------------------------|-------------|\n",
      "| Customer_ID             | TEXT PK  | Unique customer identifier                 | 'CUST0012'  |\n",
      "| Total_Spend             | FLOAT    | Total amount spent                         | 4250.75     |\n",
      "| Num_Transactions        | INTEGER  | Number of transactions                     | 30          |\n",
      "| Avg_Txn_Amount          | FLOAT    | Average transaction value                  | 141.69      |\n",
      "| Max_Txn_Amount          | FLOAT    | Largest single transaction                 | 1200.00     |\n",
      "| Has_Salary_Credit       | INTEGER  | 1 if salary detected, else 0               | 1           |\n",
      "| Spend_Baby              | FLOAT    | Spend on baby-related purchases            | 300.00      |\n",
      "| Spend_Dining            | FLOAT    | Dining spend                               | 850.00      |\n",
      "| Spend_Education         | FLOAT    | Education-related spend                    | 500.00      |\n",
      "| Spend_Entertainment     | FLOAT    | Entertainment spend                        | 400.00      |\n",
      "| Spend_Fuel              | FLOAT    | Fuel spend                                 | 220.00      |\n",
      "| Spend_Grocery           | FLOAT    | Grocery spend                              | 958.81      |\n",
      "| Spend_Home              | FLOAT    | Home-related spend                         | 1200.00     |\n",
      "| Spend_Medical           | FLOAT    | Medical expenses                           | 250.00      |\n",
      "| Total_Salary_Credits    | FLOAT    | Total salary credited                      | 6000.00     |\n",
      "| Spend_Travel            | FLOAT    | Travel spend                               | 1250.00     |\n",
      "| Age                    | INTEGER  | Customer's age                             | 35          |\n",
      "| Annual_Income           | INTEGER  | Annual income in USD                       | 75000       |\n",
      "| Credit_Score            | INTEGER  | Credit score                               | 720         |\n",
      "| Aggregation_Days        | INTEGER  | Days over which data was aggregated        | 30          |\n",
      "| Spend_Variability       | FLOAT    | Std deviation of spend amounts             | 500.00      |\n",
      "| Salary_to_Spend_Ratio   | FLOAT    | Salary vs spend ratio                      | 0.65        |\n",
      "| Top_Spend_Category      | TEXT     | Category with highest spend                | 'Grocery'   |\n",
      "| Idle_Balance_Estimate   | FLOAT    | Estimated idle balance                     | 7500.00     |\n",
      "\n",
      "---\n",
      "\n",
      "### **Entity Relationships:**\n",
      "- `customers.Customer_ID` ⬌ `transactions.Customer_ID` (**1-to-many**)\n",
      "- `customers.Customer_ID` ⬌ `customer_products.Customer_ID` (**1-to-many**)\n",
      "- `customer_products.Product_ID` ⬌ `products.Product_ID` (**many-to-1**)\n",
      "- `feature_store.Customer_ID` ⬌ `customers.Customer_ID` (**1-to-1**)\n",
      "\n",
      "---\n",
      "\n",
      "### **Example Queries You Can Answer:**\n",
      "- \"List all products owned by customers with credit score > 700.\"\n",
      "- \"Show David Brown's top spending category.\"\n",
      "- \"Find customers who spent more than USD 1000 on travel last month.\"\n",
      "- \"What is the average transaction amount for CUST0012?\"\n",
      "- \"Which customers have idle balances above USD 5000?\"\n",
      "\n",
      "Always generate **SQLite-compatible SQL queries** using only this schema.\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThought: To find out how much Kevin Fleming spent in total and over how many days, I need to first identify his `Customer_ID` from the `customers` table. Then, I can query the `feature_store` table for his `Total_Spend` and `Aggregation_Days`.\n",
      "\n",
      "Action: run_sql\n",
      "Action Input: SELECT Customer_ID FROM customers WHERE First_Name = 'Kevin' AND Last_Name = 'Fleming';\u001b[0m\u001b[38;5;200m\u001b[1;3m✅ Results for `SELECT Customer_ID FROM customers WHERE First_Name = 'Kevin' AND Last_Name = 'Fleming'`:\n",
      "\n",
      "| Customer_ID   |\n",
      "|:--------------|\n",
      "| CUST0010      |\u001b[0m\u001b[32;1m\u001b[1;3mTo determine Kevin Fleming's total spend and aggregation days, I will query the `feature_store` table using his `Customer_ID` (`CUST0010`).\n",
      "\n",
      "Action: run_sql\n",
      "Action Input: SELECT Total_Spend, Aggregation_Days FROM feature_store WHERE Customer_ID = 'CUST0010';\u001b[0m\u001b[38;5;200m\u001b[1;3m✅ Results for `SELECT Total_Spend, Aggregation_Days FROM feature_store WHERE Customer_ID = 'CUST0010'`:\n",
      "\n",
      "|   Total_Spend |   Aggregation_Days |\n",
      "|--------------:|-------------------:|\n",
      "|       20516.8 |                 23 |\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: Kevin Fleming spent a total of $20,516.80 over 23 days.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "import textwrap\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", react_prompt),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"ai\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tools = [fetch_customer_profile, analyze_customer_behavior, fetch_product_catalog, fetch_owned_products, fetch_schema_info, run_sql ,clean_sql_statement ]\n",
    "# tools = [fetch_schema_info, run_sql  , clean_sql_statement]\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt   # Optional. If omitted, uses LangChain's default ReAct prompt\n",
    ")\n",
    "\n",
    "# 4. Agent Executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "user_query = \"How much did Kevin Fleming spend in total over how many days?\"\n",
    "# user_query = \"Recommend products for Kevin Fleming based on his current products and expenditures.\"\n",
    "# user_query = \"Give me a view of all transactions by David Brown\"\n",
    "# user_query = \"Give me customer info for DAvid Brown\"\n",
    "# user_query = \"How many total customers bought more than 2 products ?\"\n",
    "response = agent_executor.invoke({\"input\": user_query})\n",
    "\n",
    "output_text = response.get('output', '')\n",
    "\n",
    "# Pretty print with wrapping at 100 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_recommendation_summary(raw_text):\n",
    "    # Remove initial label if present\n",
    "    raw_text = raw_text.replace(\"**Recommendation Summary:**\", \"\").strip()\n",
    "\n",
    "    # Split by numbering (assuming '1.' and '2.' structure)\n",
    "    parts = raw_text.split(\" 2. \")\n",
    "    rec_1 = parts[0].strip()\n",
    "    rec_2 = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "\n",
    "    formatted_output = \"\"\n",
    "\n",
    "    for idx, rec in enumerate([rec_1, rec_2], start=1):\n",
    "        if not rec:\n",
    "            continue\n",
    "        # Split the recommendation into lines by bullet points\n",
    "        lines = rec.split(\" - \")\n",
    "        title = lines[0].strip()\n",
    "        bullets = lines[1:]\n",
    "\n",
    "        formatted_output += f\"{idx}. {title}\\n\"\n",
    "        for bullet in bullets:\n",
    "            bullet = bullet.replace(\"Eligibility Criteria\", \"Eligibility Criteria\") \\\n",
    "                           .replace(\"Reason\", \"Reason\") \\\n",
    "                           .replace(\"Benefit\", \"Benefit\")\n",
    "            formatted_output += f\"   - {bullet.strip()}\\n\"\n",
    "        formatted_output += \"\\n\"\n",
    "\n",
    "    return textwrap.dedent(formatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Based on Kevin Fleming's financial profile, spending patterns, and existing products, I recommend the following products:\n",
      "\n",
      "1. **Smart Shopper Card (P003)**:\n",
      "   - **Reason**: Kevin has significant spending on fuel and groceries. This card offers 2% cashback on these categories, aligning well with his spending habits.\n",
      "   - **Special Offer**: USD 50 cashback on the first USD 500 spend.\n",
      "\n",
      "2. **CashBuilder Certificate (P016)**:\n",
      "   - **Reason**: Kevin has an estimated idle balance of $93,333.20. This fixed deposit product offers a 4.75% fixed interest rate for 6 months, which can help him earn returns on his idle funds.\n",
      "   - **Special Offer**: USD 25 bonus for auto-renewal.\n",
      "\n",
      "3. **Lifestyle Bundle Plus (P017)**:\n",
      "   - **Reason**: Kevin is an affluent customer with a high income and multiple existing products. This bundle combines credit, wealth, and travel perks, offering a premium experience.\n",
      "   - **Special Offer**: USD 300 statement credit and concierge onboarding.\n",
      "\n",
      "4. **HealthSecure Plan (P013)**:\n",
      "   - **Reason**: Kevin has notable medical expenses. This product integrates health savings and telehealth access, which could help him manage medical costs effectively.\n",
      "   - **Special Offer**: USD 200 credit toward medical expenses.\n",
      "\n",
      "These recommendations align with Kevin's financial behavior, income level, and spending patterns while avoiding overlap with his existing products.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_recommendation_summary(output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
