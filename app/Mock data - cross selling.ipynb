{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.7)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikeras 0.4.1 requires packaging<22.0,>=0.21, but you have packaging 23.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (2.2.3)\n",
      "Collecting scikit-learn>=1.3.1 (from mlxtend)\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (3.9.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.28.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Collecting joblib>=0.13.2 (from mlxtend)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 1.4/1.4 MB 23.2 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 11.1/11.1 MB 18.8 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib, scikit-learn, mlxtend\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "  Attempting uninstall: mlxtend\n",
      "    Found existing installation: mlxtend 0.1.7\n",
      "    Uninstalling mlxtend-0.1.7:\n",
      "      Successfully uninstalled mlxtend-0.1.7\n",
      "Successfully installed joblib-1.4.2 mlxtend-0.23.4 scikit-learn-1.6.1\n"
     ]
    }
   ],
   "source": [
    "! py -m pip install mlxtend --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Customer_ID First_Name Last_Name Date_of_Birth  Age Gender  \\\n",
      "9254   CUST09255     Steven     Singh    1957-05-17   67      M   \n",
      "1561   CUST01562      Eddie      Bush    1977-08-26   47      M   \n",
      "1670   CUST01671      Diane     Perry    1966-11-11   58      F   \n",
      "6087   CUST06088      Emily  Martinez    1978-11-08   46      F   \n",
      "6669   CUST06670    William    Morrow    2006-05-14   18      M   \n",
      "\n",
      "     Marital_Status                     Email                Phone  \\\n",
      "9254        Widowed  ellisanthony@example.net           2005344588   \n",
      "1561        Married  mariahgibson@example.org   889.926.7013x61916   \n",
      "1670        Widowed     gateskyle@example.net    516-531-6641x7000   \n",
      "6087       Divorced       karnold@example.com    283.523.5976x2995   \n",
      "6669        Widowed       obailey@example.com  +1-491-818-7979x573   \n",
      "\n",
      "                                                Address             City  \\\n",
      "9254  641 Larsen Harbors Apt. 904, Thomasbury, DE 72836       Coxchester   \n",
      "1561       77594 Kenneth Oval, Mclaughlintown, WI 37210     Jeremiahbury   \n",
      "1670            7421 Kaitlyn Canyon, Larafurt, AK 49640  Lake Mariemouth   \n",
      "6087       1019 Pugh Road Apt. 538, Banksview, SD 73118      Melvinhaven   \n",
      "6669  00392 Johnny Mountain, West Stephanieshire, SD...       East Malik   \n",
      "\n",
      "              State Postal_Code Country Employment_Status  Annual_Income  \\\n",
      "9254      Louisiana       10497     USA           Retired          31000   \n",
      "1561  New Hampshire       96360     USA         Full-Time         104000   \n",
      "1670       Nebraska       78291     USA         Full-Time          55000   \n",
      "6087  West Virginia       62531     USA         Part-Time          70000   \n",
      "6669       Nebraska       20088     USA         Part-Time          72000   \n",
      "\n",
      "      Credit_Score Account_Type Customer_Since  \n",
      "9254           471         Both     2020-11-05  \n",
      "1561           698         Both     2021-03-25  \n",
      "1670           566         Both     2016-01-11  \n",
      "6087           650     Checking     2017-07-29  \n",
      "6669           563         Both     2024-04-17  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import date, timedelta\n",
    "\n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "num_customers = 10000\n",
    "\n",
    "def generate_credit_score(income):\n",
    "    base = np.interp(income, [20000, 200000], [500, 800])\n",
    "    noise = np.random.normal(loc=0, scale=50)\n",
    "    return int(np.clip(base + noise, 300, 850))\n",
    "\n",
    "def generate_employment_status(age):\n",
    "    if age < 18:\n",
    "        return \"Unemployed\"\n",
    "    elif age < 30:\n",
    "        return random.choices(\n",
    "            ['Full-Time', 'Part-Time', 'Self-Employed', 'Student'],\n",
    "            weights=[0.4, 0.2, 0.1, 0.3]\n",
    "        )[0]\n",
    "    elif age >= 60:\n",
    "        return random.choices(\n",
    "            ['Retired', 'Self-Employed', 'Unemployed'],\n",
    "            weights=[0.7, 0.2, 0.1]\n",
    "        )[0]\n",
    "    else:\n",
    "        return random.choices(\n",
    "            ['Full-Time', 'Part-Time', 'Self-Employed', 'Unemployed'],\n",
    "            weights=[0.6, 0.15, 0.15, 0.1]\n",
    "        )[0]\n",
    "\n",
    "def generate_account_type():\n",
    "    return random.choices(\n",
    "        ['Savings', 'Checking', 'Both'],\n",
    "        weights=[0.2, 0.3, 0.5]\n",
    "    )[0]\n",
    "\n",
    "def generate_customer_since(age):\n",
    "    today = date.today()\n",
    "    if age < 20:\n",
    "        return today - timedelta(days=365)  # 1 year\n",
    "    elif age < 30:\n",
    "        return today - timedelta(days=random.randint(365, 5*365))  # up to 5 years\n",
    "    else:\n",
    "        return today - timedelta(days=random.randint(365, 10*365))  # up to 10 years\n",
    "\n",
    "# Generate customers\n",
    "customers = []\n",
    "for i in range(1, num_customers + 1):\n",
    "    is_male = random.choice([True, False])\n",
    "    first_name = fake.first_name_male() if is_male else fake.first_name_female()\n",
    "    gender = \"M\" if is_male else \"F\"\n",
    "    last_name = fake.last_name()\n",
    "    dob = fake.date_of_birth(minimum_age=18, maximum_age=75)\n",
    "    age = int((pd.Timestamp.now().date() - pd.to_datetime(dob).date()).days / 365)\n",
    "\n",
    "    income = np.random.randint(20, 200) * 1000  # in increments of 1000\n",
    "    credit_score = generate_credit_score(income)\n",
    "    marital_status = random.choice(['Married', 'Single', 'Divorced', 'Widowed']) if age >= 18 else 'Single'\n",
    "\n",
    "    customers.append({\n",
    "        \"Customer_ID\": f\"CUST{i:05d}\",\n",
    "        \"First_Name\": first_name,\n",
    "        \"Last_Name\": last_name,\n",
    "        \"Date_of_Birth\": dob,\n",
    "        \"Age\": age,\n",
    "        \"Gender\": gender,\n",
    "        \"Marital_Status\": marital_status,\n",
    "        \"Email\": fake.email(),\n",
    "        \"Phone\": fake.phone_number(),\n",
    "        \"Address\": fake.address().replace(\"\\n\", \", \"),\n",
    "        \"City\": fake.city(),\n",
    "        \"State\": fake.state(),\n",
    "        \"Postal_Code\": fake.postcode(),\n",
    "        \"Country\": \"USA\",\n",
    "        \"Employment_Status\": generate_employment_status(age),\n",
    "        \"Annual_Income\": income,\n",
    "        \"Credit_Score\": credit_score,\n",
    "        \"Account_Type\": generate_account_type(),\n",
    "        \"Customer_Since\": generate_customer_since(age)\n",
    "    })\n",
    "\n",
    "df_customers = pd.DataFrame(customers)\n",
    "\n",
    "# Split into train and test\n",
    "# train_df, test_df = train_test_split(df_customers, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Preview\n",
    "# print(train_df.head())\n",
    "\n",
    "# # Uncomment to save\n",
    "# train_df.to_csv(\"customers_train.csv\", index=False)\n",
    "# test_df.to_csv(\"customers_test.csv\", index=False)\n",
    "\n",
    "df_customers.to_csv(\"customers.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transaction_ID Customer_ID           Timestamp         Merchant  \\\n",
      "0     TXN0046402   CUST07774 2022-04-18 05:54:56           Subway   \n",
      "1     TXN0039211   CUST01840 2022-04-18 06:50:56     Grocery Town   \n",
      "2     TXN0049956   CUST00310 2022-04-18 07:16:22     Pharmacy Hub   \n",
      "3     TXN0046728   CUST02783 2022-04-18 07:24:42          Walmart   \n",
      "4     TXN0018524   CUST01522 2022-04-18 07:55:21  Dorm Essentials   \n",
      "\n",
      "      Category   Amount                    Description  \n",
      "0       Retail    93.38             Purchase at Subway  \n",
      "1       Retail    66.65       Purchase at Grocery Town  \n",
      "2      Grocery    47.87       Purchase at Pharmacy Hub  \n",
      "3       Retail   179.28            Purchase at Walmart  \n",
      "4  Electronics  1939.09  Electronics - Dorm Essentials  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fake = Faker()\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Load customer IDs from combined train + test\n",
    "customer_ids = [f\"CUST{i:05d}\" for i in range(1, 10001)]\n",
    "\n",
    "# Define life events\n",
    "life_events = {\n",
    "    \"New Job\": [\"Salary - Google LLC\", \"Uber Eats\", \"BestBuy\", \"Starbucks\"],\n",
    "    \"Marriage\": [\"Wedding Planner\", \"Zales Jewelry\", \"Airbnb Honeymoon\", \"Flower Co\"],\n",
    "    \"Home Purchase\": [\"Home Depot\", \"Furniture World\", \"Mortgage Payment\", \"Lowe's\"],\n",
    "    \"Retirement\": [\"Pension Fund Credit\", \"Leisure Travel\", \"Pharmacy\", \"Garden Supplies\"],\n",
    "    \"Childbirth\": [\"BabyGap\", \"Target\", \"Pediatric Hospital\", \"Mothercare\"],\n",
    "    \"College\": [\"University Bookstore\", \"Tuition Fee\", \"Laptop Purchase\", \"Dorm Essentials\"]\n",
    "}\n",
    "\n",
    "life_event_categories = {\n",
    "    \"New Job\": [\"Salary\", \"Food\", \"Electronics\", \"Coffee\"],\n",
    "    \"Marriage\": [\"Wedding\", \"Jewelry\", \"Travel\", \"Flowers\"],\n",
    "    \"Home Purchase\": [\"Home Improvement\", \"Furniture\", \"Mortgage\", \"DIY\"],\n",
    "    \"Retirement\": [\"Pension\", \"Travel\", \"Healthcare\", \"Gardening\"],\n",
    "    \"Childbirth\": [\"Baby\", \"Retail\", \"Medical\", \"Baby Gear\"],\n",
    "    \"College\": [\"Education\", \"Tuition\", \"Electronics\", \"Student Supplies\"]\n",
    "}\n",
    "\n",
    "# Assign 3,000 customers to life events (500 per event)\n",
    "life_event_customers = {}\n",
    "all_life_event_ids = random.sample(customer_ids, 3000)\n",
    "remaining_ids = set(customer_ids) - set(all_life_event_ids)\n",
    "\n",
    "split_event_ids = np.array_split(all_life_event_ids, 6)\n",
    "life_event_keys = list(life_events.keys())\n",
    "\n",
    "for i, event in enumerate(life_event_keys):\n",
    "    life_event_customers[event] = list(split_event_ids[i])\n",
    "\n",
    "transactions = []\n",
    "txn_id = 1\n",
    "\n",
    "def generate_random_transaction(customer_id):\n",
    "    merchant = random.choice([\n",
    "        \"Walmart\", \"Shell Gas\", \"Grocery Town\", \"Subway\", \"Pharmacy Hub\", \"Local Market\"\n",
    "    ])\n",
    "    category = random.choice([\"Grocery\", \"Fuel\", \"Dining\", \"Pharmacy\", \"Retail\"])\n",
    "    amount = round(random.uniform(10, 200), 2)\n",
    "    description = f\"Purchase at {merchant}\"\n",
    "    date = fake.date_time_between(start_date=\"-3y\", end_date=\"now\")\n",
    "    \n",
    "    return {\n",
    "        \"Transaction_ID\": f\"TXN{txn_id:07d}\",\n",
    "        \"Customer_ID\": customer_id,\n",
    "        \"Timestamp\": date,\n",
    "        \"Merchant\": merchant,\n",
    "        \"Category\": category,\n",
    "        \"Amount\": amount,\n",
    "        \"Description\": description\n",
    "    }\n",
    "\n",
    "# Generate life event transactions\n",
    "for event, ids in life_event_customers.items():\n",
    "    for customer_id in ids:\n",
    "        num_txns = random.randint(3, 10)\n",
    "        for _ in range(num_txns):\n",
    "            merchant = random.choice(life_events[event])\n",
    "            category = random.choice(life_event_categories[event])\n",
    "            amount = round(random.uniform(100, 3000), 2) if \"Salary\" not in merchant and \"Pension\" not in merchant else round(random.uniform(3000, 12000), 2)\n",
    "            description = f\"{category} - {merchant}\"\n",
    "            date = fake.date_time_between(start_date=\"-3y\", end_date=\"now\")\n",
    "            transactions.append({\n",
    "                \"Transaction_ID\": f\"TXN{txn_id:07d}\",\n",
    "                \"Customer_ID\": customer_id,\n",
    "                \"Timestamp\": date,\n",
    "                \"Merchant\": merchant,\n",
    "                \"Category\": category,\n",
    "                \"Amount\": amount,\n",
    "                \"Description\": description\n",
    "            })\n",
    "            txn_id += 1\n",
    "\n",
    "# Generate normal customer transactions\n",
    "for customer_id in remaining_ids:\n",
    "    num_txns = random.randint(3, 10)\n",
    "    for _ in range(num_txns):\n",
    "        txn = generate_random_transaction(customer_id)\n",
    "        txn[\"Transaction_ID\"] = f\"TXN{txn_id:07d}\"\n",
    "        transactions.append(txn)\n",
    "        txn_id += 1\n",
    "\n",
    "# Create DataFrame\n",
    "df_transactions = pd.DataFrame(transactions)\n",
    "\n",
    "# Sort by timestamp for realism\n",
    "df_transactions = df_transactions.sort_values(by=\"Timestamp\").reset_index(drop=True)\n",
    "\n",
    "print(df_transactions.head())\n",
    "\n",
    "# Optional save\n",
    "df_transactions.to_csv(\"transactions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock Transactions data generated and saved as 'Transactions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "total_customers = 10000\n",
    "\n",
    "# Ensure each customer has at least one transaction.\n",
    "base_customer_ids = np.arange(1, total_customers + 1)\n",
    "\n",
    "# Decide on extra transactions (e.g., 5000 additional transactions)\n",
    "extra_transactions = 10000\n",
    "extra_customer_ids = np.random.randint(1, total_customers + 1, extra_transactions)\n",
    "\n",
    "# Combine to get a list where every customer appears at least once.\n",
    "customer_ids = np.concatenate([base_customer_ids, extra_customer_ids])\n",
    "num_transactions = len(customer_ids)\n",
    "\n",
    "# TransactionID: Sequential IDs starting from 5001\n",
    "transaction_ids = np.arange(5001, 5001 + num_transactions)\n",
    "\n",
    "# Extensive list of products and their variations that large banks typically offer\n",
    "products = {\n",
    "    'Mortgage': ['Fixed Rate', 'Adjustable Rate', 'Interest Only', 'Reverse Mortgage'],\n",
    "    'Credit Card': ['Rewards', 'Cashback', 'Travel', 'Business', 'Secured'],\n",
    "    'Checking Account': ['Premium', 'Basic', 'Senior', 'Interest Bearing'],\n",
    "    'Savings Account': ['High Yield', 'Regular', 'Money Market', \"Children's Savings\"],\n",
    "    'Certificate of Deposit': ['1-Year', '2-Year', '5-Year', '10-Year'],\n",
    "    'Personal Loan': ['Secured', 'Unsecured', 'Debt Consolidation', 'Home Improvement'],\n",
    "    'Auto Loan': ['New Car', 'Used Car', 'Refinance', 'Lease'],\n",
    "    'Home Equity Loan': ['Fixed Rate', 'Variable Rate', 'HELOC'],\n",
    "    'Investment Account': ['Managed', 'Self-Directed', 'Robo Advisor', 'Brokerage'],\n",
    "    'Business Loan': ['Term Loan', 'Line of Credit', 'SBA Loan', 'Equipment Financing'],\n",
    "    'Retirement Account': ['IRA', '401K', 'Roth IRA', 'Simple IRA'],\n",
    "    'Student Loan': ['Federal', 'Private', 'Refinance', 'Consolidation']\n",
    "}\n",
    "\n",
    "# List of product names for random selection\n",
    "product_list = list(products.keys())\n",
    "chosen_products = np.random.choice(product_list, num_transactions)\n",
    "variations = [np.random.choice(products[prod]) for prod in chosen_products]\n",
    "\n",
    "# Generate random dates between 2020-01-01 and 2025-03-31\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2025, 3, 31)\n",
    "days_range = (end_date - start_date).days\n",
    "random_days = np.random.randint(0, days_range + 1, num_transactions)\n",
    "dates = [start_date + timedelta(days=int(day)) for day in random_days]\n",
    "# Format dates as MM/DD/YYYY (e.g., \"08/04/2020\")\n",
    "formatted_dates = [d.strftime(\"%m/%d/%Y\") for d in dates]\n",
    "\n",
    "# Create the DataFrame\n",
    "df_transactions = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'CustomerID': customer_ids,\n",
    "    'Product': chosen_products,\n",
    "    'Variation': variations,\n",
    "    'Date': formatted_dates\n",
    "})\n",
    "\n",
    "# Ensure Date column is explicitly string\n",
    "df_transactions['Date'] = df_transactions['Date'].astype(str)\n",
    "\n",
    "# Save to CSV with all fields quoted so that formatting is preserved\n",
    "df_transactions.to_csv(\"../data/Transactions.csv\", index=False, quoting=csv.QUOTE_ALL)\n",
    "print(\"Mock Transactions data generated and saved as 'Transactions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified mock Transactions data generated and saved as 'Transactions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "total_customers = 10000\n",
    "\n",
    "# Ensure each customer has at least one transaction.\n",
    "base_customer_ids = np.arange(1, total_customers + 1)\n",
    "extra_transactions = 10000  # Increase extra transactions if needed\n",
    "extra_customer_ids = np.random.randint(1, total_customers + 1, extra_transactions)\n",
    "customer_ids = np.concatenate([base_customer_ids, extra_customer_ids])\n",
    "num_transactions = len(customer_ids)\n",
    "\n",
    "# TransactionID: Sequential IDs starting from 5001\n",
    "transaction_ids = np.arange(5001, 5001 + num_transactions)\n",
    "\n",
    "# Original products dictionary with variations\n",
    "products = {\n",
    "    'Mortgage': ['Fixed Rate', 'Adjustable Rate', 'Hybrid Rate', 'Interest Only', 'Balloon Payment', 'Reverse Mortgage'],\n",
    "    'Credit Card': ['Rewards', 'Cashback', 'Travel', 'Business', 'Student', 'Secured', 'Balance Transfer'],\n",
    "    'Checking Account': ['Premium', 'Basic', 'Student', 'Senior', 'Interest Bearing'],\n",
    "    'Savings Account': ['High Yield', 'Regular', 'Money Market', \"Children's Savings\"],\n",
    "    'Certificate of Deposit': ['3-Month', '6-Month', '1-Year', '2-Year', '5-Year', '10-Year'],\n",
    "    'Personal Loan': ['Secured', 'Unsecured', 'Debt Consolidation', 'Home Improvement'],\n",
    "    'Auto Loan': ['New Car', 'Used Car', 'Refinance', 'Lease'],\n",
    "    'Home Equity Loan': ['Fixed Rate', 'Variable Rate', 'HELOC'],\n",
    "    'Investment Account': ['Managed', 'Self-Directed', 'Robo Advisor', 'Brokerage'],\n",
    "    'Business Loan': ['Term Loan', 'Line of Credit', 'SBA Loan', 'Equipment Financing'],\n",
    "    'Retirement Account': ['IRA', '401K', 'Roth IRA', 'SEP IRA', 'Simple IRA'],\n",
    "    'Student Loan': ['Federal', 'Private', 'Refinance', 'Consolidation']\n",
    "}\n",
    "\n",
    "# Define three product groups (fewer combinations per customer)\n",
    "group1 = ['Mortgage', 'Credit Card', 'Business Loan']\n",
    "group2 = ['Checking Account', 'Savings Account', 'Certificate of Deposit', 'Personal Loan']\n",
    "group3 = ['Auto Loan', 'Home Equity Loan', 'Investment Account', 'Retirement Account', 'Student Loan']\n",
    "\n",
    "groups = {1: group1, 2: group2, 3: group3}\n",
    "all_products = group1 + group2 + group3  # complete list of products\n",
    "\n",
    "# Assign each customer to one group at random\n",
    "customer_group = {}\n",
    "for cid in range(1, total_customers + 1):\n",
    "    customer_group[cid] = np.random.choice([1, 2, 3])\n",
    "\n",
    "# Generate chosen_products for each transaction:\n",
    "# With 80% probability, choose from the customer's group.\n",
    "chosen_products = []\n",
    "expanded_customer_ids = []\n",
    "\n",
    "for cid in customer_ids:\n",
    "    if np.random.rand() < 0.9:\n",
    "        n_products = np.random.choice([2, 3], p=[0.7, 0.3])\n",
    "        prods = np.random.choice(groups[customer_group[cid]], size=n_products, replace=False)\n",
    "        chosen_products.extend(prods)\n",
    "        expanded_customer_ids.extend([cid] * n_products)\n",
    "    else:\n",
    "        prod = np.random.choice(all_products)\n",
    "        chosen_products.append(prod)\n",
    "        expanded_customer_ids.append(cid)\n",
    "\n",
    "# Now they match\n",
    "assert len(expanded_customer_ids) == len(chosen_products)\n",
    "\n",
    "# TransactionID\n",
    "transaction_ids = np.arange(5001, 5001 + len(expanded_customer_ids))\n",
    "\n",
    "# Variations\n",
    "chosen_variations = [np.random.choice(products[prod]) for prod in chosen_products]\n",
    "\n",
    "# Dates\n",
    "random_days = np.random.randint(0, days_range + 1, len(expanded_customer_ids))\n",
    "dates = [start_date + timedelta(days=int(day)) for day in random_days]\n",
    "formatted_dates = [d.strftime(\"%m/%d/%Y\") for d in dates]\n",
    "\n",
    "# Final DataFrame\n",
    "df_transactions = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'CustomerID': expanded_customer_ids,\n",
    "    'Product': chosen_products,\n",
    "    'Variation': chosen_variations,\n",
    "    'Date': formatted_dates\n",
    "})\n",
    "\n",
    "# Save\n",
    "df_transactions['Date'] = df_transactions['Date'].astype(str)\n",
    "df_transactions.to_csv(\"../data/Transactions.csv\", index=False, quoting=csv.QUOTE_ALL)\n",
    "print(\"Modified mock Transactions data generated and saved as 'Transactions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductVariationRatings.csv generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Transactions data\n",
    "df_transactions = pd.read_csv(\"../data/Transactions.csv\")\n",
    "\n",
    "# Generate a rating between 1.0 to 5.0 with slight skew toward higher values\n",
    "# We'll use a clipped normal distribution\n",
    "ratings = np.random.normal(loc=4.0, scale=0.7, size=len(df_transactions))\n",
    "ratings = np.clip(ratings, 1.0, 5.0)\n",
    "ratings = np.round(ratings, 1)\n",
    "\n",
    "# Create the new DataFrame\n",
    "df_ratings = df_transactions.copy()\n",
    "df_ratings = df_ratings.drop(columns=[\"Date\"])  # Remove Date\n",
    "df_ratings[\"Rating\"] = ratings  # Add Rating column\n",
    "\n",
    "# Save to CSV\n",
    "df_ratings.to_csv(\"../data/ProductVariationRatings.csv\", index=False, quoting=1)  # quoting=1 = csv.QUOTE_ALL\n",
    "print(\"ProductVariationRatings.csv generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions Data Sample:\n",
      "   TransactionID  CustomerID             Product         Variation        Date\n",
      "0           5001           1         Credit Card  Balance Transfer  04/30/2020\n",
      "1           5002           1            Mortgage  Reverse Mortgage  11/15/2021\n",
      "2           5003           2  Retirement Account           SEP IRA  04/12/2023\n",
      "3           5004           2  Investment Account     Self-Directed  09/09/2023\n",
      "4           5005           3         Credit Card           Rewards  03/28/2025\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Transactions data\n",
    "df_transactions = pd.read_csv(\"../data/Transactions.csv\")\n",
    "\n",
    "# Take a quick look at the data\n",
    "print(\"Transactions Data Sample:\")\n",
    "print(df_transactions.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basket Sample:\n",
      "<bound method NDFrame.head of       CustomerID                                            Product\n",
      "0              1                            [Mortgage, Credit Card]\n",
      "1              2  [Investment Account, Auto Loan, Home Equity Lo...\n",
      "2              3             [Business Loan, Mortgage, Credit Card]\n",
      "3              4             [Business Loan, Mortgage, Credit Card]\n",
      "4              5             [Business Loan, Mortgage, Credit Card]\n",
      "...          ...                                                ...\n",
      "9995        9996             [Investment Account, Home Equity Loan]\n",
      "9996        9997  [Mortgage, Savings Account, Home Equity Loan, ...\n",
      "9997        9998                          [Business Loan, Mortgage]\n",
      "9998        9999  [Business Loan, Mortgage, Credit Card, Home Eq...\n",
      "9999       10000             [Business Loan, Mortgage, Credit Card]\n",
      "\n",
      "[10000 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Group transactions by CustomerID and aggregate unique products into a list (basket)\n",
    "basket = df_transactions.groupby('CustomerID')['Product'] \\\n",
    "                          .apply(lambda x: list(set(x))) \\\n",
    "                          .reset_index()\n",
    "\n",
    "print(\"\\nBasket Sample:\")\n",
    "print(basket.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-Hot Encoded Basket Sample:\n",
      "   CustomerID  Auto Loan  Business Loan  Certificate of Deposit  \\\n",
      "0           1      False          False                   False   \n",
      "1           2       True          False                   False   \n",
      "2           3      False           True                   False   \n",
      "3           4      False           True                   False   \n",
      "4           5      False           True                   False   \n",
      "\n",
      "   Checking Account  Credit Card  Home Equity Loan  Investment Account  \\\n",
      "0             False         True             False               False   \n",
      "1             False        False              True                True   \n",
      "2             False         True             False               False   \n",
      "3             False         True             False               False   \n",
      "4             False         True             False               False   \n",
      "\n",
      "   Mortgage  Personal Loan  Retirement Account  Savings Account  Student Loan  \n",
      "0      True          False               False            False         False  \n",
      "1     False          False                True            False         False  \n",
      "2      True          False               False            False         False  \n",
      "3      True          False               False            False         False  \n",
      "4      True          False               False            False         False  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Transform the basket list into one-hot encoded format\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(basket['Product']).transform(basket['Product'])\n",
    "df_basket = pd.DataFrame(te_array, columns=te.columns_, index=basket['CustomerID'])\n",
    "df_basket.reset_index(inplace=True)  # Optionally keep CustomerID as a column\n",
    "\n",
    "print(\"\\nOne-Hot Encoded Basket Sample:\")\n",
    "print(df_basket.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets Sample:\n",
      "    support                                           itemsets\n",
      "0    0.2214                                        (Auto Loan)\n",
      "1    0.2901                                    (Business Loan)\n",
      "2    0.2590                           (Certificate of Deposit)\n",
      "3    0.2481                                 (Checking Account)\n",
      "4    0.2869                                      (Credit Card)\n",
      "..      ...                                                ...\n",
      "92   0.0591  (Auto Loan, Student Loan, Retirement Account, ...\n",
      "93   0.0578  (Investment Account, Auto Loan, Student Loan, ...\n",
      "94   0.0964  (Certificate of Deposit, Checking Account, Per...\n",
      "95   0.0574  (Investment Account, Home Equity Loan, Student...\n",
      "96   0.0406  (Investment Account, Student Loan, Retirement ...\n",
      "\n",
      "[97 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Drop CustomerID from the one-hot encoded DataFrame since it's not needed for Apriori\n",
    "df_onehot = df_basket.drop(columns=['CustomerID'])\n",
    "\n",
    "# Run the Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df_onehot, min_support=0.005, use_colnames=True)\n",
    "\n",
    "print(\"\\nFrequent Itemsets Sample:\")\n",
    "print(frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules from the frequent itemsets\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "# print(\"\\nAssociation Rules Sample:\")\n",
    "# print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "rules = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sets to lists so they can be JSON-serialized\n",
    "rules_clean = rules.copy()\n",
    "rules_clean['antecedents'] = rules_clean['antecedents'].apply(list)\n",
    "rules_clean['consequents'] = rules_clean['consequents'].apply(list)\n",
    "\n",
    "# Save as JSON Lines\n",
    "rules_clean.to_json(\"../data/rules.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Similar Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load JSON lines\n",
    "rules = pd.read_json(\"../data/rules.json\", lines=True)\n",
    "\n",
    "# Convert antecedents/consequents back to sets\n",
    "rules['antecedents'] = rules['antecedents'].apply(set)\n",
    "rules['consequents'] = rules['consequents'].apply(set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_next_products(customer_products, rules_df, min_conf, min_lift):\n",
    "    recommendations = set()\n",
    "    for _, row in rules_df.iterrows():\n",
    "        antecedent = list(row['antecedents'])\n",
    "        consequent = list(row['consequents'])\n",
    "        if set(antecedent).issubset(set(customer_products)) and row['confidence'] >= min_conf and row['lift'] >= min_lift:\n",
    "            recommendations.update(consequent)\n",
    "    return list(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_customer_similarity(customers_df):\n",
    "    # Select numeric and categorical features\n",
    "    numeric_cols = ['Age', 'Income', 'Credit Score', 'Tenure']\n",
    "    categorical_col = ['Segment']\n",
    "    \n",
    "    # Normalize numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    numeric_scaled = scaler.fit_transform(customers_df[numeric_cols])\n",
    "    \n",
    "    # One-hot encode Segment\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    segment_encoded = encoder.fit_transform(customers_df[categorical_col])\n",
    "    \n",
    "    # Combine features into single vector\n",
    "    combined_features = np.hstack((numeric_scaled, segment_encoded))\n",
    "    \n",
    "    # Compute cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(combined_features)\n",
    "    \n",
    "    # Return as DataFrame with CustomerID as index/columns\n",
    "    sim_df = pd.DataFrame(similarity_matrix, \n",
    "                          index=customers_df['CustomerID'], \n",
    "                          columns=customers_df['CustomerID'])\n",
    "    return sim_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Customer 200 has Mortgage. We recommend Credit Card. Now find best Credit Card variation\n",
    "\n",
    "# Load the Customers.csv first\n",
    "customers_df = pd.read_csv(\"../data/Customers.csv\")\n",
    "\n",
    "# Compute cosine similarity between all customers using their attributes\n",
    "sim_df = compute_customer_similarity(customers_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test set with 100 customers and their main product saved as 'customer_test.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the real data from the data folder\n",
    "df_customers = pd.read_csv(\"../data/Customers.csv\")\n",
    "df_transactions = pd.read_csv(\"../data/Transactions.csv\")\n",
    "\n",
    "# Get each customer's first product (sorted by transaction ID or date)\n",
    "df_first_product = df_transactions.sort_values(by=\"TransactionID\").groupby(\"CustomerID\").first().reset_index()\n",
    "df_first_product = df_first_product[['CustomerID', 'Product']]\n",
    "df_first_product.rename(columns={'Product': 'MainProduct'}, inplace=True)\n",
    "\n",
    "# Merge with customers\n",
    "df_customer_test = pd.merge(df_customers, df_first_product, on=\"CustomerID\", how=\"inner\")\n",
    "\n",
    "# Take any 100 customers for the test set\n",
    "df_customer_test = df_customer_test.sample(n=100, random_state=42)\n",
    "\n",
    "# Save to CSV\n",
    "df_customer_test.to_csv(\"../data/customer_test.csv\", index=False)\n",
    "\n",
    "print(\"✅ Test set with 100 customers and their main product saved as 'customer_test.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend Product variation based on Similar Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_variation_with_customer_similarity(customer_id, product, df_ratings, sim_df, top_n_similar_users=10):\n",
    "    if customer_id not in sim_df.index:\n",
    "        return None\n",
    "\n",
    "    # Get most similar customers\n",
    "    similar_customers = sim_df.loc[customer_id].sort_values(ascending=False)\n",
    "    similar_customers = similar_customers.drop(index=customer_id).head(top_n_similar_users).index.tolist()\n",
    "\n",
    "    # Filter ratings by these similar customers for the product\n",
    "    similar_ratings = df_ratings[(df_ratings['CustomerID'].isin(similar_customers)) &\n",
    "                                 (df_ratings['Product'] == product)]\n",
    "\n",
    "    if similar_ratings.empty:\n",
    "        return None\n",
    "\n",
    "    # Get highest-rated variation\n",
    "    top_variation = (similar_ratings.groupby('Variation')['Rating']\n",
    "                     .mean()\n",
    "                     .sort_values(ascending=False)\n",
    "                     .idxmax())\n",
    "    return top_variation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reverse Mortgage'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_variation_with_customer_similarity(\n",
    "    customer_id=1, \n",
    "    product=\"Mortgage\", \n",
    "    df_ratings=df_ratings, \n",
    "    sim_df=sim_df,top_n_similar_users=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_recommendation(customer_id, df_transactions, rules_df, df_ratings, sim_df, min_conf, min_lift):\n",
    "    # Step 1: Find what the customer already has\n",
    "    customer_products = df_transactions[df_transactions['CustomerID'] == customer_id]['Product'].unique().tolist()\n",
    "    \n",
    "    # Step 2: Get recommended products using Apriori rules\n",
    "    recommended_products = recommend_next_products(customer_products, rules_df, min_conf, min_lift)\n",
    "\n",
    "    # Step 3: Recommend best variation using customer-based similarity\n",
    "    recommendations = []\n",
    "    for prod in recommended_products:\n",
    "        best_variation = recommend_variation_with_customer_similarity(\n",
    "            customer_id, prod, df_ratings, sim_df, 10\n",
    "        )\n",
    "        recommendations.append({\n",
    "            'Product': prod,\n",
    "            'Variation': best_variation or \"Default\"\n",
    "        })\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investment Account</td>\n",
       "      <td>Robo Advisor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student Loan</td>\n",
       "      <td>Consolidation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retirement Account</td>\n",
       "      <td>Simple IRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home Equity Loan</td>\n",
       "      <td>Fixed Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto Loan</td>\n",
       "      <td>Refinance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Product      Variation\n",
       "0  Investment Account   Robo Advisor\n",
       "1        Student Loan  Consolidation\n",
       "2  Retirement Account     Simple IRA\n",
       "3    Home Equity Loan     Fixed Rate\n",
       "4           Auto Loan      Refinance"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions = pd.read_csv(\"../data/Transactions.csv\")\n",
    "# rules = pd.read_csv(\"../data/rules.csv\")  # assuming you've saved your Apriori rules\n",
    "\n",
    "recos = full_recommendation(\n",
    "    customer_id=6,\n",
    "    df_transactions=df_transactions,\n",
    "    rules_df=rules,\n",
    "    df_ratings=df_ratings,\n",
    "    sim_df=sim_df, min_conf=0.6, min_lift=2\n",
    ")\n",
    "\n",
    "pd.DataFrame(recos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
