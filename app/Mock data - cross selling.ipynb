{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.7)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikeras 0.4.1 requires packaging<22.0,>=0.21, but you have packaging 23.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (2.2.3)\n",
      "Collecting scikit-learn>=1.3.1 (from mlxtend)\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (3.9.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.28.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Collecting joblib>=0.13.2 (from mlxtend)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sujaysunilnagvekar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 1.4/1.4 MB 23.2 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 11.1/11.1 MB 18.8 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib, scikit-learn, mlxtend\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "  Attempting uninstall: mlxtend\n",
      "    Found existing installation: mlxtend 0.1.7\n",
      "    Uninstalling mlxtend-0.1.7:\n",
      "      Successfully uninstalled mlxtend-0.1.7\n",
      "Successfully installed joblib-1.4.2 mlxtend-0.23.4 scikit-learn-1.6.1\n"
     ]
    }
   ],
   "source": [
    "! py -m pip install mlxtend --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Random.randint() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m dob \u001b[38;5;241m=\u001b[39m fake\u001b[38;5;241m.\u001b[39mdate_of_birth(minimum_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m, maximum_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m75\u001b[39m)\n\u001b[0;32m     24\u001b[0m age \u001b[38;5;241m=\u001b[39m (datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mdate() \u001b[38;5;241m-\u001b[39m dob)\u001b[38;5;241m.\u001b[39mdays \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m365\u001b[39m\n\u001b[1;32m---> 25\u001b[0m income \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m credit_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mclip(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m \u001b[38;5;241m+\u001b[39m (income \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m), scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m), \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m850\u001b[39m))\n\u001b[0;32m     28\u001b[0m customer_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUST\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst_Name\u001b[39m\u001b[38;5;124m\"\u001b[39m: first_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCredit_Score\u001b[39m\u001b[38;5;124m\"\u001b[39m: credit_score\n\u001b[0;32m     44\u001b[0m })\n",
      "\u001b[1;31mTypeError\u001b[0m: Random.randint() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Setup\n",
    "fake = Faker()\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# -----------------------\n",
    "# 1. Generate Customers\n",
    "# -----------------------\n",
    "num_customers = 100\n",
    "customer_data = []\n",
    "\n",
    "for i in range(1, num_customers + 1):\n",
    "    is_male = random.choice([True, False])\n",
    "    first_name = fake.first_name_male() if is_male else fake.first_name_female()\n",
    "    last_name = fake.last_name()\n",
    "    gender = 'M' if is_male else 'F'\n",
    "    dob = fake.date_of_birth(minimum_age=18, maximum_age=75)\n",
    "    age = (datetime.now().date() - dob).days // 365\n",
    "    income = random.randint(20000, 150000)\n",
    "    credit_score = int(np.clip(np.random.normal(loc=600 + (income / 1000), scale=50), 300, 850))\n",
    "\n",
    "    customer_data.append({\n",
    "        \"Customer_ID\": f\"CUST{i:04d}\",\n",
    "        \"First_Name\": first_name,\n",
    "        \"Last_Name\": last_name,\n",
    "        \"Gender\": gender,\n",
    "        \"Date_of_Birth\": dob,\n",
    "        \"Age\": age,\n",
    "        \"Email\": fake.email(),\n",
    "        \"Phone\": fake.phone_number(),\n",
    "        \"Address\": fake.address().replace(\"\\n\", \", \"),\n",
    "        \"City\": fake.city(),\n",
    "        \"State\": fake.state(),\n",
    "        \"Postal_Code\": fake.postcode(),\n",
    "        \"Country\": \"USA\",\n",
    "        \"Annual_Income\": income,\n",
    "        \"Credit_Score\": credit_score\n",
    "    })\n",
    "\n",
    "df_customers = pd.DataFrame(customer_data)\n",
    "df_customers.to_csv(\"customers.csv\", index=False)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Generate Transactions\n",
    "# ----------------------------\n",
    "transaction_data = []\n",
    "categories = ['Grocery', 'Fuel', 'Dining', 'Travel', 'Medical', 'Baby', 'Education', 'Entertainment', 'Home', 'Salary']\n",
    "merchants = {\n",
    "    'Grocery': ['Walmart', 'Whole Foods', 'Kroger'],\n",
    "    'Fuel': ['Shell', 'Exxon', 'Chevron'],\n",
    "    'Dining': ['McDonald\\'s', 'Starbucks', 'Chipotle'],\n",
    "    'Travel': ['Delta', 'Airbnb', 'Uber'],\n",
    "    'Medical': ['CVS', 'Walgreens', 'Urgent Care'],\n",
    "    'Baby': ['BabyGap', 'Target', 'Pampers Store'],\n",
    "    'Education': ['Coursera', 'Udemy', 'University Bookstore'],\n",
    "    'Entertainment': ['Netflix', 'AMC Theatres', 'Spotify'],\n",
    "    'Home': ['Home Depot', 'Lowe\\'s', 'IKEA'],\n",
    "    'Salary': ['Company Payroll', 'Direct Deposit']\n",
    "}\n",
    "\n",
    "txn_id = 1\n",
    "for customer in df_customers['Customer_ID']:\n",
    "    num_txns = random.randint(5, 15)\n",
    "    for _ in range(num_txns):\n",
    "        category = random.choice(categories)\n",
    "        merchant = random.choice(merchants[category])\n",
    "        amount = round(random.uniform(10, 2000) if category != 'Salary' else random.uniform(3000, 10000), 2)\n",
    "        date = datetime.now() - timedelta(days=random.randint(0, 28))\n",
    "        \n",
    "        transaction_data.append({\n",
    "            \"Transaction_ID\": f\"TXN{txn_id:06d}\",\n",
    "            \"Customer_ID\": customer,\n",
    "            \"Timestamp\": date.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"Merchant\": merchant,\n",
    "            \"Category\": category,\n",
    "            \"Amount\": amount,\n",
    "            \"Description\": f\"{category} - {merchant}\"\n",
    "        })\n",
    "        txn_id += 1\n",
    "\n",
    "df_transactions = pd.DataFrame(transaction_data)\n",
    "df_transactions.to_csv(\"transactions.csv\", index=False)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Generate Product Table\n",
    "# -------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSVs\n",
    "df_customers = pd.read_csv(\"customers.csv\")\n",
    "df_transactions = pd.read_csv(\"transactions.csv\")\n",
    "\n",
    "# Ensure timestamp is in datetime format\n",
    "df_transactions[\"Timestamp\"] = pd.to_datetime(df_transactions[\"Timestamp\"])\n",
    "\n",
    "# Filter only last 4 weeks of transactions\n",
    "latest_date = df_transactions[\"Timestamp\"].max()\n",
    "cutoff_date = latest_date - pd.Timedelta(days=28)\n",
    "df_recent = df_transactions[df_transactions[\"Timestamp\"] >= cutoff_date]\n",
    "\n",
    "# Aggregate features per customer\n",
    "features = df_recent.groupby(\"Customer_ID\").agg(\n",
    "    Total_Spend=(\"Amount\", \"sum\"),\n",
    "    Num_Transactions=(\"Transaction_ID\", \"count\"),\n",
    "    Avg_Txn_Amount=(\"Amount\", \"mean\"),\n",
    "    Max_Txn_Amount=(\"Amount\", \"max\"),\n",
    "    Has_Salary_Credit=(\"Category\", lambda x: int(\"Salary\" in x.values))\n",
    ").reset_index()\n",
    "\n",
    "# Pivot category spend into separate columns\n",
    "category_spend = df_recent.pivot_table(\n",
    "    index=\"Customer_ID\",\n",
    "    columns=\"Category\",\n",
    "    values=\"Amount\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    ").add_prefix(\"Spend_\").reset_index()\n",
    "\n",
    "# Merge with customer demographics\n",
    "df_feature_store = (\n",
    "    features\n",
    "    .merge(category_spend, on=\"Customer_ID\", how=\"left\")\n",
    "    .merge(df_customers[[\"Customer_ID\", \"Age\", \"Annual_Income\", \"Credit_Score\"]], on=\"Customer_ID\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "df_feature_store.to_csv(\"feature_store.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ products.csv created with detailed product information.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Full product list with detailed columns\n",
    "products = [\n",
    "    (\"P001\", \"Starter Credit Card\", \"Credit Card\", \"Low\",\n",
    "     \"1% cashback on all purchases\",\n",
    "     \"New credit users, low spenders\",\n",
    "     \"Income > 20,000 and Credit Score > 600\",\n",
    "     \"$25 cashback on first $300 spend\"),\n",
    "    \n",
    "    (\"P002\", \"Everyday Saver\", \"Savings Account\", \"Low\",\n",
    "     \"4% interest, no maintenance fees\",\n",
    "     \"Customers starting savings\",\n",
    "     \"Open to all with minimum $100 deposit\",\n",
    "     \"$50 bonus for maintaining $1,000 balance for 3 months\"),\n",
    "    \n",
    "    (\"P003\", \"Smart Shopper Card\", \"Credit Card\", \"Mid\",\n",
    "     \"2% cashback on groceries & fuel\",\n",
    "     \"High grocery and fuel spenders\",\n",
    "     \"Income > 30,000 and Credit Score > 650\",\n",
    "     \"$50 cashback on first $500 spend\"),\n",
    "    \n",
    "    (\"P004\", \"Smart Budget Account\", \"Savings + Budget\", \"Mid\",\n",
    "     \"5% APY on goal-based savings\",\n",
    "     \"Budget-conscious savers\",\n",
    "     \"Income > 25,000\",\n",
    "     \"Free premium budgeting tools for 6 months\"),\n",
    "    \n",
    "    (\"P005\", \"Travel Rewards Elite\", \"Credit Card\", \"High\",\n",
    "     \"3x travel points, lounge access\",\n",
    "     \"Frequent travelers\",\n",
    "     \"Income > 70,000 and Credit Score > 700\",\n",
    "     \"$200 travel voucher after $5,000 spend\"),\n",
    "    \n",
    "    (\"P006\", \"Elite Wealth Plan\", \"Investment\", \"High\",\n",
    "     \"6-8% ROI, personal wealth advisor\",\n",
    "     \"High-income professionals\",\n",
    "     \"Income > 100,000 and Age > 30\",\n",
    "     \"1% bonus returns for first year\"),\n",
    "    \n",
    "    (\"P007\", \"Family Future Plan\", \"Insurance/Savings\", \"Mid-High\",\n",
    "     \"Child savings + life insurance combo\",\n",
    "     \"Families, new parents\",\n",
    "     \"Married, Age 25-45\",\n",
    "     \"$100 bonus on first year premium\"),\n",
    "    \n",
    "    (\"P008\", \"Student Flex Account\", \"Savings\", \"Student\",\n",
    "     \"No fees, education budgeting tools\",\n",
    "     \"Students under 25\",\n",
    "     \"Age < 25\",\n",
    "     \"$100 top-up on monthly deposits over $200\"),\n",
    "    \n",
    "    (\"P009\", \"Home Advantage Loan\", \"Loan\", \"Mid-High\",\n",
    "     \"Low-interest home loans\",\n",
    "     \"First-time home buyers\",\n",
    "     \"Home-related spend > $10,000\",\n",
    "     \"Reduced interest rate for bundled insurance\"),\n",
    "    \n",
    "    (\"P010\", \"Retirement Essentials\", \"Wealth + Health\", \"Senior\",\n",
    "     \"Pension fund + health perks\",\n",
    "     \"Customers over 60\",\n",
    "     \"Age > 60\",\n",
    "     \"$500 wellness bonus for first year\"),\n",
    "    \n",
    "    (\"P011\", \"FlexFuel Card\", \"Credit Card\", \"Low-Mid\",\n",
    "     \"3% cashback on fuel\",\n",
    "     \"Regular commuters\",\n",
    "     \"Fuel spend > $150/month\",\n",
    "     \"$50 fuel voucher after $500 spend\"),\n",
    "    \n",
    "    (\"P012\", \"Digital Nomad Saver\", \"Savings Account\", \"Mid\",\n",
    "     \"1.5% bonus APY for international use\",\n",
    "     \"Frequent travelers, remote workers\",\n",
    "     \"Travel spend > $500/month\",\n",
    "     \"No international transfer fees for 6 months\"),\n",
    "    \n",
    "    (\"P013\", \"HealthSecure Plan\", \"Health + Savings\", \"Mid\",\n",
    "     \"HSA integration, telehealth access\",\n",
    "     \"Health-conscious individuals\",\n",
    "     \"Medical spend > $200/month\",\n",
    "     \"$200 credit toward medical expenses\"),\n",
    "    \n",
    "    (\"P014\", \"GreenLife Investment\", \"ESG Investment\", \"Mid-High\",\n",
    "     \"5-9% returns in sustainable funds\",\n",
    "     \"Eco-conscious investors\",\n",
    "     \"Interest in ESG, Income > 40,000\",\n",
    "     \"$100 green bonus + 0.5% bonus returns\"),\n",
    "    \n",
    "    (\"P015\", \"Weekend Explorer Card\", \"Credit Card\", \"Mid\",\n",
    "     \"2.5% cashback on dining & entertainment\",\n",
    "     \"Social and active lifestyle\",\n",
    "     \"Dining + entertainment spend > $400/month\",\n",
    "     \"Free concert ticket after $2,000 spend\"),\n",
    "    \n",
    "    (\"P016\", \"CashBuilder Certificate\", \"CD / Fixed Deposit\", \"Low-Mid\",\n",
    "     \"4.75% fixed interest (6 months)\",\n",
    "     \"Idle balance savers\",\n",
    "     \"Idle funds > $5,000\",\n",
    "     \"$25 bonus for auto-renewal\"),\n",
    "    \n",
    "    (\"P017\", \"Lifestyle Bundle Plus\", \"Bundle (3-in-1)\", \"High\",\n",
    "     \"Credit + Wealth + Travel perks\",\n",
    "     \"Affluent, multi-product users\",\n",
    "     \"Income > 100,000\",\n",
    "     \"$300 statement credit + concierge onboarding\"),\n",
    "    \n",
    "    (\"P018\", \"BabyStart Trust Plan\", \"Child Investment\", \"Mid\",\n",
    "     \"Custodial account for education\",\n",
    "     \"Parents with young children\",\n",
    "     \"Children < 5 years\",\n",
    "     \"1st year fees waived + $100 education bonus\"),\n",
    "    \n",
    "    (\"P019\", \"MoveSmart Relocation Loan\", \"Loan\", \"Mid\",\n",
    "     \"0% for 6 months, flexible repayment\",\n",
    "     \"Customers with large recent spends\",\n",
    "     \"One-time spend > $5,000\",\n",
    "     \"$150 moving voucher\"),\n",
    "    \n",
    "    (\"P020\", \"SideHustle Account\", \"Business Checking\", \"Low-Mid\",\n",
    "     \"No fees, invoice management\",\n",
    "     \"Freelancers, side businesses\",\n",
    "     \"Self-employed, 3+ biz txns/month\",\n",
    "     \"$75 bonus for linking payment gateway\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"Product_ID\", \"Product_Name\", \"Product_Type\", \"Tier\",\n",
    "           \"Features_Benefits\", \"Target_Behavior\", \"Eligibility_Criteria\", \"Special_Offer\"]\n",
    "\n",
    "df_products = pd.DataFrame(products, columns=columns)\n",
    "\n",
    "for col in [\"Features_Benefits\", \"Special_Offer\"]:\n",
    "    df_products[col] = df_products[col].str.replace(\"$\", \"USD \", regex=False)\n",
    "\n",
    "# Save to CSV\n",
    "df_products.to_csv(\"products.csv\", index=False)\n",
    "\n",
    "print(\"✅ products.csv created with detailed product information.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enhanced feature_store_enhanced.csv created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df_transactions = pd.read_csv(\"transactions.csv\")\n",
    "df_customers = pd.read_csv(\"customers.csv\")\n",
    "df_feature_store = pd.read_csv(\"feature_store.csv\")\n",
    "\n",
    "# Ensure Timestamp is datetime\n",
    "df_transactions[\"Timestamp\"] = pd.to_datetime(df_transactions[\"Timestamp\"])\n",
    "\n",
    "# 1️⃣ Calculate Aggregation_Days per customer\n",
    "agg_days = df_transactions.groupby(\"Customer_ID\").agg(\n",
    "    First_Txn_Date=(\"Timestamp\", \"min\"),\n",
    "    Last_Txn_Date=(\"Timestamp\", \"max\")\n",
    ")\n",
    "agg_days[\"Aggregation_Days\"] = (agg_days[\"Last_Txn_Date\"] - agg_days[\"First_Txn_Date\"]).dt.days + 1\n",
    "agg_days = agg_days[[\"Aggregation_Days\"]].reset_index()\n",
    "\n",
    "# 2️⃣ Calculate Spend Variability (std deviation of Amount)\n",
    "spend_var = df_transactions.groupby(\"Customer_ID\").agg(\n",
    "    Spend_Variability=(\"Amount\", \"std\")\n",
    ").fillna(0).reset_index()\n",
    "\n",
    "# 3️⃣ Calculate Salary_to_Spend_Ratio\n",
    "salary_spend = df_transactions.groupby([\"Customer_ID\", \"Category\"]).agg(Total_Category_Spend=(\"Amount\", \"sum\")).reset_index()\n",
    "salary = salary_spend[salary_spend[\"Category\"] == \"Salary\"][[\"Customer_ID\", \"Total_Category_Spend\"]].rename(columns={\"Total_Category_Spend\": \"Total_Salary\"})\n",
    "total_spend = df_feature_store[[\"Customer_ID\", \"Total_Spend\"]]\n",
    "\n",
    "salary_ratio = pd.merge(total_spend, salary, on=\"Customer_ID\", how=\"left\").fillna(0)\n",
    "salary_ratio[\"Salary_to_Spend_Ratio\"] = salary_ratio[\"Total_Salary\"] / salary_ratio[\"Total_Spend\"]\n",
    "salary_ratio = salary_ratio[[\"Customer_ID\", \"Salary_to_Spend_Ratio\"]]\n",
    "\n",
    "# 4️⃣ Top Spend Category\n",
    "top_category = df_transactions[df_transactions[\"Category\"] != \"Salary\"].groupby([\"Customer_ID\", \"Category\"]).agg(\n",
    "    Category_Spend=(\"Amount\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "top_spend_cat = top_category.loc[top_category.groupby(\"Customer_ID\")[\"Category_Spend\"].idxmax()]\n",
    "top_spend_cat = top_spend_cat[[\"Customer_ID\", \"Category\"]].rename(columns={\"Category\": \"Top_Spend_Category\"})\n",
    "\n",
    "# 5️⃣ Idle Balance Estimate\n",
    "income = df_customers[[\"Customer_ID\", \"Annual_Income\"]]\n",
    "idle_balance = pd.merge(total_spend, income, on=\"Customer_ID\", how=\"left\")\n",
    "idle_balance[\"Idle_Balance_Estimate\"] = idle_balance[\"Annual_Income\"] - idle_balance[\"Total_Spend\"]\n",
    "idle_balance = idle_balance[[\"Customer_ID\", \"Idle_Balance_Estimate\"]]\n",
    "\n",
    "# Merge all new features\n",
    "df_enhanced = df_feature_store.merge(agg_days, on=\"Customer_ID\", how=\"left\")\n",
    "df_enhanced = df_enhanced.merge(spend_var, on=\"Customer_ID\", how=\"left\")\n",
    "df_enhanced = df_enhanced.merge(salary_ratio, on=\"Customer_ID\", how=\"left\")\n",
    "df_enhanced = df_enhanced.merge(top_spend_cat, on=\"Customer_ID\", how=\"left\")\n",
    "df_enhanced = df_enhanced.merge(idle_balance, on=\"Customer_ID\", how=\"left\")\n",
    "\n",
    "# Fill any remaining NaNs\n",
    "df_enhanced = df_enhanced.fillna({\n",
    "    \"Spend_Variability\": 0,\n",
    "    \"Salary_to_Spend_Ratio\": 0,\n",
    "    \"Top_Spend_Category\": \"Unknown\",\n",
    "    \"Aggregation_Days\": 28  # Default if only 1 txn\n",
    "})\n",
    "\n",
    "# Save enhanced feature store\n",
    "df_enhanced.to_csv(\"feature_store_enhanced.csv\", index=False)\n",
    "\n",
    "print(\"✅ Enhanced feature_store_enhanced.csv created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ customer_products.csv created with assigned owned products.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load customer data and product catalog\n",
    "df_customers = pd.read_csv(\"customers.csv\")\n",
    "df_products = pd.read_csv(\"products.csv\")\n",
    "\n",
    "# Prepare list to store ownership records\n",
    "customer_products = []\n",
    "\n",
    "# Define logic-based exclusions\n",
    "def get_eligible_products(customer_row):\n",
    "    age = customer_row['Age']\n",
    "    eligible_products = df_products.copy()\n",
    "\n",
    "    # Exclude Student Account for non-students\n",
    "    if age > 25:\n",
    "        eligible_products = eligible_products[eligible_products['Product_ID'] != 'P008']\n",
    "    \n",
    "    # Exclude Retirement plan for young customers\n",
    "    if age < 55:\n",
    "        eligible_products = eligible_products[eligible_products['Product_ID'] != 'P010']\n",
    "    \n",
    "    return eligible_products['Product_ID'].tolist()\n",
    "\n",
    "# Generate ownership for each customer\n",
    "for idx, customer in df_customers.iterrows():\n",
    "    cust_id = customer['Customer_ID']\n",
    "    \n",
    "    # Get eligible products\n",
    "    eligible_products = get_eligible_products(customer)\n",
    "    \n",
    "    # Randomly assign 1 to 3 products\n",
    "    owned_count = random.randint(1, 3)\n",
    "    owned_products = random.sample(eligible_products, owned_count)\n",
    "    \n",
    "    for prod_id in owned_products:\n",
    "        customer_products.append({\n",
    "            \"Customer_ID\": cust_id,\n",
    "            \"Product_ID\": prod_id\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df_customer_products = pd.DataFrame(customer_products)\n",
    "\n",
    "# Save to CSV\n",
    "df_customer_products.to_csv(\"customer_products.csv\", index=False)\n",
    "\n",
    "print(\"✅ customer_products.csv created with assigned owned products.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded into cross_selling.db\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load CSVs\n",
    "df_customers = pd.read_csv(\"customers.csv\")\n",
    "df_transactions = pd.read_csv(\"transactions.csv\")\n",
    "df_products = pd.read_csv(\"products.csv\")\n",
    "df_feature_store = pd.read_csv(\"feature_store_enhanced.csv\")  # From earlier step\n",
    "df_customer_products = pd.read_csv(\"customer_products.csv\")  # From earlier step\n",
    "\n",
    "# Create SQLite DB\n",
    "conn = sqlite3.connect(\"cross_selling.db\")\n",
    "\n",
    "# Write tables\n",
    "df_customers.to_sql(\"customers\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"transactions\", conn, if_exists=\"replace\", index=False)\n",
    "df_products.to_sql(\"products\", conn, if_exists=\"replace\", index=False)\n",
    "df_feature_store.to_sql(\"feature_store\", conn, if_exists=\"replace\", index=False)\n",
    "df_customer_products.to_sql(\"customer_products\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "conn.close()\n",
    "print(\"✅ Data loaded into cross_selling.db\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from langchain.agents import tool\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from prompts import *\n",
    "\n",
    "conn = sqlite3.connect(\"cross_selling.db\")\n",
    "\n",
    "@tool\n",
    "def fetch_customer_profile(name: str) -> str:\n",
    "    \"\"\"Fetch basic customer profile by full name.\"\"\"\n",
    "    df = pd.read_sql(f\"SELECT * FROM customers WHERE First_Name || ' ' || Last_Name = '{name}'\", conn)\n",
    "    return df.to_json(orient=\"records\") if not df.empty else \"Customer not found.\"\n",
    "\n",
    "@tool\n",
    "def analyze_customer_behavior(customer_id: str) -> str:\n",
    "    \"\"\"Provides a detailed analysis of customer behavior, spending patterns, and financial signals.\"\"\"\n",
    "    df = pd.read_sql(f\"SELECT * FROM feature_store WHERE Customer_ID = '{customer_id}'\", conn)\n",
    "    if df.empty:\n",
    "        return \"No behavior data found for this customer.\"\n",
    "    \n",
    "    row = df.iloc[0]\n",
    "    insights = []\n",
    "\n",
    "    # 1️⃣ Aggregation Period\n",
    "    insights.append(f\"Analysis based on {row['Aggregation_Days']} days of transaction data.\")\n",
    "\n",
    "    # 2️⃣ Spending Overview\n",
    "    insights.append(f\"Total spending during this period is ${row['Total_Spend']:.2f} across {row['Num_Transactions']} transactions.\")\n",
    "    insights.append(f\"Average transaction amount is ${row['Avg_Txn_Amount']:.2f}, with a maximum single transaction of ${row['Max_Txn_Amount']:.2f}.\")\n",
    "    \n",
    "    # 3️⃣ Key Spending Categories\n",
    "    category_flags = []\n",
    "    if row.get(\"Spend_Grocery\", 0) > 500:\n",
    "        category_flags.append(f\"Grocery: ${row['Spend_Grocery']:.2f}\")\n",
    "    if row.get(\"Spend_Travel\", 0) > 800:\n",
    "        category_flags.append(f\"Travel: ${row['Spend_Travel']:.2f}\")\n",
    "    if row.get(\"Spend_Fuel\", 0) > 150:\n",
    "        category_flags.append(f\"Fuel: ${row['Spend_Fuel']:.2f}\")\n",
    "    if row.get(\"Spend_Medical\", 0) > 200:\n",
    "        category_flags.append(f\"Medical: ${row['Spend_Medical']:.2f}\")\n",
    "    if row.get(\"Spend_Entertainment\", 0) > 300:\n",
    "        category_flags.append(f\"Entertainment: ${row['Spend_Entertainment']:.2f}\")\n",
    "\n",
    "    if category_flags:\n",
    "        insights.append(\"Significant spending detected in categories: \" + \"; \".join(category_flags))\n",
    "    else:\n",
    "        insights.append(f\"Primary spending category is {row['Top_Spend_Category']}.\")\n",
    "\n",
    "    # 4️⃣ Income & Salary Patterns\n",
    "    if row[\"Has_Salary_Credit\"]:\n",
    "        insights.append(\"Regular salary deposits detected, indicating stable income.\")\n",
    "    if row[\"Salary_to_Spend_Ratio\"] > 0.5:\n",
    "        insights.append(f\"Healthy disposable income, with a Salary-to-Spend Ratio of {row['Salary_to_Spend_Ratio']:.2f}.\")\n",
    "\n",
    "    # 5️⃣ Financial Profile\n",
    "    if row[\"Annual_Income\"] > 100000:\n",
    "        insights.append(f\"High annual income: ${row['Annual_Income']}.\")\n",
    "    elif row[\"Annual_Income\"] > 60000:\n",
    "        insights.append(f\"Moderate annual income: ${row['Annual_Income']}.\")\n",
    "\n",
    "    if row[\"Credit_Score\"] >= 750:\n",
    "        insights.append(f\"Excellent credit score: {row['Credit_Score']}.\")\n",
    "    elif row[\"Credit_Score\"] >= 700:\n",
    "        insights.append(f\"Good credit score: {row['Credit_Score']}.\")\n",
    "    else:\n",
    "        insights.append(f\"Credit score is {row['Credit_Score']}.\")\n",
    "\n",
    "    # 6️⃣ Spend Variability\n",
    "    if row[\"Spend_Variability\"] > 500:\n",
    "        insights.append(f\"High variability in spending, suggesting inconsistent transaction amounts.\")\n",
    "    else:\n",
    "        insights.append(f\"Consistent spending behavior with low variability.\")\n",
    "\n",
    "    # 7️⃣ Idle Balance Potential\n",
    "    if row[\"Idle_Balance_Estimate\"] > 5000:\n",
    "        insights.append(f\"Estimated idle balance of ${row['Idle_Balance_Estimate']:.2f}, indicating potential for savings or investment products.\")\n",
    "\n",
    "    return \" | \".join(insights)\n",
    "\n",
    "@tool\n",
    "def fetch_product_catalog(dummy_input: str) -> str:\n",
    "    \"\"\"Returns the bank's product catalog for cross-selling.\"\"\"\n",
    "    df = pd.read_sql(\"SELECT * FROM products\", conn)\n",
    "    return df.to_json(orient=\"records\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def scientific_calculator(expression: str) -> str:\n",
    "    \"\"\"Performs safe scientific calculations. Provide expressions like '1250 / 28' or 'sqrt(256)'.\"\"\"\n",
    "    import math\n",
    "    allowed_names = {k: v for k, v in math.__dict__.items() if not k.startswith(\"__\")}\n",
    "    allowed_names['abs'] = abs\n",
    "\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}}, allowed_names)\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def fetch_owned_products(customer_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the list of products currently owned by the customer.\n",
    "    The LLM should avoid recommending these products again.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "            SELECT p.Product_ID, p.Product_Name, p.Product_Type\n",
    "            FROM customer_products cp\n",
    "            JOIN products p ON cp.Product_ID = p.Product_ID\n",
    "            WHERE cp.Customer_ID = '{customer_id}'\n",
    "        \"\"\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    \n",
    "    if df.empty:\n",
    "        return \"This customer does not own any products currently.\"\n",
    "    \n",
    "    # Return a readable list\n",
    "    owned_list = df[['Product_ID', 'Product_Name', 'Product_Type']].to_dict(orient='records')\n",
    "    return f\"Customer currently owns the following products: {owned_list}\"\n",
    "\n",
    "@tool\n",
    "def fetch_schema_info(dummy_input: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Returns the pre‐built SCHEMA_INFO string describing your database schema.\n",
    "    \"\"\"\n",
    "    return SCHEMA_INFO\n",
    "\n",
    "\n",
    "@tool\n",
    "def run_sql(sql_statements: str) -> str:\n",
    "    \"\"\"\n",
    "    Executes one or more semicolon-separated SQL statements against `conn`.\n",
    "    - SELECT queries: returns top 5 rows as a markdown table.\n",
    "    - Other queries: returns success/failure status.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for stmt in sql_statements.split(\";\"):\n",
    "        stmt = stmt.strip()\n",
    "        if not stmt:\n",
    "            continue\n",
    "        try:\n",
    "            if stmt.lower().startswith(\"select\"):\n",
    "                df = pd.read_sql(stmt, conn)\n",
    "                if df.empty:\n",
    "                    outputs.append(f\"✅ `{stmt}` returned no rows.\")\n",
    "                else:\n",
    "                    table = df.head(5).to_markdown(index=False)\n",
    "                    outputs.append(f\"✅ Results for `{stmt}`:\\n\\n{table}\")\n",
    "            else:\n",
    "                conn.execute(stmt)\n",
    "                conn.commit()\n",
    "                outputs.append(f\"✅ Executed `{stmt}` successfully.\")\n",
    "        except Exception as e:\n",
    "            outputs.append(f\"❌ Error executing `{stmt}`:\\n{str(e)}\")\n",
    "    return \"\\n\\n\".join(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_customer_profile.description = \"Fetch the customer's demographic and financial profile by full name.\"\n",
    "\n",
    "fetch_product_catalog.description = \"Retrieve the complete product catalog including features, target behaviors, eligibility criteria, and special offers.\"\n",
    "\n",
    "fetch_owned_products.description = \"Get a list of products already owned by the customer to avoid duplicate recommendations.\"\n",
    "\n",
    "scientific_calculator.description = \"Perform numeric calculations such as averages, ratios, or thresholds to support financial reasoning.\"\n",
    "\n",
    "fetch_schema_info.description = (\n",
    "    \"Use this tool to retrieve the database schema (tables, columns, types) \"\n",
    "    \"from the predefined SCHEMA_INFO string before using run_sql rool\"\n",
    ")\n",
    "\n",
    "run_sql.description = (\n",
    "    \"Use this tool to execute raw SQL statements. \"\n",
    "    \"Accepts one or multiple semicolon-separated queries. \"\n",
    "    \"SELECT statements return a markdown table of top 5 rows; \"\n",
    "    \"other statements return execution status.\"\n",
    ")\n",
    "\n",
    "analyze_customer_behavior.description = (\n",
    "    \"Use this ONLY to summarize customer behavior patterns for making product recommendations. \"\n",
    "    \"Do NOT use this tool to answer specific data questions like amounts spent.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_DEPLOYMENT_ENDPOINT = \"https://az-openai-document-question-answer-service.openai.azure.com/\" \n",
    "OPENAI_API_KEY = \"5d24331966b648738e5003caad552df8\" \n",
    "OPENAI_API_VERSION = \"2023-05-15\"\n",
    "\n",
    "OPENAI_DEPLOYMENT_NAME = \"az-gpt_35_model\"\n",
    "OPENAI_MODEL_NAME=\"gpt-3.5-turbo\"\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = \"az-embedding_model\" \n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "\n",
    "encoding_name = \"cl100k_base\"\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "                        temperature=0.1,\n",
    "                        deployment_name=OPENAI_DEPLOYMENT_NAME,\n",
    "                        model_name=OPENAI_MODEL_NAME,\n",
    "                        azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "                        openai_api_version=OPENAI_API_VERSION,\n",
    "                        openai_api_key=OPENAI_API_KEY            \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: fetch_customer_profile\n",
      "Action Input: Kevin Fleming\u001b[0m\u001b[36;1m\u001b[1;3m[{\"Customer_ID\":\"CUST0010\",\"First_Name\":\"Kevin\",\"Last_Name\":\"Fleming\",\"Gender\":\"M\",\"Date_of_Birth\":\"1975-03-27\",\"Age\":50,\"Email\":\"gabriellehansen@example.org\",\"Phone\":\"(742)374-6367x9468\",\"Address\":\"95733 Melody Islands Apt. 230, West Valerie, AK 25231\",\"City\":\"North Kathyburgh\",\"State\":\"Minnesota\",\"Postal_Code\":61475,\"Country\":\"USA\",\"Annual_Income\":113850,\"Credit_Score\":740}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: run_sql\n",
      "Action Input: SELECT * FROM Transactions WHERE Customer_ID = 'CUST0010' AND Category = 'Fuel';\u001b[0m\u001b[36;1m\u001b[1;3m✅ Results for `SELECT * FROM Transactions WHERE Customer_ID = 'CUST0010' AND Category = 'Fuel'`:\n",
      "\n",
      "| Transaction_ID   | Customer_ID   | Timestamp           | Merchant   | Category   |   Amount | Description   |\n",
      "|:-----------------|:--------------|:--------------------|:-----------|:-----------|---------:|:--------------|\n",
      "| TXN000103        | CUST0010      | 2025-04-04 11:24:43 | Exxon      | Fuel       |   821.12 | Fuel - Exxon  |\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: Kevin Fleming spent USD 821.12 on Fuel.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "import textwrap\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", react_prompt),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"ai\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tools = [fetch_customer_profile, analyze_customer_behavior, fetch_product_catalog, scientific_calculator, fetch_owned_products, fetch_schema_info, run_sql  ]\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt   # Optional. If omitted, uses LangChain's default ReAct prompt\n",
    ")\n",
    "\n",
    "# 4. Agent Executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "user_query = \"How much did Kevin Fleming spend on Fuel\"\n",
    "# user_query = \"Recommend products for Kevin Fleming based on his current products and expenditures.\"\n",
    "response = agent_executor.invoke({\"input\": user_query})\n",
    "\n",
    "output_text = response.get('output', '')\n",
    "\n",
    "# Pretty print with wrapping at 100 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_recommendation_summary(raw_text):\n",
    "    # Remove initial label if present\n",
    "    raw_text = raw_text.replace(\"**Recommendation Summary:**\", \"\").strip()\n",
    "\n",
    "    # Split by numbering (assuming '1.' and '2.' structure)\n",
    "    parts = raw_text.split(\" 2. \")\n",
    "    rec_1 = parts[0].strip()\n",
    "    rec_2 = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "\n",
    "    formatted_output = \"Recommendation Summary:\\n\\n\"\n",
    "\n",
    "    for idx, rec in enumerate([rec_1, rec_2], start=1):\n",
    "        if not rec:\n",
    "            continue\n",
    "        # Split the recommendation into lines by bullet points\n",
    "        lines = rec.split(\" - \")\n",
    "        title = lines[0].strip()\n",
    "        bullets = lines[1:]\n",
    "\n",
    "        formatted_output += f\"{idx}. {title}\\n\"\n",
    "        for bullet in bullets:\n",
    "            bullet = bullet.replace(\"Eligibility Criteria\", \"Eligibility Criteria\") \\\n",
    "                           .replace(\"Reason\", \"Reason\") \\\n",
    "                           .replace(\"Benefit\", \"Benefit\")\n",
    "            formatted_output += f\"   - {bullet.strip()}\\n\"\n",
    "        formatted_output += \"\\n\"\n",
    "\n",
    "    return textwrap.dedent(formatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation Summary:\n",
      "\n",
      "1. **Transactions of Kevin Fleming:**\n",
      "\n",
      "| Transaction_ID   | Customer_ID   | Timestamp           | Merchant       | Category      |   Amount | Description             |\n",
      "|:-----------------|:--------------|:--------------------|:---------------|:--------------|---------:|:------------------------|\n",
      "| TXN000092        | CUST0010      | 2025-04-04 11:24:43 | Starbucks      | Dining        |  1338.48 | Dining\n",
      "   - Starbucks      |\n",
      "| TXN000093        | CUST0010      | 2025-03-24 11:24:43 | Direct Deposit | Salary        |  9650.28 | Salary\n",
      "   - Direct Deposit |\n",
      "| TXN000094        | CUST0010      | 2025-03-24 11:24:43 | Spotify        | Entertainment |  1631.86 | Entertainment\n",
      "   - Spotify |\n",
      "| TXN000095        | CUST0010      | 2025-04-04 11:24:43 | Lowe's         | Home          |  1662.83 | Home\n",
      "   - Lowe's           |\n",
      "| TXN000096        | CUST0010      | 2025-04-06 11:24:43 | Netflix        | Entertainment |  1489.87 | Entertainment\n",
      "   - Netflix |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_recommendation_summary(output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
