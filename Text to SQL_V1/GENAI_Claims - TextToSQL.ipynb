{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\SujaySunilNagvekar\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\SujaySunilNagvekar\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~=mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\SujaySunilNagvekar\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~0mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "langchain-experimental 0.0.57 requires langchain<0.2.0,>=0.1.15, but you have langchain 0.2.11 which is incompatible.\n",
      "langchain-experimental 0.0.57 requires langchain-core<0.2.0,>=0.1.41, but you have langchain-core 0.2.24 which is incompatible.\n",
      "llama-index-embeddings-openai 0.1.11 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.20 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.1.6 requires llama-index-core<0.11.0,>=0.10.0, but you have llama-index-core 0.11.20 which is incompatible.\n",
      "llama-index-llms-openai 0.1.11 requires llama-index-core<0.11.0,>=0.10.19, but you have llama-index-core 0.11.20 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.1.9 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.20 which is incompatible.\n",
      "llama-index-program-openai 0.1.6 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.20 which is incompatible.\n",
      "llama-index-question-gen-openai 0.1.3 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.20 which is incompatible.\n",
      "llama-index-readers-file 0.1.22 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.20 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.1.6 requires llama-index-core<0.11.0,>=0.10.7, but you have llama-index-core 0.11.20 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! py -m pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import sqlite3\n",
    "from langchain_community.vectorstores.faiss import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_DEPLOYMENT_ENDPOINT = \"https://az-openai-document-question-answer-service.openai.azure.com/\" \n",
    "OPENAI_API_KEY = \"5d24331966b648738e5003caad552df8\" \n",
    "OPENAI_API_VERSION = \"2023-05-15\"\n",
    "\n",
    "OPENAI_DEPLOYMENT_NAME = \"az-gpt_35_model\"\n",
    "OPENAI_MODEL_NAME=\"gpt-3.5-turbo\"\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = \"az-embedding_model\" \n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "\n",
    "encoding_name = \"cl100k_base\"\n",
    "\n",
    "csv_file = \"C:\\\\Users\\\\SujaySunilNagvekar\\\\VM\\\\GEN AI\\\\Claims\\\\vm-GenAI_BI\\\\Text to SQL_V1\\\\data\\\\agg_claim_data.csv\"\n",
    "### Cohere API key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "                        temperature=0.1,\n",
    "                        deployment_name=OPENAI_DEPLOYMENT_NAME,\n",
    "                        model_name=OPENAI_MODEL_NAME,\n",
    "                        azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "                        openai_api_version=OPENAI_API_VERSION,\n",
    "                        openai_api_key=OPENAI_API_KEY            \n",
    "                    )\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(openai_api_key=OPENAI_API_KEY,\n",
    "                                            deployment=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "                                            model=OPENAI_ADA_EMBEDDING_MODEL_NAME,\n",
    "                                            azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT)\n",
    "\n",
    "def get_embedding():\n",
    "    return embedding_model\n",
    "# data = load_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV into SQLite\n",
    "def load_csv_to_sqlite(csv_file, db_file, table_name):\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    df = pd.read_csv(csv_file, encoding='latin-1')\n",
    "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    conn.close()\n",
    "    print(f\"Data from {csv_file} loaded into SQLite table {table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique loss causes: ['Animal Collision', 'All Other Property Losses', 'WATER BACK-UP OF SEWERS & DRAINS', 'Wind', 'ANIMAL COLLISION', 'Glass breakage', 'FIRE', 'Falling or moving object', 'ALL OTHERS', 'CANINE/FELINE', 'WIND', 'Hail excluding losses only to roof', 'Hail Loss only to roof', 'HAIL', 'WATER DAMAGE', 'MYSTERIOUS DISAPPERANCEE - ON PREMISES', 'Hail', 'THEFT ON PREMISES', 'Collision with motor vehicle', 'TOTAL THEFT', 'ALL OTHER', 'All Other', 'VEHICLES OR AIRCRAFT', 'Tire Loss', 'DOG BITES', 'Water Back-up of Sewers & Drains', 'Water and Sewer Line', 'Windstorm', 'GLASS', 'Malicious mischief and vandalism', 'Water Damage', 'Fireplaces', 'MEDICAL PAYMENTS', 'VANDALISM', 'All Other Liability Losses', 'LIGHTNING', 'FLOOD', 'WATER DAMAGE (EXCLUDING FLOOD)', 'Medical Payments', 'WINDSTORM', 'WATERCRAFT - ALL OTHER (BOATOWNERS ONLY)', 'Lightning', 'MOLD - WET/DRY ROT', 'Theft On Premises', 'FREEZING, ICE DAM, COLLAPSE DUE TO WEIGHT OF ICE AND SNOW', 'BREAKAGE', 'Theft of entire vehicle', 'Canine / Feline', 'Property Damage', 'Theft Audio or other parts', 'Collision with fixed object', 'THEFT OFF PREMISES (AUTO)', 'Vehicles', 'WATERCRAFT - OUTBOARD ONLY (BOATOWNERS ONLY)', 'IM ONLY - Mysterious Disappearance - On Premises', 'THEFT (BURGLARY OR ROBBERY) - OFF PREMISES', 'PROPERTY DAMAGE', 'MYSTERIOUS DISAPPERANCEE - OFF PREMISES', 'ALL OTHER PHYSICAL DAMAGE', 'Collision with other object', 'Fire', 'CHILDREN', 'FLOOD OR SEWER BACKUP', 'Collapse - Non Weather Related', 'Other', 'WATER AND SEWER LINE', 'ELECTRICAL', 'COLLAPSE - NON WEATHER RELATED', 'PARTIAL FIRE', 'IM ONLY - Breakage', 'Equipment Breakdown', 'SMOKE', 'Collapse due to Weight of Ice and Snow', 'Fire (partial)', 'Ice Dam', 'EXPLOSION', 'FIREPLACES', 'Burglary, Theft and Robbery', 'Freezing', 'TOTAL FIRE', 'COLLISION', 'Vandalism', 'IM ONLY - Mysterious Disappearance - Off Premises', 'Flood', 'PARTIAL THEFT', 'Theft Off Premises (Auto)', 'Rear-end collision']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Get unique loss_cause values\n",
    "unique_loss_causes = df['loss_cause'].dropna().unique().tolist()\n",
    "print(\"Unique loss causes:\", unique_loss_causes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created for loss causes!\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "\n",
    "\n",
    "# Generate embeddings for unique loss causes\n",
    "loss_cause_embeddings = embedding_model.embed_documents(unique_loss_causes)\n",
    "\n",
    "faiss_store = FAISS.from_texts(\n",
    "    texts=unique_loss_causes,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "print(\"FAISS index created for loss causes!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest match for 'glass breakage': Glass breakage\n"
     ]
    }
   ],
   "source": [
    "# User query\n",
    "user_query = \"glass breakage\"\n",
    "\n",
    "# Perform similarity search\n",
    "matches = faiss_store.similarity_search(user_query, k=1)\n",
    "\n",
    "# Get the closest match\n",
    "if matches:\n",
    "    closest_match = matches[0].page_content  # Retrieve the matched content\n",
    "    print(f\"Closest match for '{user_query}': {closest_match}\")\n",
    "else:\n",
    "    print(\"No close match found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file = \"claims.db\"\n",
    "table_name = \"claims\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from C:\\Users\\SujaySunilNagvekar\\VM\\GEN AI\\Claims\\vm-GenAI_BI\\Text to SQL_V1\\data\\agg_claim_data.csv loaded into SQLite table claims.\n"
     ]
    }
   ],
   "source": [
    "load_csv_to_sqlite(csv_file, db_file, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|    | claim_no   |\n",
      "+====+============+\n",
      "|  0 | CA0000001  |\n",
      "+----+------------+\n",
      "|  1 | CA0000005  |\n",
      "+----+------------+\n",
      "|  2 | CA0000006  |\n",
      "+----+------------+\n",
      "|  3 | CA0000015  |\n",
      "+----+------------+\n",
      "|  4 | CA0000022  |\n",
      "+----+------------+\n",
      "|  5 | CA0000043  |\n",
      "+----+------------+\n",
      "|  6 | CA0000058  |\n",
      "+----+------------+\n",
      "|  7 | CA0000074  |\n",
      "+----+------------+\n",
      "|  8 | CA0000075  |\n",
      "+----+------------+\n",
      "|  9 | CA0000081  |\n",
      "+----+------------+\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Reconnect to the SQLite database\n",
    "conn = sqlite3.connect(\"claims.db\")\n",
    "\n",
    "# Query to fetch the top 10 rows from the Claims table\n",
    "query = \"SELECT claim_no FROM claims WHERE loss_cause LIKE '%ANIMAL COLLISION%' ORDER BY claim_no LIMIT 10;\"\n",
    "\n",
    "# Use pandas to execute the query and load the results into a DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Print the DataFrame as a formatted table\n",
    "print(tabulate(df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table_schema():\n",
    "    schema = [\n",
    "        {\"Column Name\": \"claim_no\", \"Data Type\": \"VARCHAR\", \"Null\": \"NO\", \"Primary Key\": \"YES\"},\n",
    "        {\"Column Name\": \"fnol_call\", \"Data Type\": \"VARCHAR\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"LossDate\", \"Data Type\": \"DATE\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"loss_cause\", \"Data Type\": \"VARCHAR\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"loss_location_zip\", \"Data Type\": \"VARCHAR\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"claim_description\", \"Data Type\": \"TEXT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"LOB\", \"Data Type\": \"VARCHAR\", \"Null\": \"NO\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"PolicyNumber\", \"Data Type\": \"VARCHAR\", \"Null\": \"NO\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"direct_paid_loss\", \"Data Type\": \"FLOAT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"direct_paid_LAE\", \"Data Type\": \"FLOAT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"direct_outstanding_loss\", \"Data Type\": \"FLOAT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"CAT_flag\", \"Data Type\": \"BOOLEAN\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"loss_year\", \"Data Type\": \"INTEGER\", \"Null\": \"NO\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"Age_max\", \"Data Type\": \"INTEGER\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"CoverageA_Limit\", \"Data Type\": \"FLOAT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"ConstructionYear\", \"Data Type\": \"INTEGER\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"DriverCount\", \"Data Type\": \"INTEGER\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"CreditScore\", \"Data Type\": \"INTEGER\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"bi_limit_1\", \"Data Type\": \"FLOAT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"bi_limit_2\", \"Data Type\": \"FLOAT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"one_auto_full_cov_flag\", \"Data Type\": \"BOOLEAN\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"Age_min\", \"Data Type\": \"INTEGER\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"MaritalStatus\", \"Data Type\": \"VARCHAR\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"Gender\", \"Data Type\": \"VARCHAR\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"VehicleCount\", \"Data Type\": \"INTEGER\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"AgencyProductNam\", \"Data Type\": \"VARCHAR\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"EarnedPremium\", \"Data Type\": \"FLOAT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"AnnualizedIPAmt\", \"Data Type\": \"FLOAT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"minPolicyEffectiveDt\", \"Data Type\": \"DATE\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"minPolicyInceptionDts\", \"Data Type\": \"DATE\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"maxPolicyExpirationDt\", \"Data Type\": \"DATE\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"maxPolicyCancelDt\", \"Data Type\": \"DATE\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"IncurredLossCat\", \"Data Type\": \"FLOAT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"IncurredLossNonCat\", \"Data Type\": \"FLOAT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"adjuster_notes\", \"Data Type\": \"TEXT\", \"Null\": \"YES\", \"Primary Key\": \"NO\"},\n",
    "        {\"Column Name\": \"num_adjuster_notes\", \"Data Type\": \"INTEGER\", \"Null\": \"YES\", \"Primary Key\": \"NO\"}\n",
    "    ]\n",
    "    \n",
    "    # Format schema as a string for LLM input\n",
    "    formatted_schema = \"\\n\".join(\n",
    "        f\"Column Name: {col['Column Name']}, Data Type: {col['Data Type']}, Null: {col['Null']}, Primary Key: {col['Primary Key']}\"\n",
    "        for col in schema\n",
    "    )\n",
    "    return formatted_schema\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_metadata():\n",
    "    metadata = [\n",
    "        {\"Column Name\": \"claim_no\", \"Description\": \"Unique identifier for the insurance claim.\"},\n",
    "        {\"Column Name\": \"fnol_call\", \"Description\": \"First Notice of Loss call identifier or details.\"},\n",
    "        {\"Column Name\": \"LossDate\", \"Description\": \"Date of the reported loss.\"},\n",
    "        {\"Column Name\": \"loss_cause\", \"Description\": \"Cause of the loss (e.g., fire, theft).\"},\n",
    "        {\"Column Name\": \"loss_location_zip\", \"Description\": \"ZIP code where the loss occurred.\"},\n",
    "        {\"Column Name\": \"claim_description\", \"Description\": \"Detailed description of the claim.\"},\n",
    "        {\"Column Name\": \"LOB\", \"Description\": \"Line of Business associated with the claim.\"},\n",
    "        {\"Column Name\": \"PolicyNumber\", \"Description\": \"Policy number linked to the claim.\"},\n",
    "        {\"Column Name\": \"direct_paid_loss\", \"Description\": \"Amount directly paid for the loss.\"},\n",
    "        {\"Column Name\": \"direct_paid_LAE\", \"Description\": \"Amount directly paid for Loss Adjustment Expenses.\"},\n",
    "        {\"Column Name\": \"direct_outstanding_loss\", \"Description\": \"Outstanding amount for the loss.\"},\n",
    "        {\"Column Name\": \"CAT_flag\", \"Description\": \"Indicates if the claim is related to a catastrophe event.\"},\n",
    "        {\"Column Name\": \"loss_year\", \"Description\": \"Year when the loss occurred.\"},\n",
    "        {\"Column Name\": \"Age_max\", \"Description\": \"Maximum age of the insured person(s).\"},\n",
    "        {\"Column Name\": \"CoverageA_Limit\", \"Description\": \"Limit of Coverage A for the policy.\"},\n",
    "        {\"Column Name\": \"ConstructionYear\", \"Description\": \"Year the insured property was constructed.\"},\n",
    "        {\"Column Name\": \"DriverCount\", \"Description\": \"Number of drivers covered under the policy.\"},\n",
    "        {\"Column Name\": \"CreditScore\", \"Description\": \"Credit score of the insured person or entity.\"},\n",
    "        {\"Column Name\": \"bi_limit_1\", \"Description\": \"First limit for bodily injury coverage.\"},\n",
    "        {\"Column Name\": \"bi_limit_2\", \"Description\": \"Second limit for bodily injury coverage.\"},\n",
    "        {\"Column Name\": \"one_auto_full_cov_flag\", \"Description\": \"Indicates if one auto has full coverage.\"},\n",
    "        {\"Column Name\": \"Age_min\", \"Description\": \"Minimum age of the insured person(s).\"},\n",
    "        {\"Column Name\": \"MaritalStatus\", \"Description\": \"Marital status of the insured person.\"},\n",
    "        {\"Column Name\": \"Gender\", \"Description\": \"Gender of the insured person.\"},\n",
    "        {\"Column Name\": \"VehicleCount\", \"Description\": \"Number of vehicles covered under the policy.\"},\n",
    "        {\"Column Name\": \"AgencyProductNam\", \"Description\": \"Name of the agency product linked to the policy.\"},\n",
    "        {\"Column Name\": \"EarnedPremium\", \"Description\": \"Earned premium amount for the policy.\"},\n",
    "        {\"Column Name\": \"AnnualizedIPAmt\", \"Description\": \"Annualized installment premium amount.\"},\n",
    "        {\"Column Name\": \"minPolicyEffectiveDt\", \"Description\": \"Earliest effective date of the policy.\"},\n",
    "        {\"Column Name\": \"minPolicyInceptionDts\", \"Description\": \"Earliest inception date of the policy.\"},\n",
    "        {\"Column Name\": \"maxPolicyExpirationDt\", \"Description\": \"Latest expiration date of the policy.\"},\n",
    "        {\"Column Name\": \"maxPolicyCancelDt\", \"Description\": \"Latest cancellation date of the policy.\"},\n",
    "        {\"Column Name\": \"IncurredLossCat\", \"Description\": \"Incurred loss amount for catastrophe claims.\"},\n",
    "        {\"Column Name\": \"IncurredLossNonCat\", \"Description\": \"Incurred loss amount for non-catastrophe claims.\"},\n",
    "        {\"Column Name\": \"adjuster_notes\", \"Description\": \"Notes or comments added by the claim adjuster.\"},\n",
    "        {\"Column Name\": \"num_adjuster_notes\", \"Description\": \"Number of notes made by the adjuster.\"}\n",
    "    ]\n",
    "    \n",
    "    # Format metadata as a string for LLM input\n",
    "    formatted_metadata = \"\\n\".join(\n",
    "        f\"Column Name: {col['Column Name']}, Description: {col['Description']}\" for col in metadata\n",
    "    )\n",
    "    return formatted_metadata\n",
    "\n",
    "# Example usage\n",
    "metadata_text = create_table_metadata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_schema = generate_table_schema()\n",
    "table_metadata = create_table_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationManager:\n",
    "    def __init__(self, history_limit=5):\n",
    "        \"\"\"\n",
    "        Initialize the conversation manager with a history limit.\n",
    "        \"\"\"\n",
    "        self.history = []\n",
    "        self.history_limit = history_limit\n",
    "\n",
    "    def update_conversation_history(self, question, answer):\n",
    "        \"\"\"\n",
    "        Store previous questions and answers, but limit the history size.\n",
    "        \"\"\"\n",
    "        self.history.append(f\"Question: {question} \\n Answer: {answer}\")\n",
    "        if len(self.history) > self.history_limit:\n",
    "            self.history.pop(0)  # Remove the oldest entry to keep the history within the limit\n",
    "\n",
    "    def get_conversation_context(self):\n",
    "        \"\"\"\n",
    "        Get the full conversation context as a string.\n",
    "        \"\"\"\n",
    "        return self.history\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"\n",
    "        Clear the conversation history to erase context.\n",
    "        \"\"\"\n",
    "        self.history = []\n",
    "\n",
    "    def reformulate_question(self, query_text, llm):\n",
    "        \"\"\"\n",
    "        Reformulate the follow-up question based on the conversation history.\n",
    "        \"\"\"\n",
    "               # Use the reformulation prompt to generate a standalone question\n",
    "        reformulation_prompt = \"\"\"\n",
    "        Given a chat history ( User Questions and LLM response ) and the latest user question which might reference context in the chat history, \n",
    "        formulate a standalone question which can be understood without the chat history. Do NOT answer the question, \n",
    "        just reformulate it if needed and otherwise return it as is.\n",
    "\n",
    "        Chat History:\n",
    "        {chat_history}\n",
    "\n",
    "        Latest Question:\n",
    "        {latest_question}\n",
    "        \"\"\"\n",
    "\n",
    "        # Prepare the input for the LLM model\n",
    "        formatted_prompt = reformulation_prompt.format(\n",
    "            chat_history=self.get_conversation_context(),\n",
    "            latest_question=query_text\n",
    "        )\n",
    "\n",
    "        # Get the reformulated question from LLM\n",
    "        reformulated_response = llm.invoke(input=formatted_prompt)\n",
    "        standalone_question = reformulated_response.content.strip()\n",
    "\n",
    "        return standalone_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sql_query(sql_query, faiss_store, embedding_model):\n",
    "    \"\"\"\n",
    "    Standardize loss_cause in the SQL query using the FAISS vector store.\n",
    "    \n",
    "    :param sql_query: The SQL query generated by the LLM\n",
    "    :param faiss_store: The FAISS vector store containing loss_cause embeddings\n",
    "    :param embedding_model: The embedding model to create embeddings for user input\n",
    "    :return: The updated SQL query with standardized loss_cause\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    # Check for loss_cause condition in the query\n",
    "    match = re.search(r\"loss_cause\\s*(ILIKE|LIKE|=)\\s*'([^']+)'\", sql_query, re.IGNORECASE)\n",
    "    if match:\n",
    "        # Extract the condition (LIKE, ILIKE, =) and the value to be standardized\n",
    "        condition = match.group(1).upper()\n",
    "        loss_cause_value = match.group(2)\n",
    "\n",
    "        # Query the FAISS vector store for the closest match\n",
    "        query_embedding = embedding_model.embed_query(loss_cause_value)\n",
    "        matches = faiss_store.similarity_search_by_vector(query_embedding, k=1)\n",
    "\n",
    "        if matches:\n",
    "            closest_match = matches[0].page_content  # Get the closest standardized value\n",
    "            print(f\"Standardized loss_cause: {closest_match}\")\n",
    "\n",
    "            # Handle LIKE or ILIKE conditions with wildcards\n",
    "            if \"LIKE\" in condition:\n",
    "                standardized_value = f\"%{closest_match}%\"\n",
    "            else:\n",
    "                standardized_value = closest_match\n",
    "\n",
    "            # Replace the original loss_cause value in the query\n",
    "            standardized_query = re.sub(\n",
    "                r\"loss_cause\\s*(ILIKE|LIKE|=)\\s*'([^']+)'\",\n",
    "                f\"loss_cause {condition} '{standardized_value}'\",\n",
    "                sql_query,\n",
    "                flags=re.IGNORECASE,\n",
    "            )\n",
    "            return standardized_query\n",
    "        else:\n",
    "            print(\"No close match found in FAISS for loss_cause.\")\n",
    "    else:\n",
    "        print(\"No loss_cause condition found in the query.\")\n",
    "\n",
    "    # Return the original query if no changes were made\n",
    "    return sql_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the SQL query\n",
    "def execute_sql_query_with_preprocessing(db_file, sql_query, faiss_store, embedding_model):\n",
    "    # Preprocess the SQL query for loss_cause\n",
    "    print(f\"Original SQL query: {sql_query}\")\n",
    "    standardized_sql_query = preprocess_sql_query(sql_query, faiss_store, embedding_model)\n",
    "    print(f\"standard SQL query:{standardized_sql_query}\")\n",
    "    # Connect to the database and execute the query\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(standardized_sql_query)\n",
    "        result = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        conn.close()\n",
    "        return pd.DataFrame(result, columns=columns)\n",
    "    except sqlite3.Error as e:\n",
    "        conn.close()\n",
    "        return f\"SQL error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SQL Query using AzureChatOpenAI LLM\n",
    "def generate_sql_query(llm, natural_language_query, table_metadata, table_name, schema):\n",
    "    query_prompt = f\"\"\"\n",
    "You are a SQL expert. Use the table schema and metadata provided below to generate a SQL query. The data contains information about Insurance Claims, FNOL call, Adjustor notes and other details. \n",
    "\n",
    "<table info>\n",
    "\n",
    "Table: {table_name}\n",
    "Schema:\n",
    "{schema}\n",
    "Metadata: \n",
    "{table_metadata}\n",
    "\n",
    "<table info/>\n",
    "\n",
    "<Special Instructions>\n",
    "- The SQL query must extract data semantically from text-based columns like 'adjuster_notes' , 'fnol_call'\n",
    "without relying on exact pattern matching (e.g., LIKE or CONTAINS).\n",
    "- Summarize or Explain means to read the entire Unstructured / Text Column requested\n",
    "- claim no. , Claim Number , claim # - all mean the same primary key column\n",
    "\n",
    "<Special Instructions/>\n",
    "\n",
    "Convert the following natural language query into a SQL query:\n",
    "\n",
    "{natural_language_query}\n",
    "\n",
    "Only return the SQL query, no additional text.\n",
    "\"\"\"\n",
    "    response = llm.invoke(query_prompt)\n",
    "    return response.content\n",
    "\n",
    "# Execute the SQL query\n",
    "def execute_sql_query(db_file, sql_query):\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(sql_query)\n",
    "        result = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        conn.close()\n",
    "        return pd.DataFrame(result, columns=columns)\n",
    "    except sqlite3.Error as e:\n",
    "        conn.close()\n",
    "        return f\"SQL error: {e}\"\n",
    "    \n",
    "# Generate Natural Language Response using LLM\n",
    "def generate_response(llm, dataframe, standalone_question, chat_history):\n",
    "    \"\"\"\n",
    "    Generate a concise natural language response based on the standalone question,\n",
    "    the SQL query result, and the chat history. Incorporate special instructions for uniform interpretation of key terms.\n",
    "    \"\"\"\n",
    "    special_instructions = \"\"\"\n",
    "Interpret the following terms consistently:\n",
    "- \"Summarize,\" \"Describe,\" and \"Explain\" all mean \"Provide a detailed breakdown with comprehensive coverage of the topic.\"\n",
    "- Focus on clarity, detail, and coherence in the response.\n",
    "- Avoid generic phrases or filler text (e.g., \"Based on the information provided\").\n",
    "- Do not assume missing or unrelated information unless explicitly stated in the data.\n",
    "\"\"\"\n",
    "    \n",
    "    if isinstance(dataframe, str) and \"SQL error\" in dataframe:\n",
    "    # Handle SQL syntax errors\n",
    "        error_prompt = f\"\"\"\n",
    "    The following request could not be processed due to a technical error in generating or executing the SQL query.\n",
    "    Explain this to the user in simple terms without using technical jargon like 'SQL error' or 'query execution.'\n",
    "    Focus on a helpful and user-friendly response.\n",
    "\n",
    "    User Request: {standalone_question}\n",
    "\n",
    "    Chat History:\n",
    "    {chat_history}\n",
    "\n",
    "    Error Details:\n",
    "    {dataframe}\n",
    "    \"\"\"\n",
    "        response = llm.invoke(error_prompt)\n",
    "        return response.content.strip()\n",
    "\n",
    "    elif dataframe.empty:   \n",
    "    # Handle empty results\n",
    "        no_data_prompt = f\"\"\"\n",
    "    The following request was made, but the system could not find any relevant information. \n",
    "    Provide a concise and direct response to the user, following these special instructions:\n",
    "\n",
    "    {special_instructions}\n",
    "\n",
    "    User Request: {standalone_question}\n",
    "\n",
    "    Chat History:\n",
    "    {chat_history}\n",
    "    \"\"\"\n",
    "        response = llm.invoke(no_data_prompt)\n",
    "        return response.content.strip()\n",
    "\n",
    "    else:\n",
    "        # Convert the DataFrame to a comma-separated format including column names\n",
    "        result_text = \", \".join(dataframe.columns) + \"\\n\"  # Add column names\n",
    "        result_text += \"\\n\".join(dataframe.astype(str).apply(lambda row: \", \".join(row), axis=1).tolist())\n",
    "\n",
    "        # Use the LLM to generate a response based on the query result and chat history\n",
    "        response_prompt = f\"\"\"\n",
    "Provide a response based on the retrieved information. Follow these special instructions:\n",
    "\n",
    "{special_instructions}\n",
    "\n",
    "User Request: {standalone_question}\n",
    "\n",
    "Information Retrieved:\n",
    "{result_text}\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\"\"\"\n",
    "        response = llm.invoke(response_prompt)\n",
    "        return response.content.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ConversationManager with a history limit of 5\n",
    "conv_manager = ConversationManager(history_limit=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone Question: What are the top 10 claim numbers with loss causes related to animals?\n",
      "SELECT TOP 10 claim_no \n",
      "FROM claims \n",
      "WHERE loss_cause LIKE '%animal%'\n",
      "Original SQL query: SELECT TOP 10 claim_no \n",
      "FROM claims \n",
      "WHERE loss_cause LIKE '%animal%'\n",
      "Standardized loss_cause: ANIMAL COLLISION\n",
      "standard SQL query:SELECT TOP 10 claim_no \n",
      "FROM claims \n",
      "WHERE loss_cause LIKE '%ANIMAL COLLISION%'\n",
      "We're sorry, but we're having trouble processing your request right now. Our system is having difficulty generating the information you asked for. We apologize for the inconvenience and are working to fix the issue as soon as possible. Please try again later.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate SQL Query\n",
    "user_question = \"Show me top 10 claim numbers where the loss cause like animal\"\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "print(f\"Standalone Question: {standalone_question}\")\n",
    "sql_query = generate_sql_query(llm, standalone_question, table_metadata, table_name, table_schema)\n",
    "print(sql_query)\n",
    "# Step 2: Execute SQL Query with Preprocessing\n",
    "query_result = execute_sql_query_with_preprocessing(db_file, sql_query, faiss_store, embedding_model)\n",
    "\n",
    "# Step 3: Generate Response\n",
    "response = generate_response(llm, query_result, standalone_question, conv_manager.get_conversation_context())\n",
    "print(response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT claim_no \\nFROM claims \\nWHERE loss_cause LIKE '%glass break%' \\nORDER BY claim_no \\nLIMIT 10;\""
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glass break%\n",
      "Glass breakage\n",
      "Standardized loss_cause: Glass breakage\n"
     ]
    }
   ],
   "source": [
    "if \"loss_cause\" in sql_query.lower():\n",
    "        # Extract the loss_cause value from the WHERE clause\n",
    "        import re\n",
    "        match = re.search(r\"loss_cause\\s*(ILIKE|LIKE|=)\\s*'%([^']+)%?'\", sql_query, re.IGNORECASE)\n",
    "        if match:\n",
    "            loss_cause_value = match.group(2)\n",
    "            print(loss_cause_value)\n",
    "            # Search FAISS for the closest match\n",
    "            query_embedding = embedding_model.embed_query(loss_cause_value)\n",
    "            matches = faiss_store.similarity_search_by_vector(query_embedding, k=1)\n",
    "\n",
    "            if matches:\n",
    "                closest_match = matches[0].page_content\n",
    "                print(closest_match)\n",
    "                # Replace the original value with the standardized value\n",
    "                sql_query = sql_query.replace(f\"'{loss_cause_value}'\", f\"'{closest_match}'\")\n",
    "                print(f\"Standardized loss_cause: {closest_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ConversationManager with a history limit of 5\n",
    "conv_manager = ConversationManager(history_limit=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone Question: What are the detailed steps involved in summarizing the FNOL call for Claim number CH0000002?\n",
      "Generated SQL Query: SELECT fnol_call, adjuster_notes \n",
      "FROM claims \n",
      "WHERE claim_no = 'CH0000002'\n",
      "Original SQL query: SELECT fnol_call, adjuster_notes \n",
      "FROM claims \n",
      "WHERE claim_no = 'CH0000002'\n",
      "standard SQL query:SELECT fnol_call, adjuster_notes \n",
      "FROM claims \n",
      "WHERE claim_no = 'CH0000002'\n",
      "To summarize the FNOL call for Claim number CH0000002, the customer, Sarah Johnson, reported a property loss at her home in Springfield, Illinois on June 5th, 2021, due to a large tree falling onto her house during a storm. The damage caused by the fallen tree was extensive and required immediate attention, including the removal of the tree, which cost around $1,000. However, the situation has been resolved satisfactorily, and the insurance covered most of the damage to the roof and siding. The customer expressed gratitude that no one was hurt during the incident. The insurance agent apologized for any inconvenience and assured the customer that they take these types of claims seriously and are always happy to help their customers.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"Summarize the FNOL call for Claim number CH0000002 in detail\"\n",
    "\n",
    "# Reformulate the question (if needed)\n",
    "\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "print(f\"Standalone Question: {standalone_question}\")\n",
    "\n",
    "sql_query = generate_sql_query(llm, table_metadata, standalone_question, table_name, table_schema)\n",
    "print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "# Step 4: Execute the SQL query\n",
    "query_result = execute_sql_query_with_preprocessing(db_file, sql_query, faiss_store, embedding_model)\n",
    "response = generate_response(llm, query_result, standalone_question, conv_manager.get_conversation_context())\n",
    "print(response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question: What are the detailed steps involved in summarizing the FNOL call for Claim number CH0000002? \\n Answer: The policy number associated with claim number CH0000028 is H00000459.']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_manager.get_conversation_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone Question: What are the steps to summarize the Adjustor notes for claim number CH0000002?\n",
      "Generated SQL Query: SELECT adjuster_notes \n",
      "FROM claims \n",
      "WHERE claim_no = 'CH0000002'\n",
      "To summarize the Adjustor notes for claim number CH0000002, we need to provide a detailed breakdown of the incident and its aftermath. On June 5th, 2021, the customer reported a property loss at their home in Springfield, Illinois, due to a large tree falling onto their house during a storm. The damage caused by the fallen tree was extensive and required immediate attention. However, the situation has been resolved satisfactorily according to the customer. The tree removal process cost the customer around $1,000, and the damage to the roof and siding was also significant, but most of it was covered by insurance. The customer expressed gratitude that no one was hurt during the incident. Additionally, a short form bill for tree removal was paid for $1,000.00.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"Summarize the Adjustor notes for claim number CH0000002\"\n",
    "# Reformulate the question (if needed)\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "\n",
    "print(f\"Standalone Question: {standalone_question}\")\n",
    "\n",
    "sql_query = generate_sql_query(llm, table_metadata, standalone_question, table_name, table_schema)\n",
    "print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "# Step 4: Execute the SQL query\n",
    "query_result = execute_sql_query_with_preprocessing(db_file, sql_query, faiss_store, embedding_model)\n",
    "response = generate_response(llm, query_result, standalone_question, conv_manager.get_conversation_context())\n",
    "print(response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone Question: What is the policy number associated with claim number CH0000028?\n",
      "Generated SQL Query: SELECT PolicyNumber \n",
      "FROM claims \n",
      "WHERE claim_no = 'CH0000028'\n",
      "LLM Response:\n",
      "The policy number associated with claim number CH0000028 is H00000459.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"What is the policy Number of claim number: CH0000028?\"\n",
    "\n",
    "# Reformulate the question (if needed)\n",
    "\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "print(f\"Standalone Question: {standalone_question}\")\n",
    "\n",
    "sql_query = generate_sql_query(llm, table_metadata, standalone_question, table_name, table_schema)\n",
    "print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "# Step 4: Execute the SQL query\n",
    "query_result = execute_sql_query(db_file, sql_query)\n",
    "if isinstance(query_result, str):  # Error occurred\n",
    "        print(query_result)\n",
    "else:\n",
    "        # Step 5: Generate natural language response\n",
    "        query_response = generate_response(llm, query_result,standalone_question, conv_manager.get_conversation_context())\n",
    "         # Print the response line by line\n",
    "        print(\"LLM Response:\")\n",
    "        for line in query_response.splitlines():\n",
    "                print(line)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_manager.clear_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone Question: What are the top 10 Claims numbers for cases with a Loss cause of Glass breakage?\n",
      "Standardized loss_cause: Glass breakage\n",
      "Here are the top 10 Claims numbers for cases with a Loss cause of Glass breakage:\n",
      "- CA0000007\n",
      "- CA0000009\n",
      "- CA0000010\n",
      "- CA0000011\n",
      "- CA0000012\n",
      "- CA0000013\n",
      "- CA0000018\n",
      "- CA0000020\n",
      "- CA0000033\n",
      "- CA0000035\n",
      "\n",
      "These are the specific claim numbers associated with glass breakage losses, ranked in order from highest to lowest.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"Give me the top 10 Claims numbers for cases with Loss cause like Glass breakage\"\n",
    "\n",
    "# Reformulate the question (if needed)\n",
    "\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "print(f\"Standalone Question: {standalone_question}\")\n",
    "sql_query = generate_sql_query(llm, standalone_question, table_metadata, table_name, table_schema)\n",
    "\n",
    "# Step 2: Execute SQL Query with Preprocessing\n",
    "query_result = execute_sql_query_with_preprocessing(db_file, sql_query, faiss_store, embedding_model)\n",
    "\n",
    "# Step 3: Generate Response\n",
    "response = generate_response(llm, query_result, standalone_question, conv_manager.get_conversation_context())\n",
    "print(response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT Clinical_Notes FROM nurse_notes WHERE Nurse_name LIKE \"%Olivia%\"\n",
      "Query Result:\n",
      "                                      Clinical_Notes\n",
      "0  Nurse_Note: Primary CNA was undressing residen...\n",
      "1  Nurse_Note: Safely You called to apprise that ...\n",
      "2  Nurse_Note: During care resident's aide observ...\n",
      "Nurse Olivia's clinical notes contain three entries. The first entry describes an incident where the primary CNA was undressing a resident in bed and accidentally caused a skin tear on the left lower leg. The second entry reports an incident where the Elder was looking for her watch and moving around the room, but did not fall. The third entry notes that a resident had open skin on their right lower extremity due to dry skin and discoloration.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"Summarize all of her Clinical Notes\"\n",
    "# Reformulate the question (if needed)\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "\n",
    "sql_query = generate_sql_query(llm, table_metadata, standalone_question, table_name, table_schema)\n",
    "print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "# Step 4: Execute the SQL query\n",
    "query_result = execute_sql_query(db_file, sql_query)\n",
    "if isinstance(query_result, str):  # Error occurred\n",
    "        print(query_result)\n",
    "else:\n",
    "        print(\"Query Result:\")\n",
    "        print(query_result)\n",
    "\n",
    "        # Step 5: Generate natural language response\n",
    "        query_response = generate_response(llm, query_result,standalone_question, conv_manager.get_conversation_context())\n",
    "        print(query_response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT Clinical_Notes FROM nurse_notes WHERE Nurse_name LIKE \"%Olivia%\" AND Clinical_Notes LIKE \"%injuries%\"\n",
      "Query Result:\n",
      "Empty DataFrame\n",
      "Columns: [Clinical_Notes]\n",
      "Index: []\n",
      "Yes, Nurse Olivia's clinical notes mention three injuries. The first injury was a skin tear on the left lower leg caused by the primary CNA while undressing a resident in bed. The second injury was a resident moving towards the floor while looking for her watch, but not falling. The third injury was open skin on the right lower extremity with surrounding skin discoloration and dry skin, and the resident was unable to explain how she got the injury due to cognitive deficit.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"Were there any injuries in any of her notes\"\n",
    "# Reformulate the question (if needed)\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "\n",
    "sql_query = generate_sql_query(llm, table_metadata, standalone_question, table_name, table_schema)\n",
    "print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "# Step 4: Execute the SQL query\n",
    "query_result = execute_sql_query(db_file, sql_query)\n",
    "if isinstance(query_result, str):  # Error occurred\n",
    "        print(query_result)\n",
    "else:\n",
    "        print(\"Query Result:\")\n",
    "        print(query_result)\n",
    "\n",
    "        # Step 5: Generate natural language response\n",
    "        query_response = generate_response(llm, query_result,standalone_question, conv_manager.get_conversation_context())\n",
    "        print(query_response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_manager.clear_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT Clinical_Notes FROM nurse_notes WHERE First_Name = 'Robert' AND Last_Name = 'Nash'\n",
      "Query Result:\n",
      "                                      Clinical_Notes\n",
      "0  Nurse_Note: Nurse responded to a call light in...\n",
      "Based on the information retrieved, it appears that Robert Nash fell while sitting on the floor next to his bed. He was found by a nurse who responded to his call light. He was last seen sitting in his recliner chair about an hour before the fall and denied being in pain. His vital signs were normal, and he did not appear to have any injuries. His wife was informed, and their son was called about the fall. Dr. Kobylarz was also made aware of the situation.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"Summarize Notes for Robert Nash, only Clinical\"\n",
    "# Reformulate the question (if needed)\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "\n",
    "sql_query = generate_sql_query(llm, table_metadata, standalone_question, table_name, table_schema)\n",
    "print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "# Step 4: Execute the SQL query\n",
    "query_result = execute_sql_query(db_file, sql_query)\n",
    "if isinstance(query_result, str):  # Error occurred\n",
    "        print(query_result)\n",
    "else:\n",
    "        print(\"Query Result:\")\n",
    "        print(query_result)\n",
    "\n",
    "        # Step 5: Generate natural language response\n",
    "        query_response = generate_response(llm, query_result,standalone_question, conv_manager.get_conversation_context())\n",
    "        print(query_response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_manager.clear_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT Clinical_Notes, Non_clinical_notes \n",
      "FROM nurse_notes \n",
      "WHERE Clinical_Notes LIKE \"%skin tear%\" OR Non_clinical_notes LIKE \"%skin tear%\"\n",
      "Query Result:\n",
      "                                      Clinical_Notes  \\\n",
      "0  Nurse_Note: Primary CNA was undressing residen...   \n",
      "1  Nurse_Note: 5:50pm I was in room 35 assisting ...   \n",
      "\n",
      "                                  Non_clinical_notes  \n",
      "0  Nurse_Note: At 11:00 am on 09/20/2023 nurse wa...  \n",
      "1  Nurse_Note: At 5:30 pm on 02/05/2024 nurse was...  \n",
      "Based on the notes retrieved, there were three instances of observed skin tears. The first one happened when the primary CNA was undressing Resident in bed and accidentally caused a skin tear on the left lower leg front area. The second one was observed on the left lateral aspect of Resident's knee and left lateral elbow after Resident fell and was transferred to RWJUH. The third one was not specified where it occurred.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"Summarize Notes where skin tear was observed\"\n",
    "# Reformulate the question (if needed)\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "\n",
    "sql_query = generate_sql_query(llm, table_metadata, standalone_question, table_name, table_schema)\n",
    "print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "# Step 4: Execute the SQL query\n",
    "query_result = execute_sql_query(db_file, sql_query)\n",
    "if isinstance(query_result, str):  # Error occurred\n",
    "        print(query_result)\n",
    "else:\n",
    "        print(\"Query Result:\")\n",
    "        print(query_result)\n",
    "\n",
    "        # Step 5: Generate natural language response\n",
    "        query_response = generate_response(llm, query_result,standalone_question, conv_manager.get_conversation_context())\n",
    "        print(query_response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT First_Name, Last_Name, Clinical_Notes \n",
      "FROM nurse_notes \n",
      "WHERE Clinical_Notes LIKE \"%skin tear%\"\n",
      "Query Result:\n",
      "  First_Name Last_Name                                     Clinical_Notes\n",
      "0      James    Miller  Nurse_Note: Primary CNA was undressing residen...\n",
      "1     Olivia  Martinez  Nurse_Note: 5:50pm I was in room 35 assisting ...\n",
      "Based on the information retrieved, James Miller experienced a skin tear on his left lower leg front area while being undressed by a CNA. Olivia Martinez experienced skin tears on her left lateral aspect of her knee and left lateral elbow after falling next to the nursing station.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"what were the names of the residents with skin tear\"\n",
    "# Reformulate the question (if needed)\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "\n",
    "sql_query = generate_sql_query(llm, table_metadata, standalone_question, table_name, table_schema)\n",
    "print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "# Step 4: Execute the SQL query\n",
    "query_result = execute_sql_query(db_file, sql_query)\n",
    "if isinstance(query_result, str):  # Error occurred\n",
    "        print(query_result)\n",
    "else:\n",
    "        print(\"Query Result:\")\n",
    "        print(query_result)\n",
    "\n",
    "        # Step 5: Generate natural language response\n",
    "        query_response = generate_response(llm, query_result,standalone_question, conv_manager.get_conversation_context())\n",
    "        print(query_response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_manager.clear_history()\n",
    "conv_manager.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT First_Name, Last_Name, Clinical_Notes \n",
      "FROM nurse_notes \n",
      "WHERE Clinical_Notes LIKE '%fall%'\n",
      "Query Result:\n",
      "  First_Name Last_Name                                     Clinical_Notes\n",
      "0      James    Miller  Nurse_Note: Approximately 7:30 pm Nurse respon...\n",
      "1    Michael   Johnson  Nurse_Note: Safely You called to apprise that ...\n",
      "2    Jessica     Brown  Nurse_Note: It was reported to me by the Nurse...\n",
      "3     Robert      Nash  Nurse_Note: Nurse responded to a call light in...\n",
      "Yes, I can provide you with a summary of falls that have occurred and the names of the residents involved. James Miller fell and was assisted to transfer via mechanical lift. Michael Johnson did not fall but was observed visually and tactilely scanning the area for her \"watch.\" Jessica Brown fell while reaching for items in the cabinet and was assisted to a wheelchair by two staff for safety. Robert Nash fell and was assisted into bed at his request.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"Summarize any fall incidents, Name the residents as well\"\n",
    "# Reformulate the question (if needed)\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "\n",
    "sql_query = generate_sql_query(llm, table_metadata, standalone_question, table_name, table_schema)\n",
    "print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "# Step 4: Execute the SQL query\n",
    "query_result = execute_sql_query(db_file, sql_query)\n",
    "if isinstance(query_result, str):  # Error occurred\n",
    "        print(query_result)\n",
    "else:\n",
    "        print(\"Query Result:\")\n",
    "        print(query_result)\n",
    "\n",
    "        # Step 5: Generate natural language response\n",
    "        query_response = generate_response(llm, query_result,standalone_question, conv_manager.get_conversation_context())\n",
    "        print(query_response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_manager.clear_history()\n",
    "conv_manager.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT Non_clinical_notes FROM nurse_notes WHERE First_Name = 'Robert' AND Last_Name = 'Nash'\n",
      "Query Result:\n",
      "                                  Non_clinical_notes\n",
      "0  Nurse_Note: At 3:00 pm on 12/15/2023 nurse was...\n",
      "Based on the information retrieved, it looks like there is a non-clinical note for Resident Robert Nash that needs to be summarized. The note is from a nurse who was in the recreation room on December 15th, 2023. The note mentions that an elder in Room #11A reported a lack of activities and was found sitting alone, expressing boredom and a desire for more engaging activities. The nurse discussed this with the elder and the activities coordinator was notified to include the elder's preferences in planning. The elder was invited to participate in an upcoming activity and seemed appreciative.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"Summarize non clinical notes for Resident Robert Nash\"\n",
    "# Reformulate the question (if needed)\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "\n",
    "sql_query = generate_sql_query(llm, table_metadata, standalone_question, table_name, table_schema)\n",
    "print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "# Step 4: Execute the SQL query\n",
    "query_result = execute_sql_query(db_file, sql_query)\n",
    "if isinstance(query_result, str):  # Error occurred\n",
    "        print(query_result)\n",
    "else:\n",
    "        print(\"Query Result:\")\n",
    "        print(query_result)\n",
    "\n",
    "        # Step 5: Generate natural language response\n",
    "        query_response = generate_response(llm, query_result,standalone_question, conv_manager.get_conversation_context())\n",
    "        print(query_response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT Clinical_Notes FROM nurse_notes WHERE Gender = 'Female'\n",
      "Query Result:\n",
      "                                      Clinical_Notes\n",
      "0  Nurse_Note: At 3:10 am on 07/17/2021 writer wa...\n",
      "1  Nurse_Note: Resident's pendant went off at 5:2...\n",
      "2  Nurse_Note: It was reported to me by the Nurse...\n",
      "3  Nurse_Note: 5:50pm I was in room 35 assisting ...\n",
      "4  Nurse_Note: Resident's pendant went off at 5:2...\n",
      "The clinical notes provide information about incidents that occurred with female residents. For example, one resident fell out of bed and was found sitting on the floor, another resident fell while reaching for items in a cabinet, and another resident had loose bowel movements. The notes describe the actions taken by the nursing staff, such as assessing the residents for injuries, providing assistance, and contacting physicians or family members. The notes also include vital signs and any medication administered.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get user query and convert it\n",
    "user_question = \"explain clinical notes for each female in the data\"\n",
    "# Reformulate the question (if needed)\n",
    "standalone_question = conv_manager.reformulate_question(user_question, llm)\n",
    "\n",
    "sql_query = generate_sql_query(llm, table_metadata, standalone_question, table_name, table_schema)\n",
    "print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "# Step 4: Execute the SQL query\n",
    "query_result = execute_sql_query(db_file, sql_query)\n",
    "if isinstance(query_result, str):  # Error occurred\n",
    "        print(query_result)\n",
    "else:\n",
    "        print(\"Query Result:\")\n",
    "        print(query_result)\n",
    "\n",
    "        # Step 5: Generate natural language response\n",
    "        query_response = generate_response(llm, query_result,standalone_question, conv_manager.get_conversation_context())\n",
    "        print(query_response)\n",
    "conv_manager.update_conversation_history(standalone_question, query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
