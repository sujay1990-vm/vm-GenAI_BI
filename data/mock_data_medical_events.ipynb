{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version\n",
      "---------------------------------------- -------------------\n",
      "absl-py                                  1.0.0\n",
      "aiohttp                                  3.9.5\n",
      "aiosignal                                1.3.1\n",
      "altair                                   5.3.0\n",
      "annotated-types                          0.6.0\n",
      "anyio                                    3.5.0\n",
      "argon2-cffi                              21.3.0\n",
      "argon2-cffi-bindings                     21.2.0\n",
      "asgiref                                  3.8.1\n",
      "asttokens                                2.0.5\n",
      "astunparse                               1.6.3\n",
      "async-timeout                            4.0.3\n",
      "asyncio                                  3.4.3\n",
      "attrs                                    21.4.0\n",
      "Babel                                    2.9.1\n",
      "backcall                                 0.2.0\n",
      "backoff                                  2.2.1\n",
      "bcrypt                                   4.1.3\n",
      "beautifulsoup4                           4.12.3\n",
      "black                                    21.12b0\n",
      "bleach                                   4.1.0\n",
      "blinker                                  1.7.0\n",
      "blis                                     1.0.1\n",
      "boto3                                    1.34.112\n",
      "botocore                                 1.34.112\n",
      "bs4                                      0.0.2\n",
      "build                                    1.2.1\n",
      "cachetools                               5.0.0\n",
      "catalogue                                2.0.10\n",
      "certifi                                  2024.2.2\n",
      "cffi                                     1.15.0\n",
      "chardet                                  5.2.0\n",
      "charset-normalizer                       3.3.2\n",
      "chroma-hnswlib                           0.7.3\n",
      "chromadb                                 0.5.0\n",
      "click                                    8.1.7\n",
      "cloudpathlib                             0.20.0\n",
      "cloudpickle                              2.0.0\n",
      "cohere                                   5.5.3\n",
      "colorama                                 0.4.6\n",
      "coloredlogs                              15.0.1\n",
      "comm                                     0.2.2\n",
      "comtypes                                 1.4.5\n",
      "confection                               0.1.5\n",
      "contourpy                                1.3.0\n",
      "cryptography                             43.0.1\n",
      "cycler                                   0.11.0\n",
      "cymem                                    2.0.10\n",
      "dataclasses-json                         0.6.4\n",
      "datasets                                 2.19.1\n",
      "debugpy                                  1.5.1\n",
      "decorator                                5.1.1\n",
      "deepdiff                                 7.0.1\n",
      "defusedxml                               0.7.1\n",
      "Deprecated                               1.2.14\n",
      "dill                                     0.3.8\n",
      "dirtyjson                                1.0.8\n",
      "diskcache                                5.6.3\n",
      "distro                                   1.9.0\n",
      "Django                                   5.0.6\n",
      "dnspython                                2.6.1\n",
      "docopt                                   0.6.2\n",
      "email_validator                          2.1.1\n",
      "emoji                                    2.11.1\n",
      "entrypoints                              0.3\n",
      "et-xmlfile                               1.1.0\n",
      "executing                                0.8.2\n",
      "faiss-cpu                                1.8.0\n",
      "Faker                                    33.1.0\n",
      "fastapi                                  0.111.0\n",
      "fastapi-cli                              0.0.3\n",
      "fastavro                                 1.9.4\n",
      "fastcore                                 1.7.11\n",
      "fastjsonschema                           2.20.0\n",
      "filelock                                 3.14.0\n",
      "filetype                                 1.2.0\n",
      "flatbuffers                              2.0\n",
      "fonttools                                4.28.5\n",
      "frozenlist                               1.4.1\n",
      "fsspec                                   2024.3.1\n",
      "gast                                     0.5.3\n",
      "gender-guesser                           0.4.0\n",
      "geopandas                                1.0.1\n",
      "gitdb                                    4.0.11\n",
      "GitPython                                3.1.43\n",
      "gmft                                     0.3.1\n",
      "google-auth                              2.6.0\n",
      "google-auth-oauthlib                     0.4.6\n",
      "google-pasta                             0.2.0\n",
      "googleapis-common-protos                 1.63.0\n",
      "greenlet                                 3.0.3\n",
      "grpcio                                   1.63.0\n",
      "gTTS                                     2.5.1\n",
      "gym                                      0.23.0\n",
      "gym-notices                              0.0.6\n",
      "h11                                      0.14.0\n",
      "h5py                                     3.6.0\n",
      "httpcore                                 1.0.5\n",
      "httptools                                0.6.1\n",
      "httpx                                    0.27.0\n",
      "httpx-sse                                0.4.0\n",
      "huggingface-hub                          0.23.0\n",
      "humanfriendly                            10.0\n",
      "idna                                     3.7\n",
      "imbalanced-learn                         0.9.0\n",
      "importlib-metadata                       7.0.0\n",
      "importlib_resources                      6.4.0\n",
      "intel-openmp                             2021.4.0\n",
      "ipykernel                                6.7.0\n",
      "ipython                                  8.12.3\n",
      "ipython-genutils                         0.2.0\n",
      "ipywidgets                               8.1.3\n",
      "jedi                                     0.18.1\n",
      "Jinja2                                   3.0.3\n",
      "jiter                                    0.6.0\n",
      "jmespath                                 1.0.1\n",
      "joblib                                   1.4.2\n",
      "json5                                    0.9.6\n",
      "jsonpatch                                1.33\n",
      "jsonpath-python                          1.0.6\n",
      "jsonpointer                              2.4\n",
      "jsonschema                               4.4.0\n",
      "jupyter-client                           7.1.1\n",
      "jupyter_core                             5.7.2\n",
      "jupyter-server                           1.13.3\n",
      "jupyterlab                               3.2.8\n",
      "jupyterlab-pygments                      0.1.2\n",
      "jupyterlab-server                        2.10.3\n",
      "jupyterlab_widgets                       3.0.11\n",
      "kagglehub                                0.3.3\n",
      "kaleido                                  0.2.1\n",
      "keras                                    2.8.0\n",
      "Keras-Preprocessing                      1.1.2\n",
      "keyboard                                 0.13.5\n",
      "kiwisolver                               1.3.2\n",
      "kubernetes                               29.0.0\n",
      "langchain                                0.3.14\n",
      "langchain-chroma                         0.1.4\n",
      "langchain-community                      0.3.14\n",
      "langchain-core                           0.3.29\n",
      "langchain-experimental                   0.3.4\n",
      "langchain-openai                         0.2.14\n",
      "langchain-text-splitters                 0.3.4\n",
      "langchainhub                             0.1.20\n",
      "langcodes                                3.5.0\n",
      "langdetect                               1.0.9\n",
      "langgraph                                0.2.60\n",
      "langgraph-checkpoint                     2.0.9\n",
      "langgraph-sdk                            0.1.48\n",
      "langsmith                                0.1.147\n",
      "language_data                            1.3.0\n",
      "libclang                                 13.0.0\n",
      "libsvm                                   3.23.0.4\n",
      "lida                                     0.0.14\n",
      "llama-cloud                              0.1.2\n",
      "llama-index                              0.10.19\n",
      "llama-index-agent-openai                 0.1.7\n",
      "llama-index-cli                          0.1.13\n",
      "llama-index-core                         0.10.19\n",
      "llama-index-embeddings-openai            0.1.11\n",
      "llama-index-indices-managed-llama-cloud  0.1.6\n",
      "llama-index-legacy                       0.9.48.post3\n",
      "llama-index-llms-openai                  0.1.11\n",
      "llama-index-multi-modal-llms-openai      0.1.9\n",
      "llama-index-program-openai               0.1.6\n",
      "llama-index-question-gen-openai          0.1.3\n",
      "llama-index-readers-file                 0.1.22\n",
      "llama-index-readers-llama-parse          0.1.6\n",
      "llama-parse                              0.4.9\n",
      "llamaindex-py-client                     0.1.19\n",
      "llmx                                     0.0.21a0\n",
      "lxml                                     5.2.1\n",
      "marisa-trie                              1.2.1\n",
      "Markdown                                 3.3.6\n",
      "markdown-it-py                           3.0.0\n",
      "MarkupSafe                               2.0.1\n",
      "marshmallow                              3.21.1\n",
      "matplotlib                               3.9.2\n",
      "matplotlib-inline                        0.1.3\n",
      "matplotlib-venn                          1.1.1\n",
      "mdurl                                    0.1.2\n",
      "mistune                                  3.0.2\n",
      "mizani                                   0.13.0\n",
      "mkl                                      2021.4.0\n",
      "mlxtend                                  0.23.4\n",
      "mmh3                                     4.1.0\n",
      "monotonic                                1.6\n",
      "mpmath                                   1.3.0\n",
      "msgpack                                  1.1.0\n",
      "multidict                                6.0.5\n",
      "multiprocess                             0.70.16\n",
      "murmurhash                               1.0.11\n",
      "mypy-extensions                          1.0.0\n",
      "nbclassic                                0.3.5\n",
      "nbclient                                 0.5.10\n",
      "nbconvert                                7.16.4\n",
      "nbformat                                 5.10.4\n",
      "neo4j                                    5.27.0\n",
      "neo4j-graphrag                           1.2.1\n",
      "nest-asyncio                             1.6.0\n",
      "networkx                                 3.3\n",
      "nltk                                     3.9.1\n",
      "notebook                                 6.4.7\n",
      "numexpr                                  2.10.0\n",
      "numpy                                    1.26.4\n",
      "oauthlib                                 3.2.2\n",
      "olefile                                  0.47\n",
      "onnxruntime                              1.17.3\n",
      "openai                                   1.59.4\n",
      "opencv-python                            4.10.0.84\n",
      "openpyxl                                 3.1.0\n",
      "opentelemetry-api                        1.24.0\n",
      "opentelemetry-exporter-otlp-proto-common 1.24.0\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.24.0\n",
      "opentelemetry-instrumentation            0.45b0\n",
      "opentelemetry-instrumentation-asgi       0.45b0\n",
      "opentelemetry-instrumentation-fastapi    0.45b0\n",
      "opentelemetry-proto                      1.24.0\n",
      "opentelemetry-sdk                        1.24.0\n",
      "opentelemetry-semantic-conventions       0.45b0\n",
      "opentelemetry-util-http                  0.45b0\n",
      "opt-einsum                               3.3.0\n",
      "ordered-set                              4.1.0\n",
      "orjson                                   3.10.1\n",
      "overrides                                7.7.0\n",
      "packaging                                23.2\n",
      "pandas                                   2.2.3\n",
      "pandocfilters                            1.5.0\n",
      "parso                                    0.8.3\n",
      "pathspec                                 0.9.0\n",
      "patsy                                    0.5.6\n",
      "pdf2image                                1.17.0\n",
      "pickleshare                              0.7.5\n",
      "pillow                                   10.4.0\n",
      "pip                                      25.0.1\n",
      "pipreqs                                  0.5.0\n",
      "platformdirs                             4.3.6\n",
      "playsound                                1.3.0\n",
      "plotly                                   5.19.0\n",
      "plotnine                                 0.14.1\n",
      "posthog                                  3.5.0\n",
      "preshed                                  3.0.9\n",
      "prometheus-client                        0.12.0\n",
      "prompt_toolkit                           3.0.48\n",
      "protobuf                                 3.20.0\n",
      "psutil                                   6.0.0\n",
      "pure-eval                                0.2.1\n",
      "pyarrow                                  16.0.0\n",
      "pyarrow-hotfix                           0.6\n",
      "pyasn1                                   0.4.8\n",
      "pyasn1-modules                           0.2.8\n",
      "PyAudio                                  0.2.14\n",
      "pyclipper                                1.3.0.post5\n",
      "pycparser                                2.21\n",
      "pycryptodome                             3.21.0\n",
      "pydantic                                 2.10.4\n",
      "pydantic_core                            2.27.2\n",
      "pydantic-settings                        2.7.1\n",
      "pydeck                                   0.9.0b0\n",
      "pygame                                   2.1.2\n",
      "Pygments                                 2.17.2\n",
      "PyMuPDF                                  1.24.10\n",
      "PyMuPDFb                                 1.24.10\n",
      "pyodbc                                   5.2.0\n",
      "pyogrio                                  0.10.0\n",
      "pyparsing                                3.0.6\n",
      "pypdf                                    4.3.1\n",
      "PyPDF2                                   3.0.1\n",
      "pypdfium2                                4.30.0\n",
      "PyPika                                   0.48.9\n",
      "pypiwin32                                223\n",
      "pyproj                                   3.7.0\n",
      "pyproject_hooks                          1.1.0\n",
      "pyreadline3                              3.4.1\n",
      "pyrsistent                               0.18.1\n",
      "pyspellchecker                           0.8.1\n",
      "python-dateutil                          2.8.2\n",
      "python-dotenv                            1.0.1\n",
      "python-iso639                            2024.2.7\n",
      "python-magic                             0.4.27\n",
      "python-magic-bin                         0.4.14\n",
      "python-multipart                         0.0.9\n",
      "python-oxmsg                             0.0.1\n",
      "pyttsx3                                  2.90\n",
      "pytz                                     2021.3\n",
      "pywin32                                  303\n",
      "pywinpty                                 1.1.6\n",
      "PyYAML                                   6.0.1\n",
      "pyzmq                                    22.3.0\n",
      "rank-bm25                                0.2.2\n",
      "rapidfuzz                                3.8.1\n",
      "rapidocr-onnxruntime                     1.3.24\n",
      "regex                                    2024.4.16\n",
      "requests                                 2.31.0\n",
      "requests-oauthlib                        1.3.1\n",
      "requests-toolbelt                        1.0.0\n",
      "rich                                     13.7.1\n",
      "rsa                                      4.8\n",
      "s3transfer                               0.10.1\n",
      "safetensors                              0.4.3\n",
      "scikeras                                 0.4.1\n",
      "scikit-learn                             1.6.1\n",
      "scikit-plot                              0.3.7\n",
      "scipy                                    1.14.1\n",
      "seaborn                                  0.13.0\n",
      "Send2Trash                               1.8.0\n",
      "sentence-transformers                    2.7.0\n",
      "setuptools                               58.1.0\n",
      "shapely                                  2.0.6\n",
      "shellingham                              1.5.4\n",
      "six                                      1.16.0\n",
      "smart-open                               7.0.5\n",
      "smmap                                    5.0.1\n",
      "sniffio                                  1.2.0\n",
      "soupsieve                                2.5\n",
      "spacy                                    3.8.2\n",
      "spacy-legacy                             3.0.12\n",
      "spacy-loggers                            1.0.5\n",
      "SpeechRecognition                        3.10.4\n",
      "SQLAlchemy                               2.0.29\n",
      "sqlparse                                 0.5.0\n",
      "srsly                                    2.4.8\n",
      "stack-data                               0.1.4\n",
      "starlette                                0.37.2\n",
      "statsmodels                              0.14.4\n",
      "streamlit                                1.33.0\n",
      "striprtf                                 0.0.26\n",
      "sympy                                    1.12\n",
      "tabulate                                 0.9.0\n",
      "tbb                                      2021.12.0\n",
      "tenacity                                 8.2.3\n",
      "tensorboard                              2.8.0\n",
      "tensorboard-data-server                  0.6.1\n",
      "tensorboard-plugin-wit                   1.8.1\n",
      "tensorflow                               2.8.0\n",
      "tensorflow-io-gcs-filesystem             0.24.0\n",
      "termcolor                                1.1.0\n",
      "terminado                                0.12.1\n",
      "testpath                                 0.5.0\n",
      "textblob                                 0.18.0.post0\n",
      "tf-estimator-nightly                     2.8.0.dev2021122109\n",
      "thinc                                    8.3.2\n",
      "threadpoolctl                            3.1.0\n",
      "tiktoken                                 0.7.0\n",
      "tinycss2                                 1.3.0\n",
      "tokenizers                               0.19.1\n",
      "toml                                     0.10.2\n",
      "tomli                                    1.2.3\n",
      "toolz                                    0.12.1\n",
      "torch                                    2.3.0\n",
      "tornado                                  6.1\n",
      "tqdm                                     4.66.2\n",
      "traitlets                                5.14.3\n",
      "transformers                             4.41.0\n",
      "typer                                    0.12.3\n",
      "types-requests                           2.32.0.20240523\n",
      "typing_extensions                        4.12.2\n",
      "typing-inspect                           0.9.0\n",
      "tzdata                                   2024.1\n",
      "ujson                                    5.10.0\n",
      "unstructured                             0.15.13\n",
      "unstructured-client                      0.22.0\n",
      "urllib3                                  2.2.1\n",
      "utils                                    1.0.2\n",
      "uvicorn                                  0.29.0\n",
      "wasabi                                   1.1.3\n",
      "watchdog                                 4.0.0\n",
      "watchfiles                               0.21.0\n",
      "wcwidth                                  0.2.5\n",
      "weasel                                   0.4.1\n",
      "webencodings                             0.5.1\n",
      "websocket-client                         1.2.3\n",
      "websockets                               12.0\n",
      "Werkzeug                                 2.0.2\n",
      "wheel                                    0.37.1\n",
      "widgetsnbextension                       4.0.11\n",
      "wordcloud                                1.9.3\n",
      "wrapt                                    1.13.3\n",
      "xlrd                                     2.0.1\n",
      "XlsxWriter                               3.2.0\n",
      "xxhash                                   3.4.1\n",
      "yarg                                     0.1.9\n",
      "yarl                                     1.9.4\n",
      "zipp                                     3.18.1\n"
     ]
    }
   ],
   "source": [
    "! py -m pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Dim_Resident.csv' created with 500 records.\n",
      "Data stored in SQLite database 'medical_events.db' in table 'Dim_Resident'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import sys\n",
    "\n",
    "# Initialize Faker for generating fake names.\n",
    "fake = Faker()\n",
    "\n",
    "# Helper function to generate a random timestamp between two datetime objects.\n",
    "def random_timestamp(start, end):\n",
    "    delta = end - start\n",
    "    random_seconds = random.randint(0, int(delta.total_seconds()))\n",
    "    return start + timedelta(seconds=random_seconds)\n",
    "\n",
    "# Helper function to generate a random date between two dates.\n",
    "def random_date(start, end):\n",
    "    delta = end - start\n",
    "    random_days = random.randint(0, delta.days)\n",
    "    return start + timedelta(days=random_days)\n",
    "\n",
    "# Define ingestion timestamp range (for RecordIngestedOn)\n",
    "ingest_start = datetime(2025, 1, 1)\n",
    "ingest_end = datetime(2025, 3, 31)\n",
    "\n",
    "# Define date of birth range: residents will be at least 65 in 2025 if born on or before 1960.\n",
    "dob_start = datetime(1940, 1, 1)\n",
    "dob_end = datetime(1960, 12, 31)\n",
    "\n",
    "num_residents = 500\n",
    "data = []\n",
    "\n",
    "for i in range(1, num_residents + 1):\n",
    "    resident_name = fake.name()\n",
    "    # Generate a DOB between 1900 and 1960, then format as M/D/YYYY (or MM/DD/YYYY)\n",
    "    if sys.platform.startswith(\"win\"):\n",
    "        dob_format = \"%#m/%#d/%Y\"\n",
    "    else:\n",
    "        dob_format = \"%-m/%-d/%Y\"\n",
    "\n",
    "    dob = random_date(dob_start, dob_end).strftime(dob_format)\n",
    "    # For Windows, you might use: dob = random_date(dob_start, dob_end).strftime(\"%#m/%#d/%Y\")\n",
    "    record_ingested_on = random_timestamp(ingest_start, ingest_end).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    row = {\n",
    "        \"ResidentKey\": i,\n",
    "        \"ResidentName\": resident_name,\n",
    "        \"ResidentDateOfBirth\": dob,\n",
    "        \"RecordIngestedOn\": record_ingested_on\n",
    "    }\n",
    "    data.append(row)\n",
    "\n",
    "# Create a DataFrame from the data.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "csv_filename = \"Dim_Resident.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"CSV file '{csv_filename}' created with {num_residents} records.\")\n",
    "\n",
    "# Connect to the SQLite database (medical_events.db) and store the data in the Dim_Resident table.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df.to_sql(\"Dim_Resident\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Data stored in SQLite database '{db_filename}' in table 'Dim_Resident'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Dim_Facility.csv' created with 5 records.\n",
      "Data stored in SQLite database 'medical_events.db' in table 'Dim_Facility'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# List of county names for each branch.\n",
    "counties = [\n",
    "    \"Parker at Somerset\",\n",
    "    \"Parker at River Road\",\n",
    "    \"Parker at Monroe\",\n",
    "    \"Parker at Landing Lane\",\n",
    "    \"Parker at Stonegate\"\n",
    "]\n",
    "\n",
    "# Function to generate a random timestamp between two datetime objects.\n",
    "def random_timestamp(start, end):\n",
    "    delta = end - start\n",
    "    random_seconds = random.randint(0, int(delta.total_seconds()))\n",
    "    return start + timedelta(seconds=random_seconds)\n",
    "\n",
    "# Set the date range for RecordIngestedOn.\n",
    "start_date = datetime(2025, 1, 1)\n",
    "end_date = datetime(2025, 3, 31)\n",
    "\n",
    "# Create the data for each facility using only county names.\n",
    "data = []\n",
    "for i, county in enumerate(counties, start=1):\n",
    "    facility_code = f\"{i:02d}\"  # Two-digit facility code, e.g., \"01\", \"02\", etc.\n",
    "    facility_name = f\"Reliant care at {county}\"\n",
    "    record_ingested_on = random_timestamp(start_date, end_date).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    row = {\n",
    "        \"FacilityKey\": i,\n",
    "        \"FacilityCode\": facility_code,\n",
    "        \"FacilityName\": facility_name,\n",
    "        \"RecordIngestedOn\": record_ingested_on\n",
    "    }\n",
    "    data.append(row)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "csv_filename = \"Dim_Facility.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"CSV file '{csv_filename}' created with {len(df)} records.\")\n",
    "\n",
    "# Create (or connect to) the SQLite database and store the data in the Dim_CensusFacility table.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df.to_sql(\"Dim_Facility\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Data stored in SQLite database '{db_filename}' in table 'Dim_Facility'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Dim_EHRLocation.csv' created with 5 records.\n",
      "Data stored in SQLite database 'medical_events.db' in table 'Dim_EHRLocation'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# List of county names (from the previous facility example)\n",
    "counties = [\n",
    "    \"Parker at Somerset\",\n",
    "    \"Parker at River Road\",\n",
    "    \"Parker at Monroe\",\n",
    "    \"Parker at Landing Lane\",\n",
    "    \"Parker at Stonegate\"\n",
    "]\n",
    "\n",
    "# Function to generate a random timestamp between two datetime objects.\n",
    "def random_timestamp(start, end):\n",
    "    delta = end - start\n",
    "    random_seconds = random.randint(0, int(delta.total_seconds()))\n",
    "    return start + timedelta(seconds=random_seconds)\n",
    "\n",
    "# Set the date range for RecordIngestedOn.\n",
    "start_date = datetime(2025, 1, 1)\n",
    "end_date = datetime(2025, 3, 31)\n",
    "\n",
    "# Create data for each location.\n",
    "data = []\n",
    "for i, county in enumerate(counties, start=1):\n",
    "    row = {\n",
    "        \"LocationKey\": i,\n",
    "        \"LocationId\": str(i),\n",
    "        \"LocationCode\": str(i),  # Using the row number as a string for the code.\n",
    "        \"LocationName\": county,\n",
    "        \"RecordIngestedOn\": random_timestamp(start_date, end_date).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    data.append(row)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "csv_filename = \"Dim_EHRLocation.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"CSV file '{csv_filename}' created with {len(df)} records.\")\n",
    "\n",
    "# Create (or connect to) the SQLite database and store the data in the Dim_CensusLocation table.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df.to_sql(\"Dim_EHRLocation\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Data stored in SQLite database '{db_filename}' in table 'Dim_EHRLocation'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Dim_Unit.csv' created with 10 records.\n",
      "Data stored in SQLite database 'medical_events.db' in table 'Dim_Unit'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Define 10 realistic unit names for senior living.\n",
    "unit_names = [\n",
    "\"AppleBlossom\",\n",
    "\"Red Dogwood\",\n",
    "\"Resident Services\",\n",
    "\"River Birch\",\n",
    "\"River View Way\",\n",
    "\"Rose Willow Way\",\n",
    "\"SILVER BR\",\n",
    "\"Silver Birch\",\n",
    "\"Silver Oak Court\",\n",
    "\"Spruce Run\"\n",
    "]\n",
    "\n",
    "# Function to generate a random timestamp between two datetime objects.\n",
    "def random_timestamp(start, end):\n",
    "    delta = end - start\n",
    "    random_seconds = random.randint(0, int(delta.total_seconds()))\n",
    "    return start + timedelta(seconds=random_seconds)\n",
    "\n",
    "# Set the date range for RecordIngestedOn.\n",
    "start_date = datetime(2025, 1, 1)\n",
    "end_date = datetime(2025, 3, 31)\n",
    "\n",
    "# Create data for each unit.\n",
    "data = []\n",
    "for i, unit_name in enumerate(unit_names, start=1):\n",
    "    row = {\n",
    "        \"UnitKey\": i,\n",
    "        \"UnitId\": str(i),\n",
    "        \"UnitCode\": str(i),  # Using the unit number as the code.\n",
    "        \"UnitName\": unit_name,\n",
    "        \"RecordIngestedOn\": random_timestamp(start_date, end_date).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    data.append(row)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "csv_filename = \"Dim_Unit.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"CSV file '{csv_filename}' created with {len(df)} records.\")\n",
    "\n",
    "# Create (or connect to) the SQLite database and store the data in the Dim_CensusUnit table.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df.to_sql(\"Dim_Unit\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Data stored in SQLite database '{db_filename}' in table 'Dim_Unit'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Dim_MedicalEventType.csv' created with 26 records.\n",
      "Data stored in SQLite database 'medical_events.db' in table 'Dim_MedicalEventType'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# List to hold our event type records.\n",
    "data = []\n",
    "key = 1\n",
    "\n",
    "# Group: Infection (4 events)\n",
    "infection_events = [\"Bacterial Infection\", \"Viral Infection\", \"Fungal Infection\", \"Urinary Tract Infection\"]\n",
    "for event in infection_events:\n",
    "    data.append({\n",
    "        \"MedicalEventTypeKey\": key,\n",
    "        \"MedicalEventTypeName\": event,\n",
    "        \"MedicalEventTypeGroup\": \"Infection\"\n",
    "    })\n",
    "    key += 1\n",
    "\n",
    "# Group: Medication Error (4 events)\n",
    "med_error_events = [\"Wrong Dosage\", \"Missed Dose\", \"Incorrect Medication\", \"Administration Error\"]\n",
    "for event in med_error_events:\n",
    "    data.append({\n",
    "        \"MedicalEventTypeKey\": key,\n",
    "        \"MedicalEventTypeName\": event,\n",
    "        \"MedicalEventTypeGroup\": \"Medication Error\"\n",
    "    })\n",
    "    key += 1\n",
    "\n",
    "# Group: Fall (3 events)\n",
    "fall_events = [\"Slip and Fall\", \"Trip Fall\", \"Fainting Fall\"]\n",
    "for event in fall_events:\n",
    "    data.append({\n",
    "        \"MedicalEventTypeKey\": key,\n",
    "        \"MedicalEventTypeName\": event,\n",
    "        \"MedicalEventTypeGroup\": \"Fall\"\n",
    "    })\n",
    "    key += 1\n",
    "\n",
    "# Group: Wound (3 events)\n",
    "wound_events = [\"Pressure Ulcer\", \"Laceration\", \"Abrasion\"]\n",
    "for event in wound_events:\n",
    "    data.append({\n",
    "        \"MedicalEventTypeKey\": key,\n",
    "        \"MedicalEventTypeName\": event,\n",
    "        \"MedicalEventTypeGroup\": \"Wound\"\n",
    "    })\n",
    "    key += 1\n",
    "\n",
    "# Group: Lab (3 events)\n",
    "lab_events = [\"Abnormal Blood Test\", \"High Cholesterol\", \"Low Hemoglobin\"]\n",
    "for event in lab_events:\n",
    "    data.append({\n",
    "        \"MedicalEventTypeKey\": key,\n",
    "        \"MedicalEventTypeName\": event,\n",
    "        \"MedicalEventTypeGroup\": \"Lab\"\n",
    "    })\n",
    "    key += 1\n",
    "\n",
    "# Group: Behavioral (3 events)\n",
    "behavioral_events = [\"Agitation\", \"Wandering\", \"Verbal Aggression\"]\n",
    "for event in behavioral_events:\n",
    "    data.append({\n",
    "        \"MedicalEventTypeKey\": key,\n",
    "        \"MedicalEventTypeName\": event,\n",
    "        \"MedicalEventTypeGroup\": \"Behavioral\"\n",
    "    })\n",
    "    key += 1\n",
    "\n",
    "# Group: Equipment Failure (3 events)\n",
    "equipment_events = [\"Ventilator Malfunction\", \"IV Pump Failure\", \"Monitoring Device Error\"]\n",
    "for event in equipment_events:\n",
    "    data.append({\n",
    "        \"MedicalEventTypeKey\": key,\n",
    "        \"MedicalEventTypeName\": event,\n",
    "        \"MedicalEventTypeGroup\": \"Equipment Failure\"\n",
    "    })\n",
    "    key += 1\n",
    "\n",
    "# Group: Allergy (3 events)\n",
    "allergy_events = [\"Food Allergy Reaction\", \"Medication Allergy Reaction\", \"Environmental Allergy Reaction\"]\n",
    "for event in allergy_events:\n",
    "    data.append({\n",
    "        \"MedicalEventTypeKey\": key,\n",
    "        \"MedicalEventTypeName\": event,\n",
    "        \"MedicalEventTypeGroup\": \"Allergy\"\n",
    "    })\n",
    "    key += 1\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "csv_filename = \"Dim_MedicalEventType.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"CSV file '{csv_filename}' created with {len(df)} records.\")\n",
    "\n",
    "# Save the data into a SQLite database.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df.to_sql(\"Dim_MedicalEventType\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Data stored in SQLite database '{db_filename}' in table 'Dim_MedicalEventType'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Dim_MedicalEventSeverity.csv' created with 20 records.\n",
      "Data stored in SQLite database 'medical_events.db' in table 'Dim_MedicalEventSeverity'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Define a list of 20 representative medical event severity values.\n",
    "# Each severity has a unique key starting from 1.\n",
    "severity_data = [\n",
    "    {\"MedicalEventSeverityKey\": 1, \"MedicalEventSeverity\": \"BLOOD CULTURE #1\"},\n",
    "    {\"MedicalEventSeverityKey\": 2, \"MedicalEventSeverity\": \"BLOOD CULTURE #2\"},\n",
    "    {\"MedicalEventSeverityKey\": 3, \"MedicalEventSeverity\": \"Bacteremia\"},\n",
    "    {\"MedicalEventSeverityKey\": 4, \"MedicalEventSeverity\": \"Bronchitis\"},\n",
    "    {\"MedicalEventSeverityKey\": 5, \"MedicalEventSeverity\": \"CULTURE, ANAEROBIC\"},\n",
    "    {\"MedicalEventSeverityKey\": 6, \"MedicalEventSeverity\": \"CULTURE, SPUTUM\"},\n",
    "    {\"MedicalEventSeverityKey\": 7, \"MedicalEventSeverity\": \"Candidiasis\"},\n",
    "    {\"MedicalEventSeverityKey\": 8, \"MedicalEventSeverity\": \"Cellulitis\"},\n",
    "    {\"MedicalEventSeverityKey\": 9, \"MedicalEventSeverity\": \"Covid 19\"},\n",
    "    {\"MedicalEventSeverityKey\": 10, \"MedicalEventSeverity\": \"Herpes Simplex\"},\n",
    "    {\"MedicalEventSeverityKey\": 11, \"MedicalEventSeverity\": \"Impetigo\"},\n",
    "    {\"MedicalEventSeverityKey\": 12, \"MedicalEventSeverity\": \"Influenza A\"},\n",
    "    {\"MedicalEventSeverityKey\": 13, \"MedicalEventSeverity\": \"Osteomyelitis\"},\n",
    "    {\"MedicalEventSeverityKey\": 14, \"MedicalEventSeverity\": \"Otitis Media\"},\n",
    "    {\"MedicalEventSeverityKey\": 15, \"MedicalEventSeverity\": \"Pneumonia\"},\n",
    "    {\"MedicalEventSeverityKey\": 16, \"MedicalEventSeverity\": \"Sepsis, unspecified\"},\n",
    "    {\"MedicalEventSeverityKey\": 17, \"MedicalEventSeverity\": \"Septicemia\"},\n",
    "    {\"MedicalEventSeverityKey\": 18, \"MedicalEventSeverity\": \"Severity Level 1-No Harm/Damage\"},\n",
    "    {\"MedicalEventSeverityKey\": 19, \"MedicalEventSeverity\": \"Severity Level 3-Serious Injury/Damage\"},\n",
    "    {\"MedicalEventSeverityKey\": 20, \"MedicalEventSeverity\": \"Severity Level 4-Death\"}\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame.\n",
    "df = pd.DataFrame(severity_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "csv_filename = \"Dim_MedicalEventSeverity.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"CSV file '{csv_filename}' created with {len(df)} records.\")\n",
    "\n",
    "# Connect to the SQLite database and store the data in the Dim_MedicalEventSeverity table.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df.to_sql(\"Dim_MedicalEventSeverity\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Data stored in SQLite database '{db_filename}' in table 'Dim_MedicalEventSeverity'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Dim_EventStatus.csv' created with 8 records.\n",
      "Data stored in SQLite database 'medical_events.db' in table 'Dim_EventStatus'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Create a list of dictionaries for event status data.\n",
    "data = [\n",
    "    {\"EventStatusKey\": 1, \"EventStatusName\": \"Closed\", \"EventStatusReason\": \"Criteria Not Met\"},\n",
    "    {\"EventStatusKey\": 2, \"EventStatusName\": \"Closed\", \"EventStatusReason\": \"Deceased (In House)\"},\n",
    "    {\"EventStatusKey\": 3, \"EventStatusName\": \"Closed\", \"EventStatusReason\": \"Discharged\"},\n",
    "    {\"EventStatusKey\": 4, \"EventStatusName\": \"Closed\", \"EventStatusReason\": \"Duplicate\"},\n",
    "    {\"EventStatusKey\": 5, \"EventStatusName\": \"Confirmed (D)\", \"EventStatusReason\": \"Error\"},\n",
    "    {\"EventStatusKey\": 6, \"EventStatusName\": \"Confirmed (P)\", \"EventStatusReason\": \"Resolved\"},\n",
    "    {\"EventStatusKey\": 7, \"EventStatusName\": \"Suspected\", \"EventStatusReason\": \"Criteria Not Met\"},\n",
    "    {\"EventStatusKey\": 8, \"EventStatusName\": \"Suspected\", \"EventStatusReason\": \"Error\"}\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "csv_filename = \"Dim_EventStatus.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"CSV file '{csv_filename}' created with {len(df)} records.\")\n",
    "\n",
    "# Connect to the SQLite database and store the data in the Dim_EventStatus table.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df.to_sql(\"Dim_EventStatus\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Data stored in SQLite database '{db_filename}' in table 'Dim_EventStatus'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Dim_MedicalEventDate.csv' created with 1461 records.\n",
      "Data stored in SQLite database 'medical_events.db' in table 'Dim_MedicalEventDate'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the date range: from 2021-01-01 to 2024-12-31\n",
    "start_date = datetime(2021, 1, 1)\n",
    "end_date = datetime(2024, 12, 31)\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "data = []\n",
    "for dt in date_range:\n",
    "    dt_date = dt.to_pydatetime()\n",
    "    \n",
    "    # MedicalEventDateKey: yyyyMMdd as integer\n",
    "    key = int(dt_date.strftime(\"%Y%m%d\"))\n",
    "    \n",
    "    # MedicalEventDateDate: formatted as yyyy-mm-dd 00:00:00 (change to mm-dd-yyyy if needed)\n",
    "    # The specification says mm-dd-yyyy format, so we convert accordingly.\n",
    "    med_date_date = dt_date.strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    # Determine quarter and first day of quarter\n",
    "    quarter = ((dt_date.month - 1) // 3) + 1\n",
    "    first_month_of_quarter = (quarter - 1) * 3 + 1\n",
    "    first_day_of_quarter = datetime(dt_date.year, first_month_of_quarter, 1)\n",
    "    day_in_quarter = (dt_date - first_day_of_quarter).days + 1\n",
    "    \n",
    "    # Day names and day of month\n",
    "    day_name = dt_date.strftime(\"%A\")\n",
    "    day_abbr = dt_date.strftime(\"%a\")\n",
    "    day_of_month = dt_date.day\n",
    "    \n",
    "    # Numeric day of week (1=Monday, 7=Sunday). Python's weekday(): Monday=0 ... Sunday=6\n",
    "    dow = dt_date.weekday()\n",
    "    day_of_week = dow + 1  # Now Monday=1, Sunday=7\n",
    "    \n",
    "    # Occurrence count of that weekday in the month\n",
    "    day_of_week_in_month = sum(1 for d in range(1, dt_date.day + 1)\n",
    "                               if datetime(dt_date.year, dt_date.month, d).weekday() == dow)\n",
    "    \n",
    "    # Day of year\n",
    "    day_of_year = dt_date.timetuple().tm_yday\n",
    "    \n",
    "    # First day of month, quarter, and year in specified format (mm-dd-yyyy 00:00:00)\n",
    "    first_day_of_month = dt_date.replace(day=1).strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    first_day_of_quarter_str = first_day_of_quarter.strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    first_day_of_year = datetime(dt_date.year, 1, 1).strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    # Determine holiday (simple rules for three common holidays)\n",
    "    holiday = \"\"\n",
    "    if dt_date.month == 1 and dt_date.day == 1:\n",
    "        holiday = \"New Year's Day\"\n",
    "    elif dt_date.month == 7 and dt_date.day == 4:\n",
    "        holiday = \"Independence Day\"\n",
    "    elif dt_date.month == 12 and dt_date.day == 25:\n",
    "        holiday = \"Christmas Day\"\n",
    "    \n",
    "    is_holiday = \"TRUE\" if holiday else \"FALSE\"\n",
    "    is_weekday = \"TRUE\" if dt_date.weekday() < 5 else \"FALSE\"\n",
    "    is_weekend = \"TRUE\" if dt_date.weekday() >= 5 else \"FALSE\"\n",
    "    \n",
    "    # Last day of quarter\n",
    "    last_month_of_quarter = first_month_of_quarter + 2\n",
    "    last_day_q = calendar.monthrange(dt_date.year, last_month_of_quarter)[1]\n",
    "    last_day_of_quarter = datetime(dt_date.year, last_month_of_quarter, last_day_q).strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    # Last day of month and year\n",
    "    last_day_m = calendar.monthrange(dt_date.year, dt_date.month)[1]\n",
    "    last_day_of_month = dt_date.replace(day=last_day_m).strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    last_day_of_year = datetime(dt_date.year, 12, 31).strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    # Month details\n",
    "    month = dt_date.month\n",
    "    month_abbr = dt_date.strftime(\"%b\")\n",
    "    month_name = dt_date.strftime(\"%B\")\n",
    "    month_of_quarter = dt_date.month - first_month_of_quarter + 1  # as string below\n",
    "    \n",
    "    # Quarter details\n",
    "    quarter_num = quarter\n",
    "    quarter_name = {1: \"First\", 2: \"Second\", 3: \"Third\", 4: \"Fourth\"}[quarter_num]\n",
    "    quarter_short_name = f\"Q{quarter_num}\"\n",
    "    \n",
    "    # Week of month, quarter, and year\n",
    "    week_of_month = (dt_date.day - 1) // 7 + 1\n",
    "    week_of_quarter = ((dt_date - first_day_of_quarter).days) // 7 + 1\n",
    "    week_of_year = dt_date.isocalendar()[1]\n",
    "    \n",
    "    # YYYYMM formatted as yyyy/MM\n",
    "    yyyy_mm = dt_date.strftime(\"%Y/%m\")\n",
    "    \n",
    "    year = dt_date.year\n",
    "    year_and_quarter = f\"{year}/Q{quarter_num}\"\n",
    "    year_month = f\"{year}/{dt_date.strftime('%b')}\"\n",
    "    year_name = f\"CY {year}\"\n",
    "    \n",
    "    # Fiscal calculations (assume fiscal year starts on October 1)\n",
    "    if dt_date.month < 10:\n",
    "        fiscal_start = datetime(dt_date.year - 1, 10, 1)\n",
    "    else:\n",
    "        fiscal_start = datetime(dt_date.year, 10, 1)\n",
    "    fiscal_start_str = fiscal_start.strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    # Fiscal Date Key: we can reuse key (or compute similarly)\n",
    "    fiscal_date_key = key  # as string in our schema\n",
    "    fiscal_day_of_year = (dt_date - fiscal_start).days + 1\n",
    "    # Fiscal month: October becomes month 1, November 2, etc.\n",
    "    fiscal_month = dt_date.month - 9 if dt_date.month >= 10 else dt_date.month + 3\n",
    "    fiscal_quarter = ((fiscal_month - 1) // 3) + 1\n",
    "    fiscal_quarter_name = f\"Q{fiscal_quarter}\"\n",
    "    fiscal_week_of_year = ((dt_date - fiscal_start).days) // 7 + 1\n",
    "    fiscal_year_val = dt_date.year if dt_date.month < 10 else dt_date.year + 1\n",
    "    fiscal_year = f\"FY{fiscal_year_val}\"\n",
    "    \n",
    "    is_first_day_fiscal = \"TRUE\" if dt_date.date() == fiscal_start.date() else \"FALSE\"\n",
    "    fiscal_year_end = datetime(fiscal_year_val, 9, 30)\n",
    "    is_last_day_fiscal = \"TRUE\" if dt_date.date() == fiscal_year_end.date() else \"FALSE\"\n",
    "    last_day_fiscal = fiscal_year_end.strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    row = {\n",
    "        \"MedicalEventDateKey\": key,\n",
    "        \"MedicalEventDateDate\": med_date_date,\n",
    "        \"MedicalEventDateDayInQuarter\": str(day_in_quarter),\n",
    "        \"MedicalEventDateDayName\": day_name,\n",
    "        \"MedicalEventDateDayNameAbbrevation\": day_abbr,\n",
    "        \"MedicalEventDateDayOfMonth\": str(day_of_month),\n",
    "        \"MedicalEventDateDayOfWeek\": str(day_of_week),\n",
    "        \"MedicalEventDateDayOfWeekInMonth\": str(day_of_week_in_month),\n",
    "        \"MedicalEventDateDayOfYear\": str(day_of_year),\n",
    "        \"MedicalEventDateFirstDayOfMonth\": first_day_of_month,\n",
    "        \"MedicalEventDateFirstDayOfQuarter\": first_day_of_quarter_str,\n",
    "        \"MedicalEventDateFirstDayofYear\": first_day_of_year,\n",
    "        \"MedicalEventDateHoliday\": holiday,\n",
    "        \"MedicalEventDateIsHoliday\": is_holiday,\n",
    "        \"MedicalEventDateIsWeekday\": is_weekday,\n",
    "        \"MedicalEventDateIsWeekend\": is_weekend,\n",
    "        \"MedicalEventDateLastDayOfQuarter\": last_day_of_quarter,\n",
    "        \"MedicalEventDateLastDayofMonth\": last_day_of_month,\n",
    "        \"MedicalEventDateLastDayofYear\": last_day_of_year,\n",
    "        \"MedicalEventDateMonth\": str(month),\n",
    "        \"MedicalEventDateMonthAbbrevation\": month_abbr,\n",
    "        \"MedicalEventDateMonthName\": month_name,\n",
    "        \"MedicalEventDateMonthOfQuarter\": str(month_of_quarter),\n",
    "        \"MedicalEventDateQuarter\": str(quarter_num),\n",
    "        \"MedicalEventDateQuarterName\": quarter_name,\n",
    "        \"MedicalEventDateQuarterShortName\": quarter_short_name,\n",
    "        \"MedicalEventDateWeekOfMonth\": str(week_of_month),\n",
    "        \"MedicalEventDateWeekOfQuarter\": str(week_of_quarter),\n",
    "        \"MedicalEventDateWeekOfYear\": str(week_of_year),\n",
    "        \"MedicalEventDateYYYYMM\": yyyy_mm,\n",
    "        \"MedicalEventDateYear\": str(year),\n",
    "        \"MedicalEventDateYearAndQuarter\": year_and_quarter,\n",
    "        \"MedicalEventDateYearMonth\": year_month,\n",
    "        \"MedicalEventDateYearName\": year_name,\n",
    "        \"MedicalEventDateFirstDayOfFiscalYear\": fiscal_start_str,\n",
    "        \"MedicalEventDateFiscalDateKey\": str(fiscal_date_key),\n",
    "        \"MedicalEventDateFiscalDayOfYear\": str(fiscal_day_of_year),\n",
    "        \"MedicalEventDateFiscalMonth\": str(fiscal_month),\n",
    "        \"MedicalEventDateFiscalQuarter\": str(fiscal_quarter),\n",
    "        \"MedicalEventDateFiscalQuarterName\": fiscal_quarter_name,\n",
    "        \"MedicalEventDateFiscalWeekOfYear\": str(fiscal_week_of_year),\n",
    "        \"MedicalEventDateFiscalYear\": fiscal_year,\n",
    "        \"MedicalEventDateIsFirstDayOfFiscalYear\": is_first_day_fiscal,\n",
    "        \"MedicalEventDateIsLastOfFiscalYear\": is_last_day_fiscal,\n",
    "        \"MedicalEventDateLastDayOfFiscalYear\": last_day_fiscal\n",
    "    }\n",
    "    data.append(row)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "csv_filename = \"Dim_MedicalEventDate.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"CSV file '{csv_filename}' created with {len(df)} records.\")\n",
    "\n",
    "# Create (or connect to) the SQLite database and store the data.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df.to_sql(\"Dim_MedicalEventDate\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Data stored in SQLite database '{db_filename}' in table 'Dim_MedicalEventDate'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Dim_ReportDate.csv' created with 1461 records.\n",
      "Data stored in SQLite database 'medical_events.db' in table 'Dim_ReportDate'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the date range: from 2021-01-01 to 2024-12-31\n",
    "start_date = datetime(2021, 1, 1)\n",
    "end_date = datetime(2024, 12, 31)\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "data = []\n",
    "for dt in date_range:\n",
    "    dt_date = dt.to_pydatetime()\n",
    "    \n",
    "    # ReportDateKey: yyyyMMdd as integer\n",
    "    key = int(dt_date.strftime(\"%Y%m%d\"))\n",
    "    \n",
    "    # ReportDateDate: formatted as mm-dd-yyyy 00:00:00\n",
    "    report_date_date = dt_date.strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    # Determine quarter and first day of quarter\n",
    "    quarter = ((dt_date.month - 1) // 3) + 1\n",
    "    first_month_of_quarter = (quarter - 1) * 3 + 1\n",
    "    first_day_of_quarter = datetime(dt_date.year, first_month_of_quarter, 1)\n",
    "    day_in_quarter = (dt_date - first_day_of_quarter).days + 1\n",
    "    \n",
    "    # Day names and day of month\n",
    "    day_name = dt_date.strftime(\"%A\")\n",
    "    day_abbr = dt_date.strftime(\"%a\")\n",
    "    day_of_month = dt_date.day\n",
    "    \n",
    "    # Numeric day of week (1=Monday, 7=Sunday); Python: Monday=0 ... Sunday=6\n",
    "    dow = dt_date.weekday()\n",
    "    day_of_week = dow + 1\n",
    "    \n",
    "    # Occurrence count of that weekday in the month\n",
    "    day_of_week_in_month = sum(1 for d in range(1, dt_date.day + 1)\n",
    "                               if datetime(dt_date.year, dt_date.month, d).weekday() == dow)\n",
    "    \n",
    "    # Day of year\n",
    "    day_of_year = dt_date.timetuple().tm_yday\n",
    "    \n",
    "    # First day values for month, quarter, and year (formatted as mm-dd-yyyy 00:00:00)\n",
    "    first_day_of_month = dt_date.replace(day=1).strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    first_day_of_quarter_str = first_day_of_quarter.strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    first_day_of_year = datetime(dt_date.year, 1, 1).strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    # Determine holiday (simple rules for three common holidays)\n",
    "    holiday = \"\"\n",
    "    if dt_date.month == 1 and dt_date.day == 1:\n",
    "        holiday = \"New Year's Day\"\n",
    "    elif dt_date.month == 7 and dt_date.day == 4:\n",
    "        holiday = \"Independence Day\"\n",
    "    elif dt_date.month == 12 and dt_date.day == 25:\n",
    "        holiday = \"Christmas Day\"\n",
    "    \n",
    "    is_holiday = \"TRUE\" if holiday else \"FALSE\"\n",
    "    is_weekday = \"TRUE\" if dt_date.weekday() < 5 else \"FALSE\"\n",
    "    is_weekend = \"TRUE\" if dt_date.weekday() >= 5 else \"FALSE\"\n",
    "    \n",
    "    # Last day of quarter\n",
    "    last_month_of_quarter = first_month_of_quarter + 2\n",
    "    last_day_q = calendar.monthrange(dt_date.year, last_month_of_quarter)[1]\n",
    "    last_day_of_quarter = datetime(dt_date.year, last_month_of_quarter, last_day_q).strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    # Last day of month and year\n",
    "    last_day_m = calendar.monthrange(dt_date.year, dt_date.month)[1]\n",
    "    last_day_of_month = dt_date.replace(day=last_day_m).strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    last_day_of_year = datetime(dt_date.year, 12, 31).strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    # Month details\n",
    "    month = dt_date.month\n",
    "    month_abbr = dt_date.strftime(\"%b\")\n",
    "    month_name = dt_date.strftime(\"%B\")\n",
    "    month_of_quarter = dt_date.month - first_month_of_quarter + 1\n",
    "    \n",
    "    # Quarter details\n",
    "    quarter_num = quarter\n",
    "    quarter_name = {1: \"First\", 2: \"Second\", 3: \"Third\", 4: \"Fourth\"}[quarter_num]\n",
    "    quarter_short_name = f\"Q{quarter_num}\"\n",
    "    \n",
    "    # Week numbers\n",
    "    week_of_month = (dt_date.day - 1) // 7 + 1\n",
    "    week_of_quarter = ((dt_date - first_day_of_quarter).days) // 7 + 1\n",
    "    week_of_year = dt_date.isocalendar()[1]\n",
    "    \n",
    "    # YYYYMM formatted as yyyy/MM\n",
    "    yyyy_mm = dt_date.strftime(\"%Y/%m\")\n",
    "    \n",
    "    year = dt_date.year\n",
    "    year_and_quarter = f\"{year}/Q{quarter_num}\"\n",
    "    year_month = f\"{year}/{dt_date.strftime('%b')}\"\n",
    "    year_name = f\"CY {year}\"\n",
    "    \n",
    "    # Fiscal calculations (assume fiscal year starts on October 1)\n",
    "    if dt_date.month < 10:\n",
    "        fiscal_start = datetime(dt_date.year - 1, 10, 1)\n",
    "    else:\n",
    "        fiscal_start = datetime(dt_date.year, 10, 1)\n",
    "    fiscal_start_str = fiscal_start.strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    # Fiscal Date Key (reuse key) and other fiscal values\n",
    "    fiscal_date_key = key\n",
    "    fiscal_day_of_year = (dt_date - fiscal_start).days + 1\n",
    "    fiscal_month = dt_date.month - 9 if dt_date.month >= 10 else dt_date.month + 3\n",
    "    fiscal_quarter = ((fiscal_month - 1) // 3) + 1\n",
    "    fiscal_quarter_name = f\"Q{fiscal_quarter}\"\n",
    "    fiscal_week_of_year = ((dt_date - fiscal_start).days) // 7 + 1\n",
    "    fiscal_year_val = dt_date.year if dt_date.month < 10 else dt_date.year + 1\n",
    "    fiscal_year = f\"FY{fiscal_year_val}\"\n",
    "    \n",
    "    is_first_day_fiscal = \"TRUE\" if dt_date.date() == fiscal_start.date() else \"FALSE\"\n",
    "    fiscal_year_end = datetime(fiscal_year_val, 9, 30)\n",
    "    is_last_day_fiscal = \"TRUE\" if dt_date.date() == fiscal_year_end.date() else \"FALSE\"\n",
    "    last_day_fiscal = fiscal_year_end.strftime(\"%m-%d-%Y 00:00:00\")\n",
    "    \n",
    "    row = {\n",
    "        \"ReportDateKey\": key,\n",
    "        \"ReportDateDate\": report_date_date,\n",
    "        \"ReportDateDayInQuarter\": str(day_in_quarter),\n",
    "        \"ReportDateDayName\": day_name,\n",
    "        \"ReportDateDayNameAbbrevation\": day_abbr,\n",
    "        \"ReportDateDayOfMonth\": str(day_of_month),\n",
    "        \"ReportDateDayOfWeek\": str(day_of_week),\n",
    "        \"ReportDateDayOfWeekInMonth\": str(day_of_week_in_month),\n",
    "        \"ReportDateDayOfYear\": str(day_of_year),\n",
    "        \"ReportDateFirstDayOfMonth\": first_day_of_month,\n",
    "        \"ReportDateFirstDayOfQuarter\": first_day_of_quarter_str,\n",
    "        \"ReportDateFirstDayofYear\": first_day_of_year,\n",
    "        \"ReportDateHoliday\": holiday,\n",
    "        \"ReportDateIsHoliday\": is_holiday,\n",
    "        \"ReportDateIsWeekday\": is_weekday,\n",
    "        \"ReportDateIsWeekend\": is_weekend,\n",
    "        \"ReportDateLastDayOfQuarter\": last_day_of_quarter,\n",
    "        \"ReportDateLastDayofMonth\": last_day_of_month,\n",
    "        \"ReportDateLastDayofYear\": last_day_of_year,\n",
    "        \"ReportDateMonth\": str(month),\n",
    "        \"ReportDateMonthAbbrevation\": month_abbr,\n",
    "        \"ReportDateMonthName\": month_name,\n",
    "        \"ReportDateMonthOfQuarter\": str(month_of_quarter),\n",
    "        \"ReportDateQuarter\": str(quarter_num),\n",
    "        \"ReportDateQuarterName\": quarter_name,\n",
    "        \"ReportDateQuarterShortName\": quarter_short_name,\n",
    "        \"ReportDateWeekOfMonth\": str(week_of_month),\n",
    "        \"ReportDateWeekOfQuarter\": str(week_of_quarter),\n",
    "        \"ReportDateWeekOfYear\": str(week_of_year),\n",
    "        \"ReportDateYYYYMM\": yyyy_mm,\n",
    "        \"ReportDateYear\": str(year),\n",
    "        \"ReportDateYearAndQuarter\": year_and_quarter,\n",
    "        \"ReportDateYearMonth\": year_month,\n",
    "        \"ReportDateYearName\": year_name,\n",
    "        \"ReportDateFirstDayOfFiscalYear\": fiscal_start_str,\n",
    "        \"ReportDateFiscalDateKey\": str(fiscal_date_key),\n",
    "        \"ReportDateFiscalDayOfYear\": str(fiscal_day_of_year),\n",
    "        \"ReportDateFiscalMonth\": str(fiscal_month),\n",
    "        \"ReportDateFiscalQuarter\": str(fiscal_quarter),\n",
    "        \"ReportDateFiscalQuarterName\": fiscal_quarter_name,\n",
    "        \"ReportDateFiscalWeekOfYear\": str(fiscal_week_of_year),\n",
    "        \"ReportDateFiscalYear\": fiscal_year,\n",
    "        \"ReportDateIsFirstDayOfFiscalYear\": is_first_day_fiscal,\n",
    "        \"ReportDateIsLastOfFiscalYear\": is_last_day_fiscal,\n",
    "        \"ReportDateLastDayOfFiscalYear\": last_day_fiscal\n",
    "    }\n",
    "    data.append(row)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "csv_filename = \"Dim_ReportDate.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"CSV file '{csv_filename}' created with {len(df)} records.\")\n",
    "\n",
    "# Create (or connect to) the SQLite database and store the data.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df.to_sql(\"Dim_ReportDate\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Data stored in SQLite database '{db_filename}' in table 'Dim_ReportDate'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Fact_MedicalEvent.csv' created with 200 records.\n",
      "Data stored in SQLite database 'medical_events.db' in table 'Fact_MedicalEvent'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define date range for report and medical event dates.\n",
    "date_start = datetime(2021, 1, 1)\n",
    "date_end = datetime(2024, 12, 31)\n",
    "\n",
    "def random_date_key(start, end):\n",
    "    \"\"\"Generate a random date between start and end, formatted as yyyyMMdd (integer).\"\"\"\n",
    "    delta = end - start\n",
    "    random_days = random.randint(0, delta.days)\n",
    "    date_val = start + timedelta(days=random_days)\n",
    "    return int(date_val.strftime(\"%Y%m%d\"))\n",
    "\n",
    "def random_time():\n",
    "    \"\"\"Generate a random time in h:mm:ss AM/PM format.\"\"\"\n",
    "    hour = random.randint(1, 12)\n",
    "    minute = random.randint(0, 59)\n",
    "    second = random.randint(0, 59)\n",
    "    am_pm = random.choice([\"AM\", \"PM\"])\n",
    "    return f\"{hour}:{minute:02d}:{second:02d} {am_pm}\"\n",
    "\n",
    "# Define lists for random selection for text fields.\n",
    "detail_options = [\n",
    "    \"COLONY COUNT: 100,000+ GRAM-POSITIVE COCCI IN CHAINS\",\n",
    "    \"COLONY COUNT: 50,000 MIXED FLORA - THREE OR MORE SPECIES PRESENT\",\n",
    "    \"ISOLATION OF THREE OR MORE DIFFERENT BACTERIA. PLEASE REPEAT IF CLINICALLY INDICATED\",\n",
    "    \"LABORATORY CONFIRMATION OF BACTERIAL PATHOGEN\",\n",
    "    \"SIGNIFICANT ELEVATION IN WHITE BLOOD CELL COUNT\"\n",
    "]\n",
    "\n",
    "prescription_options = [\n",
    "    \"Molnupiravir Oral Capsule 200 MG (Aug 22, 2024 - Aug 27, 2024)\",\n",
    "    \"Flomax Capsule 0.4 MG (Dec 07, 2024 - Indefinite)\",\n",
    "    \"Atorvastatin Tablet 20 MG (Jan 01, 2025 - Indefinite)\",\n",
    "    \"Metformin Tablet 500 MG (Feb 15, 2025 - Indefinite)\"\n",
    "]\n",
    "\n",
    "room_options = [\n",
    "    \"cafeteria\", \"activity room\", \"E110\", \"E120\", \"Nursing Station\", \"Lobby\"\n",
    "]\n",
    "\n",
    "num_records = 200\n",
    "fact_data = []\n",
    "\n",
    "for i in range(1, num_records + 1):\n",
    "    record = {\n",
    "        \"ResidentKey\": random.randint(1, 500),  # from Dim_Resident\n",
    "        \"FacilityKey\": random.randint(1, 5),     # from Dim_Facility\n",
    "        \"UnitKey\": random.randint(1, 10),         # from Dim_Unit\n",
    "        \"LocationKey\": random.randint(1, 5),     # from Dim_EHRLocation (or similar)\n",
    "        \"MedicalEventTypeKey\": random.randint(1, 26),  # from Dim_MedicalEventType\n",
    "        \"MedicalEventSeverityKey\": random.randint(1, 20),  # from Dim_MedicalEventSeverity\n",
    "        \"EventStatusKey\": random.randint(1, 8),   # from Dim_EventStatus\n",
    "        \"ReportDateKey\": random_date_key(date_start, date_end),  # from Dim_ReportDate\n",
    "        \"MedicalEventDateKey\": random_date_key(date_start, date_end),  # from Dim_MedicalEventDate\n",
    "        \"EventId\": str(i),\n",
    "        \"MedicalEventFactId\": \"MEF\" + str(i),\n",
    "        \"MedicalEventDetail\": random.choice(detail_options),\n",
    "        \"Evaluation\": random.choice([\"Positive\", \"Negative\", \"Inconclusive\"]),\n",
    "        \"Etiology\": random.choice([\"On Admission\", \"In House\", \"Community-Acquired\"]),\n",
    "        \"Prescription\": random.choice(prescription_options),\n",
    "        \"MedicalEventRoom\": random.choice(room_options),\n",
    "        \"MedicalEventTime\": random_time(),\n",
    "        \"InjuryFlag\": random.choice([\"Y\", \"N\"]),\n",
    "        \"WoundFlag\": random.choice([\"Y\", \"N\"]),\n",
    "        \"MedicationErrorFlag\": random.choice([\"Y\", \"N\"]),\n",
    "        \"NatureOfInjury\": random.choice([\"wound re-opened\", \"ulcer\", \"none\", \"abrasion\"]),\n",
    "        \"DegreeOfInjury\": random.choice([\n",
    "            \"Moderate Injury, Treatment Required\", \n",
    "            \"Mild Injury, First Aid Required\", \n",
    "            \"Severe Injury, Hospitalization Required\", \n",
    "            \"No Injury\"\n",
    "        ]),\n",
    "        \"SafetyPrecautionTaken\": random.choice([\n",
    "            \"wheelchair brakes on\", \"walker available\", \"none\", \"bed rails secured\"\n",
    "        ]),\n",
    "        \"Organism\": random.choice([\n",
    "            \"ENTEROCOCCUS FAECIUM\", \"PROTEUS MIRABILIS\", \"ENTEROCOCCUS FAECALIS\", \n",
    "            \"STAPHYLOCOCCUS AUREUS\", \"Escherichia Coli\", \"Pseudomonas aeruginosa\", \n",
    "            \"Klebsiella pneumoniae\", \"NONE\"\n",
    "        ])\n",
    "    }\n",
    "    fact_data.append(record)\n",
    "\n",
    "# Create a DataFrame from the fact records.\n",
    "df_fact = pd.DataFrame(fact_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "csv_filename = \"Fact_MedicalEvent.csv\"\n",
    "df_fact.to_csv(csv_filename, index=False)\n",
    "print(f\"CSV file '{csv_filename}' created with {num_records} records.\")\n",
    "\n",
    "# Connect to the SQLite database and store the fact table.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df_fact.to_sql(\"Fact_MedicalEvent\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Data stored in SQLite database '{db_filename}' in table 'Fact_MedicalEvent'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Fact_MedicalEvent_WithNotes.csv' created with ClinicalNotes column.\n",
      "Updated Fact_MedicalEvent table stored in SQLite database 'medical_events.db'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ----- Your existing fact table generation code (simplified) -----\n",
    "# Assuming you have already generated your fact table DataFrame as df_fact\n",
    "# For example:\n",
    "df_fact = pd.read_csv(\"Fact_MedicalEvent.csv\")\n",
    "# (Or use your generation code provided earlier.)\n",
    "\n",
    "# For demonstration, let's assume df_fact exists. (Replace this with your actual df_fact.)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Initialize the LLM (ensure you have your config and API key set correctly)\n",
    "llm = AzureChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    deployment_name=\"az-gpt_35_model\",\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    azure_endpoint=\"https://az-openai-document-question-answer-service.openai.azure.com/\",\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    openai_api_key=\"5d24331966b648738e5003caad552df8\"            \n",
    ")\n",
    "\n",
    "# Define the prompt for generating clinical notes.\n",
    "notes_gen_prompt = (\"\"\"\n",
    "    \"You are a medical note generator. Based on the following medical event data, \"\n",
    "    \"generate a detailed clinical note that a nurse might record in the patient's chart. \"\n",
    "    \"Incorporate relevant details such as DegreeOfInjury, NatureOfInjury, SafetyPrecautionTaken, \"\n",
    "    \"Prescription, MedicalEventDetail, and Evaluation into a coherent narrative. \"\n",
    "    \"Do not simply list the values; produce a natural language note.\"\n",
    "    Use Below Format : \n",
    "   1.  Upon observation the nurse noted dried blood under the left foot 5th toenail, 0.2x0.2cm skin tear on left 4th toe. Right shin with superficial skin tear 0.1x0.1x<0.1cm. \n",
    "   Resident stated, \"he bumped himself in the gym at 2pm this afternoon, and that he scratched his leg\".\n",
    "2. Resident found to have a skin tear to the right outer ankle.\n",
    "called by OT to assessed skin tear to left FA, skin tear measured 5.5cm x 4cm x0.1cm. half moon shape skin flap scant bleeding noted. \n",
    "and Vera denies any pain. Per Loren it happened during transfer from toilet to chair. \n",
    "she and the CNA assisted her during the transfer.  MD notified and received order to apply steri strip xeroform cover abd. pad wrap with kling and wound consult. daughter Lyn aware as well.\n",
    "\n",
    "3. Discoloration with a skin tear measuring 1cm x 1.4cm to right lower leg.\n",
    "4. Resident sustained a sheered skin tear to right lower leg during transfer.\n",
    "5. Skin tear might have been caused by resident's action while sitting on the wheelchair. Site of skin tear was the same level as where the leg rest were in place.\n",
    "6. esident was sent out to the ER for agitation during the night, came back with bruise and skin tear. Prior going to the ER his skin was intact as per last weekly skin observation on 3/21/24.\n",
    ",resident reported to the care attendant a self-inflicted wound to the back of his hand. He told care partner that he caught his hand- back of his hand, on the side of the bedside table on front of him, a skin tear measuring 1cm x 1 cm was noted in between his 2nd and 3rd knuckles. Skin tear protocol initiated.\n",
    "7. This writer with CNA  was transferring resident with Hoyer lift.  Instructed resident to hug himself , resident  then lifted his arms to hold the Hoyer, accidentally hit his right hand on the mechanical lift (Hoyer) machine and sustained skin tear. Scant amount of bleeding noted. Skin tear measured :5cm x 3.5cm. Tx given. Megan APN notified. Ordered to apply Xeroform daily until heal. Daughter Diane visited during dinner time and notified.\n",
    "    \"\"\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", notes_gen_prompt),\n",
    "    (\"human\", \"Medical event data:\\n{data_from_fact}\")\n",
    "])\n",
    "\n",
    "# Define a function that takes a fact record (row) and returns a generated ClinicalNotes string.\n",
    "def generate_clinical_notes(row):\n",
    "    # Construct an input string from the key columns.\n",
    "    data_from_fact = (\n",
    "        f\"DegreeOfInjury: {row['DegreeOfInjury']}\\n\"\n",
    "        f\"NatureOfInjury: {row['NatureOfInjury']}\\n\"\n",
    "        f\"SafetyPrecautionTaken: {row['SafetyPrecautionTaken']}\\n\"\n",
    "        f\"Prescription: {row['Prescription']}\\n\"\n",
    "        f\"MedicalEventDetail: {row['MedicalEventDetail']}\\n\"\n",
    "        f\"Evaluation: {row['Evaluation']}\\n\"\n",
    "        f\"Etiology: {row.get('Etiology', 'N/A')}\\n\"\n",
    "        f\"Organism: {row.get('Organism', 'N/A')}\"\n",
    "    )\n",
    "    # Format the prompt.\n",
    "    prompt_input = prompt.format_prompt(data_from_fact=data_from_fact)\n",
    "    # Invoke the LLM.\n",
    "    response = llm.invoke(prompt_input)\n",
    "    return response.content.strip()\n",
    "\n",
    "# For demonstration, process a small sample first.\n",
    "# Uncomment the next two lines to process only the first 10 rows:\n",
    "# df_sample = df_fact.head(10).copy()\n",
    "# df_sample[\"ClinicalNotes\"] = df_sample.apply(generate_clinical_notes, axis=1); print(df_sample[[\"MedicalEventDetail\", \"ClinicalNotes\"]])\n",
    "\n",
    "# To update the full fact table with clinical notes, apply the function row-wise.\n",
    "df_fact[\"ClinicalNotes\"] = df_fact.apply(generate_clinical_notes, axis=1)\n",
    "\n",
    "# Save the updated fact table to a new CSV file.\n",
    "csv_filename_updated = \"Fact_MedicalEvent_WithNotes.csv\"\n",
    "df_fact.to_csv(csv_filename_updated, index=False)\n",
    "print(f\"CSV file '{csv_filename_updated}' created with ClinicalNotes column.\")\n",
    "\n",
    "# Update the SQLite database with the new fact table.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df_fact.to_sql(\"Fact_MedicalEvent\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Updated Fact_MedicalEvent table stored in SQLite database '{db_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Fact_MedicalEvent_WithNotes.csv' created with ClinicalNotes column.\n",
      "Updated Fact_MedicalEvent table stored in SQLite database 'medical_events.db'.\n"
     ]
    }
   ],
   "source": [
    "csv_filename_updated = \"Fact_MedicalEvent_WithNotes.csv\"\n",
    "df_fact = pd.read_csv(csv_filename_updated)\n",
    "print(f\"CSV file '{csv_filename_updated}' created with ClinicalNotes column.\")\n",
    "\n",
    "# Update the SQLite database with the new fact table.\n",
    "db_filename = \"medical_events.db\"\n",
    "conn = sqlite3.connect(db_filename)\n",
    "df_fact.to_sql(\"Fact_MedicalEvent\", conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Updated Fact_MedicalEvent table stored in SQLite database '{db_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables in DB: [('Dim_CensusRoomType',), ('Dim_CensusStatus',), ('Dim_CensusDate',), ('Dim_CensusResident',), ('Dim_CensusFacility',), ('Dim_CensusLocation',), ('Dim_CensusUnit',), ('Fact_Census',)]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(db_filename)\n",
    "\n",
    "# Debug: list available tables in the database\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "tables = cursor.fetchall()\n",
    "print(\"Available tables in DB:\", tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
